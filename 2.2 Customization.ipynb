{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# Warum auch immer, bekomme ich einen fehler wenn ich das hier nicht drinne habe. \n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(65536, shape=(), dtype=int32)\n",
      "tf.Tensor(1368, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Tensoren. Multidimensionale Arrays die schnell durch GPU schneller berechnet werden können (je nach lib)\n",
    "# Tensoren sind unveränderlich\n",
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(256))\n",
    "print(tf.reduce_sum([123, 456, 789]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow operations convert numpy arrays to Tensors automatically\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "And NumPy operations convert Tensors to numpy arrays automatically\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      "The .numpy() method explicitly converts a Tensor to a numpy array\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a GPU available: \n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Is the Tensor on GPU #0:  \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow nutzt wenn möglich eine GPU. Ich hatte in letzterzeit immer Probleme damit, deshalb immer schauen ob die wirklich verwendet wird\n",
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"Is there a GPU available: \"),\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))\n",
    "\n",
    "print(\"Is the Tensor on GPU #0:  \"),\n",
    "print(x.device.endswith('GPU:0')) # Tensor.device sagt einem immer wo der Tensor gespeichert ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On CPU:\n",
      "100 loops: 564.02ms\n",
      "On GPU:\n",
      "100 loops: 1.99ms\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow bestimmt selbst, welche Quelle am besten geeignet ist. Es ist aber möglich es selbst zu bestimmen mit tf.device:\n",
    "import time\n",
    "\n",
    "def time_matmul(x):\n",
    "    start = time.time()\n",
    "    for loop in range(100):\n",
    "        tf.matmul(x, x)\n",
    "\n",
    "    result = time.time()-start\n",
    "\n",
    "    print(\"100 loops: {:0.2f}ms\".format(1000*result))\n",
    "\n",
    "# Force CPU\n",
    "print(\"On CPU:\")\n",
    "with tf.device(\"CPU:0\"):\n",
    "    x = tf.random.uniform([1000, 1000])\n",
    "    assert x.device.endswith(\"CPU:0\")\n",
    "    time_matmul(x)\n",
    "\n",
    "# Force GPU wenn möglich!\n",
    "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    print(\"On GPU:\")\n",
    "    with tf.device(\"GPU:0\"):\n",
    "        x = tf.random.uniform([1000, 1000])\n",
    "        assert x.device.endswith(\"GPU:0\")\n",
    "        time_matmul(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets sind ein wesentlicher bestandteil und werden IMMER benötigt. Das richtige einlesen und verwenden ist daher wichtig:\n",
    "\n",
    "# direkt aus memory einlesen\n",
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Erstellen einer CSV Datei die als beispiel Dataset dient. \n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp()\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(\"\"\"Line 1\n",
    "        Line 2\n",
    "        Line 3\n",
    "        \"\"\")\n",
    "\n",
    "ds_file = tf.data.TextLineDataset(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Tensorflow Datasets erlauben schneller und direktes bearbeiten der Daten...\n",
    "\n",
    "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
    "\n",
    "ds_file = ds_file.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements of ds_tensors:\n",
      "tf.Tensor([1 4], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 9 25], shape=(2,), dtype=int32)\n",
      "tf.Tensor([16 36], shape=(2,), dtype=int32)\n",
      "\n",
      "Elements in ds_file:\n",
      "tf.Tensor([b'Line 1' b'        Line 2'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'        Line 3' b'        '], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print('Elements of ds_tensors:')\n",
    "for x in ds_tensors:\n",
    "    print(x)\n",
    "\n",
    "print('\\nElements in ds_file:')\n",
    "for x in ds_file:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "### Erstellen von eigenen Layers ###########\n",
    "############################################\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow hat komplett Keras als package dabei. \n",
    "# Bei Keras sind Layers Objecte mit dem ersten parameter als output dimension\n",
    "\n",
    "layer = tf.keras.layers.Dense(100)\n",
    "\n",
    "# Die Inputs sind meist unwichtig und können selbst bestimmt werden durch das Modell, können aber auch selbst angegeben werden:\n",
    "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(tf.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       "  array([[-0.40929544,  0.3124389 ,  0.40546972, -0.09909713, -0.07109708,\n",
       "           0.6319142 , -0.48159188,  0.05686063, -0.0063591 ,  0.06572825],\n",
       "         [ 0.26137668, -0.0314014 ,  0.41012746, -0.03485429,  0.31970614,\n",
       "          -0.41851783,  0.4239146 , -0.44705364,  0.02539951,  0.5565849 ],\n",
       "         [-0.08241683,  0.17229319,  0.4672262 , -0.25725383, -0.43908307,\n",
       "          -0.00500816, -0.39614558, -0.21510434, -0.50964665,  0.5362541 ],\n",
       "         [-0.526144  , -0.45505708, -0.08405441,  0.62521404,  0.13114089,\n",
       "           0.34899455,  0.4711463 , -0.5616564 , -0.5248999 , -0.34409043],\n",
       "         [ 0.30135167, -0.484842  ,  0.1627689 ,  0.12434554,  0.25461906,\n",
       "           0.4656729 , -0.5514828 ,  0.16638374, -0.10623926,  0.57282716]],\n",
       "        dtype=float32)>,\n",
       "  <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>],\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[-0.40929544,  0.3124389 ,  0.40546972, -0.09909713, -0.07109708,\n",
       "          0.6319142 , -0.48159188,  0.05686063, -0.0063591 ,  0.06572825],\n",
       "        [ 0.26137668, -0.0314014 ,  0.41012746, -0.03485429,  0.31970614,\n",
       "         -0.41851783,  0.4239146 , -0.44705364,  0.02539951,  0.5565849 ],\n",
       "        [-0.08241683,  0.17229319,  0.4672262 , -0.25725383, -0.43908307,\n",
       "         -0.00500816, -0.39614558, -0.21510434, -0.50964665,  0.5362541 ],\n",
       "        [-0.526144  , -0.45505708, -0.08405441,  0.62521404,  0.13114089,\n",
       "          0.34899455,  0.4711463 , -0.5616564 , -0.5248999 , -0.34409043],\n",
       "        [ 0.30135167, -0.484842  ,  0.1627689 ,  0.12434554,  0.25461906,\n",
       "          0.4656729 , -0.5514828 ,  0.16638374, -0.10623926,  0.57282716]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Die Daten eines layers sind einfach zugänglich..\n",
    "layer.variables, layer.kernel, layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen eines eigenen Layers:\n",
    "# Erben von der Layer Klasse und die Methoden: __init__, build und call implementieren\n",
    "class NicoDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(NicoDense, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "        \n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.kernel)\n",
    "    \n",
    "layer = NicoDense(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nico_dense/kernel:0']\n"
     ]
    }
   ],
   "source": [
    "_ = layer(tf.zeros([10, 5]))\n",
    "print([var.name for var in layer.trainable_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composing Layers ist das A und O für bessere Modelle, TF bietet mit Keras einfache und gute Möglichkeiten:\n",
    "\n",
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super(ResnetIdentityBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters\n",
    "\n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x1edcd8f2cc8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1edcd8dd4c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1edcd8ddb48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1edcd8fa1c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1edcd8fa708>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1edcd8fae48>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = block(tf.zeros([1, 2, 3, 3]))\n",
    "block.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_identity_block\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  8         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  12        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3, 3), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nico_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1), input_shape=(None, None, 3)),\n",
    "                            tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1,\n",
    "                                                    padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "\n",
    "nico_seq(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, None, None, 1)     4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, None, None, 1)     4         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 2)     4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, None, None, 2)     8         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, None, 3)     9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, None, None, 3)     12        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nico_seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
