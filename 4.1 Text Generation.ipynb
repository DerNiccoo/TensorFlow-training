{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# Warum auch immer, bekomme ich einen fehler wenn ich das hier nicht drinne habe. \n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 135349 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "import textract\n",
    "text = textract.process(\"D:\\\\Nico\\\\OneDrive\\\\Studium\\\\Bachelor\\\\Bachelor Thesis\\\\Abschlussarbeit_Nico_Wellermann.pdf\").decode(\"utf-8\")\n",
    "\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nderem versucht, dem Computer die menschliche Sprache zu\n",
      "vermitteln. Bei virtuellen Marktplätzen hat sich seit der Einführung viel verändert. So\n",
      "wird z.B. das Kundenverhalten mithilfe neuronaler Netze analysiert, um gezielt Vorschläge\n",
      "zu platzieren. Die eigentliche Produktsuche hat sich hingegen kaum verändert. In dieser\n",
      "Arbeit wird ein alternatives Verfahren untersucht, das mithilfe der natürlichen Sprachverarbeitung die herkömmliche Produktsuche ersetzen soll.\n",
      "\n",
      "1.1. Motivation\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(text[11500:12000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einzigartige Chars: 102\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'Einzigartige Chars: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zwei Lookup tables, chars -> zahlen & zahlen -> chars\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n': 0\n",
      "'\\x0c': 1\n",
      "'\\r': 2\n",
      "' ': 3\n",
      "'!': 4\n",
      "'%': 5\n",
      "'&': 6\n",
      "'(': 7\n",
      "')': 8\n",
      "'+': 9\n",
      "',': 10\n",
      "'-': 11\n",
      "'.': 12\n",
      "'/': 13\n",
      "'0': 14\n",
      "'1': 15\n",
      "'2': 16\n",
      "'3': 17\n",
      "'4': 18\n",
      "'5': 19\n"
     ]
    }
   ],
   "source": [
    "for char, _ in zip(char2idx, range(20)):\n",
    "    print(f'{repr(char)}: {char2idx[char]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Name:\\r\\n\\r\\nNico' ------ mapped ------ > [43 59 71 63 24  2  0  2  0 43 67 61 73]\n"
     ]
    }
   ],
   "source": [
    "# Wie ist der Text mapped?\n",
    "print(f'{repr(text[:13])} ------ mapped ------ > {text_as_int[:13]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340\n",
      "N\n",
      "a\n",
      "m\n",
      "e\n",
      ":\n"
     ]
    }
   ],
   "source": [
    "# Das Trainieren ist relativ einfach\n",
    "# Wir versuchen ein vorhersage Modell auf Char basis. Wir haben bereits einen (langen) original Text. \n",
    "# Wir gehen einfach für jeden char durch das Modell und können testen ob es richtig vorhersagt, da wir den Text haben\n",
    "# RNN haben den Vorteil, einen internen Zustand zu haben, der das vorherige Ergebniss speichert. Dadurch gut für Wörter / Sätze geeignet\n",
    "\n",
    "# Wir trainieren das Modell in Sequenzen. Bsp. Seq_leng = 4 und der Text = \"Hello\" input = \"Hell\" output = \"ello\"\n",
    "\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length + 1)\n",
    "print(examples_per_epoch)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "#for input_example, target_example in  dataset.take(1):\n",
    "#    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "#    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 43 ('N')\n",
      "  expected output: 59 ('a')\n",
      "Step    1\n",
      "  input: 59 ('a')\n",
      "  expected output: 71 ('m')\n",
      "Step    2\n",
      "  input: 71 ('m')\n",
      "  expected output: 63 ('e')\n",
      "Step    3\n",
      "  input: 63 ('e')\n",
      "  expected output: 24 (':')\n",
      "Step    4\n",
      "  input: 24 (':')\n",
      "  expected output: 2 ('\\r')\n"
     ]
    }
   ],
   "source": [
    "# Example copy pasta wie das Modell lernen würde:\n",
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer=\"glorot_uniform\"),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(vocab_size = len(vocab), embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 102) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           26112     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 102)           104550    \n",
      "=================================================================\n",
      "Total params: 4,068,966\n",
      "Trainable params: 4,068,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 71,  93,  31,  55,  75,  30,  44,  23,  38,  16,  39,  15,  92,\n",
       "        26,  56,  14,   2,  70,  95,  27,  88,  62,  26,  82,  18,  17,\n",
       "        40,  12,  27,  70,  90,  29,  74,  92,   0,  61,  25,  77,  62,\n",
       "        69,  16,  16,  72,  63,  38,  70,  52,  75,  61,  26,  63,  28,\n",
       "        27,  66,  92,  31,  16,  42,  67,  32,  86,  68,  92,  61,   2,\n",
       "        78, 101,  53,  94,  65,  73,  79,  35,  88,   3,  94,  25,  75,\n",
       "        71,  31,  78,  36,  86,  85,   0,  54,  74,  75,   7,  37,  10,\n",
       "        58,  69,  63,  84,  23,  82,  94,   8,  65], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " ' . . .\\r\\n3.3.4 Persistierung . . . . . . . . . . .\\r\\n3.3.5 Auswertung . . . . . . . . . . . .\\r\\n3.4 Pro'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'm̈BZqAO9I2J1́<[0\\rl–=äd<x43K.=lü?ṕ\\nc;sdk22neIlWqc<e>=h́B2MiC}j́c\\rt•X̌gouFä ̌;qmBtG}{\\nYpq(H,]kez9x̌)g'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 102)\n",
      "4.6237774\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(example_batch_predictions.shape)\n",
    "print(example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 4.4151\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 3.1985\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 2.7310\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 2.4918\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 2.3616\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 2.2606\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 2.1793\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 2.1002\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 2.0162\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 1s 69ms/step - loss: 1.9386\n"
     ]
    }
   ],
   "source": [
    "# Da das Training vermutlich sehr lange dauert, wollen wir Checkpoints haben.\n",
    "checkpoint_dir = './nico_training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)\n",
    "\n",
    "EPOCHS=10\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            26112     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 102)            104550    \n",
      "=================================================================\n",
      "Total params: 4,068,966\n",
      "Trainable params: 4,068,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Um die Batch Size zu ändern muss dass Modell neu erzeugt werden, mit den Weights aus dem Training\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, temperature = 1.0):\n",
    "    num_generate = 1000\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    text_generated = []\n",
    "    \n",
    "    temperature = temperature # Tief = mehr vorhersehbar, Hoch = mehr unerwartet\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        \n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einleitung giesbeieren västame mutzissen zzionnachen\n",
      "bieken mmabeienen em ehsweit, nachen\n",
      "Sechnioßen. HKallsist die hiasches Anwendute teis die Lehoresist die s.\n",
      "\n",
      "Abberdeben. Abwirdungale vorhel en Aus alt riendanf fathle enst wird–Klichten ein Terestelonon die erseitisto — wurden.\n",
      "\n",
      "2.337\n",
      "\n",
      "\f",
      "Raweis\n",
      "Bebinduzr, wurd einse metzein kelfener Asföllss, wird. Die istrveiteignwichtetichen.\n",
      "Eingerach “2001). Rachlitionasen Preiode fügle faturient\n",
      "weiss e kohnessarn. Domicheinss ins undung däs verwenl Ans dasse ze werdensscheit undet.\n",
      "Dieserbeite zufesteplen der Derännache htries eine enfandenan stwitpe Abbeitzuge orbebenfen on de\n",
      "Be riegen sschise reiken die enn rimm tor von Ethnach uftor Autigrigk–ersommäbvioren in dee Anworden Das\n",
      "betalden des An der Algchlebsichter äcwerkeretthr der Sutzresxenen.\n",
      "mir aphacbeu hriscenitreitend, verharinit zuher gehauf des Vestetztan. Dasis eanen Ander unde anfüglon wie der Ssteill nellet\n",
      "diesen werch dan Lodimt: Ang–den Ergexchmitt eingager :. Mere\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Einleitung \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "# Advanced Training:\n",
    "model = build_model(vocab_size = len(vocab), embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inp)\n",
    "        loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(target, predictions, from_logits=True))\n",
    "        \n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.624759197235107\n",
      "Epoch 1 Loss 3.6770\n",
      "Time taken for 1 epoch 2.097106695175171 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.6241683959960938\n",
      "Epoch 2 Loss 2.8968\n",
      "Time taken for 1 epoch 0.9770314693450928 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.870112895965576\n",
      "Epoch 3 Loss 2.5338\n",
      "Time taken for 1 epoch 0.9730319976806641 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.511029005050659\n",
      "Epoch 4 Loss 2.4738\n",
      "Time taken for 1 epoch 1.0231082439422607 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 2.3689935207366943\n",
      "Epoch 5 Loss 2.3287\n",
      "Time taken for 1 epoch 1.259098768234253 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.2994742393493652\n",
      "Epoch 6 Loss 2.2235\n",
      "Time taken for 1 epoch 0.9943468570709229 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.2322096824645996\n",
      "Epoch 7 Loss 2.1111\n",
      "Time taken for 1 epoch 0.9850912094116211 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 2.0730948448181152\n",
      "Epoch 8 Loss 2.1221\n",
      "Time taken for 1 epoch 0.9805796146392822 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 2.1575448513031006\n",
      "Epoch 9 Loss 1.9125\n",
      "Time taken for 1 epoch 0.9806873798370361 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.8859862089157104\n",
      "Epoch 10 Loss 1.8845\n",
      "Time taken for 1 epoch 1.2313554286956787 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.888048529624939\n",
      "Epoch 11 Loss 1.7667\n",
      "Time taken for 1 epoch 0.9743940830230713 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.7653312683105469\n",
      "Epoch 12 Loss 1.6873\n",
      "Time taken for 1 epoch 0.9832322597503662 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.5766427516937256\n",
      "Epoch 13 Loss 1.5841\n",
      "Time taken for 1 epoch 0.9789235591888428 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.5945297479629517\n",
      "Epoch 14 Loss 1.6345\n",
      "Time taken for 1 epoch 0.9988470077514648 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.5578418970108032\n",
      "Epoch 15 Loss 1.4549\n",
      "Time taken for 1 epoch 1.2486581802368164 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 1.3895012140274048\n",
      "Epoch 16 Loss 1.4807\n",
      "Time taken for 1 epoch 0.9854187965393066 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.2666610479354858\n",
      "Epoch 17 Loss 1.3636\n",
      "Time taken for 1 epoch 1.0171656608581543 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 1.2710130214691162\n",
      "Epoch 18 Loss 1.2341\n",
      "Time taken for 1 epoch 0.9857437610626221 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.2762161493301392\n",
      "Epoch 19 Loss 1.1854\n",
      "Time taken for 1 epoch 0.9778897762298584 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.105526328086853\n",
      "Epoch 20 Loss 1.1200\n",
      "Time taken for 1 epoch 1.281963586807251 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 1.088761806488037\n",
      "Epoch 21 Loss 1.1228\n",
      "Time taken for 1 epoch 0.9785106182098389 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.9860420227050781\n",
      "Epoch 22 Loss 1.1589\n",
      "Time taken for 1 epoch 0.981926441192627 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.9610470533370972\n",
      "Epoch 23 Loss 1.0164\n",
      "Time taken for 1 epoch 0.9747650623321533 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 1.0320515632629395\n",
      "Epoch 24 Loss 0.9639\n",
      "Time taken for 1 epoch 0.9804489612579346 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.9222578406333923\n",
      "Epoch 25 Loss 0.9666\n",
      "Time taken for 1 epoch 1.2770366668701172 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.8758096098899841\n",
      "Epoch 26 Loss 0.9131\n",
      "Time taken for 1 epoch 1.0021240711212158 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.7986491918563843\n",
      "Epoch 27 Loss 0.8350\n",
      "Time taken for 1 epoch 0.9669747352600098 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.7802958488464355\n",
      "Epoch 28 Loss 0.8489\n",
      "Time taken for 1 epoch 0.9816854000091553 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.748015284538269\n",
      "Epoch 29 Loss 0.8014\n",
      "Time taken for 1 epoch 0.9786350727081299 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.7132469415664673\n",
      "Epoch 30 Loss 0.7647\n",
      "Time taken for 1 epoch 1.3273372650146484 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.6462832093238831\n",
      "Epoch 31 Loss 0.7196\n",
      "Time taken for 1 epoch 0.9828314781188965 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.6504468321800232\n",
      "Epoch 32 Loss 0.7383\n",
      "Time taken for 1 epoch 0.9859139919281006 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.5975772142410278\n",
      "Epoch 33 Loss 0.6499\n",
      "Time taken for 1 epoch 0.9734148979187012 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.5623155832290649\n",
      "Epoch 34 Loss 0.6432\n",
      "Time taken for 1 epoch 0.9814469814300537 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.5210016369819641\n",
      "Epoch 35 Loss 0.5854\n",
      "Time taken for 1 epoch 1.2355384826660156 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.495981365442276\n",
      "Epoch 36 Loss 0.5766\n",
      "Time taken for 1 epoch 0.9839367866516113 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.45900389552116394\n",
      "Epoch 37 Loss 0.5487\n",
      "Time taken for 1 epoch 0.9752566814422607 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.42891567945480347\n",
      "Epoch 38 Loss 0.4988\n",
      "Time taken for 1 epoch 0.9906294345855713 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.4061674475669861\n",
      "Epoch 39 Loss 0.4740\n",
      "Time taken for 1 epoch 0.9791805744171143 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.388224720954895\n",
      "Epoch 40 Loss 0.4323\n",
      "Time taken for 1 epoch 1.2873811721801758 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.3563792407512665\n",
      "Epoch 41 Loss 0.4355\n",
      "Time taken for 1 epoch 0.9859075546264648 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.32025232911109924\n",
      "Epoch 42 Loss 0.4046\n",
      "Time taken for 1 epoch 0.9871184825897217 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.3003750741481781\n",
      "Epoch 43 Loss 0.3928\n",
      "Time taken for 1 epoch 0.9799246788024902 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.2691766619682312\n",
      "Epoch 44 Loss 0.3768\n",
      "Time taken for 1 epoch 0.978325366973877 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.2786734104156494\n",
      "Epoch 45 Loss 0.3645\n",
      "Time taken for 1 epoch 1.2686002254486084 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.2657788097858429\n",
      "Epoch 46 Loss 0.3488\n",
      "Time taken for 1 epoch 0.9852714538574219 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.2524743378162384\n",
      "Epoch 47 Loss 0.3350\n",
      "Time taken for 1 epoch 0.9813830852508545 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.2228463739156723\n",
      "Epoch 48 Loss 0.3090\n",
      "Time taken for 1 epoch 0.9794139862060547 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.2151319831609726\n",
      "Epoch 49 Loss 0.2885\n",
      "Time taken for 1 epoch 0.9787540435791016 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.20410789549350739\n",
      "Epoch 50 Loss 0.2965\n",
      "Time taken for 1 epoch 1.2618250846862793 sec\n",
      "\n",
      "Epoch 51 Batch 0 Loss 0.19715413451194763\n",
      "Epoch 51 Loss 0.2795\n",
      "Time taken for 1 epoch 0.9843111038208008 sec\n",
      "\n",
      "Epoch 52 Batch 0 Loss 0.1862414926290512\n",
      "Epoch 52 Loss 0.2717\n",
      "Time taken for 1 epoch 0.9733965396881104 sec\n",
      "\n",
      "Epoch 53 Batch 0 Loss 0.18189285695552826\n",
      "Epoch 53 Loss 0.2514\n",
      "Time taken for 1 epoch 0.9861152172088623 sec\n",
      "\n",
      "Epoch 54 Batch 0 Loss 0.17778177559375763\n",
      "Epoch 54 Loss 0.2399\n",
      "Time taken for 1 epoch 0.9823720455169678 sec\n",
      "\n",
      "Epoch 55 Batch 0 Loss 0.1790662705898285\n",
      "Epoch 55 Loss 0.2440\n",
      "Time taken for 1 epoch 1.269949197769165 sec\n",
      "\n",
      "Epoch 56 Batch 0 Loss 0.1677244007587433\n",
      "Epoch 56 Loss 0.2319\n",
      "Time taken for 1 epoch 0.9796609878540039 sec\n",
      "\n",
      "Epoch 57 Batch 0 Loss 0.15849009156227112\n",
      "Epoch 57 Loss 0.2237\n",
      "Time taken for 1 epoch 0.9884481430053711 sec\n",
      "\n",
      "Epoch 58 Batch 0 Loss 0.1513485163450241\n",
      "Epoch 58 Loss 0.2204\n",
      "Time taken for 1 epoch 0.9863603115081787 sec\n",
      "\n",
      "Epoch 59 Batch 0 Loss 0.1431942582130432\n",
      "Epoch 59 Loss 0.2185\n",
      "Time taken for 1 epoch 0.9717025756835938 sec\n",
      "\n",
      "Epoch 60 Batch 0 Loss 0.14927564561367035\n",
      "Epoch 60 Loss 0.2154\n",
      "Time taken for 1 epoch 1.2810394763946533 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training step\n",
    "EPOCHS = 60\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  # resetting the hidden state at the start of every epoch\n",
    "  model.reset_states()\n",
    "\n",
    "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "    loss = train_step(inp, target)\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "      template = 'Epoch {} Batch {} Loss {}'\n",
    "      print(template.format(epoch+1, batch_n, loss))\n",
    "\n",
    "  # saving (checkpoint) the model every 5 epochs\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "  print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
    "  print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_docs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2870cfb37d3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_docs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfdocs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplotter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHistoryPlotter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmoothing_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#plt.ylim([0.5, 0.7])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_docs'"
     ]
    }
   ],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)\n",
    "plotter.plot(history)\n",
    "#plt.ylim([0.5, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, None, 256)            26112     \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, None, 102)            104550    \n",
      "=================================================================\n",
      "Total params: 4,068,966\n",
      "Trainable params: 4,068,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Einleitung: Lolgat Klasse; F. 25.\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "45\n",
      "38\n",
      "40\n",
      "31\n",
      "53\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "15\n",
      "166\n",
      "\n",
      "3 % \n",
      "196 Evaluation . . . . . .\n",
      "3.3.2 Hybrid named-entity recognition . . . . . . . . . . . . . . . . . . . . . . bedingt\n",
      "die Wörter “iPhone” und “A–F2702). Dampht werden. Somit ebenfalls Annahmen,\n",
      "geitt zu den Klassen • und Teller Anngabe die Beisp\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()\n",
    "print(generate_text(model, start_string=u\"Einleitung: \", temperature = 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umsetzung der Eingabe verloren,\n",
      "die bei einer Auswertung nicht beachtet werden sollen (hier Fenstergröße = 1). Die Anforderungen werden mit den Buchstaben FA und NA für fin\n",
      "Outpuell ausgewichtet und das e genaueren Evaluation der Daten (Abbildung 14) zeigte, dass das Modell keine Produkte erkennt, die ausgewählte Sequenz dem jeweiligen Attribut\n",
      "zugewiesen werden sollten, was die Bearbeitung von Smartphones miteinschließt. Das häufige Eingeben von Text wird durch die Verwendung einer Anfrage und so die Performance zu verbessern. Die Verfahren werden\n",
      "passend zu den Klassen “Erkannt, rient ein Ungleichgewicht und Sequenzen\n",
      "mit stark variierender Länge werden von dem Modell nur schwerer Vorverarbeitung die herkömmliche Produktsuche erschwert. Abbildung 8 zeigt eine beispielhafte Eingabe in der die Attribute farblich hervorgehoben werden. In dem 1.1. Kapitel wurde die Zahlen betrachtet, welches die Anwender selbst die Attribute markieren, um die Datenbasis zu erweitern. Technologische Arti\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Umsetzung \", temperature = 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Name:\\r\\n\\r\\nNico Wellermann\\r\\n\\r\\nThema:\\r\\n\\r\\nNat\\xc3\\xbcrlichsprachliche Kommunikation in virtuellen\\r\\nMarktpl\\xc3\\xa4tzen\\r\\n\\r\\nArbeitsplatz:\\r\\n\\r\\nCAS Software AG, Karlsruhe\\r\\n\\r\\nReferent:\\r\\n\\r\\nProf. Dr. W\\xc3\\xb6lfel\\r\\n\\r\\nKorreferent:\\r\\n\\r\\nProf. Dr. K\\xc3\\xb6rner\\r\\n\\r\\nAbgabetermin:\\r\\n\\r\\n09.02.2020\\r\\n\\r\\nKarlsruhe, 09.11.2019\\r\\nDer Vorsitzende des Pr\\xc3\\xbcfungsausschusses\\r\\n\\r\\nProf. Dr. Heiko K\\xc3\\xb6rner\\r\\n\\r\\nFakult\\xc3\\xa4t f\\xc3\\xbcr Informatik und Wirtschaftsinformatik\\r\\n\\r\\nBachelor-Thesis\\r\\n\\r\\n\\x0cErkla\\xcc\\x88rung\\r\\nHiermit versichere ich, dass ich meine Abschlussarbeit selbsta\\xcc\\x88ndig verfasst und keine\\r\\nanderen als die angegebenen Quellen und Hilfsmittel benutzt habe.\\r\\n\\r\\nDatum:\\r\\n\\r\\n.......................................................\\r\\n(Unterschrift)\\r\\n\\r\\n\\x0cZUSAMMENFASSUNG\\r\\n\\r\\nI. Zusammenfassung\\r\\nVirtuelle Marktpla\\xcc\\x88tze werden von Jahr zu Jahr bedeutsamer. Auf elektronischen Marktpla\\xcc\\x88tzen beispielsweise finden viele Ka\\xcc\\x88ufer\\xe2\\x80\\x93Verka\\xcc\\x88ufer Situationen statt. Anwender erstellen\\r\\nein digitales Angebot, das von potenziellen Ka\\xcc\\x88ufern gefunden werden mo\\xcc\\x88chte. Fu\\xcc\\x88r eine intuitive Bedienung soll die Verwendung der natu\\xcc\\x88rlichen Eingabe untersucht werden. Diese\\r\\nArbeit befasst sich mit dem Erfassen und Strukturieren von Informationen, die in Textform vorliegen. Aus diesen Texten sollen die wesentlichen Informationen extrahiert werden\\r\\nund mit Hilfe der strukturierten Daten soll es dann mo\\xcc\\x88glich sein, passende Angebote fu\\xcc\\x88r\\r\\neine gegebene Anfrage zu finden. Dafu\\xcc\\x88r wird ein Prototyp in Form einer Webanwendung\\r\\nentwickelt, welcher die verschiedenen Aufgaben eines virtuellen Marktplatzes erfu\\xcc\\x88llt. Zum\\r\\nErkennen der Attribute aus der Texteingabe wurden mehrere Algorithmen verwendet,\\r\\ndie zusammen eine Pipeline bilden. Um die Performance der Pipeline messen zu ko\\xcc\\x88nnen,\\r\\nwurden verschiedene Metriken aufgestellt.\\r\\nDurch das Erstellen einer Pipeline ko\\xcc\\x88nnen die Sta\\xcc\\x88rken der einzelnen Algorithmen kombiniert werden und somit das Ergebnis optimiert. Die verwendeten Algorithmen zum\\r\\nErkennen des Hauptattribut \\xe2\\x80\\x9cProdukt\\xe2\\x80\\x9d erreichten eine Genauigkeit von 87,46 % auf den\\r\\nvorhandenen Datensatz. Beschreibbare Attribute wurden durch regelbasierte Ansa\\xcc\\x88tze aus\\r\\ndem Text extrahiert, was ein zielfu\\xcc\\x88hrendes Ergebnis erzielte. Die gemessenen Ergebnisse u\\xcc\\x88bertrafen deutlich die vorherigen Erwartungen und Anwender hatten das Gefu\\xcc\\x88hl als\\r\\nwu\\xcc\\x88rde das System sie verstehen. Dieses Verfahren ermo\\xcc\\x88glicht eine neue Art, um Verhandlungen in virtuellen Marktpla\\xcc\\x88tzen zu fu\\xcc\\x88hren.\\r\\n\\r\\nI\\r\\n\\r\\n\\x0cZUSAMMENFASSUNG\\r\\n\\r\\nII. Abstract\\r\\nSince few years, virtual marketplaces are catching more and more attention. Daily, hundreds of thousands buyer and seller situations all over the world take place on so called\\r\\nelectronic marketplaces. Users create digital offers that are found by potential buyers. Unfortunately, one online search creates numerous possible offers leading to a time-consuming\\r\\ncomparison between many different offers. Therefore, an intuitive workflow using natural\\r\\ninput is needed to facilitate each query. Main goal of the thesis was to collect and structure\\r\\nthe query input, sort the collected information to present one perfect-fit offer. For this\\r\\npurpose, a prototype in form of a web application was developed fulfilling various tasks\\r\\nof a virtual marketplace. Several algorithms like ELMo and Targer were used to recognize\\r\\nattributes from the text input, forming a pipeline.\\r\\nBy creating a pipeline, the strength of each individual algorithm was combined to optimize\\r\\nthe overall result. In order to measure the performance of the pipeline, different metrics\\r\\nwere set up. Algorithms used to recognize the main attribute \\xe2\\x80\\x9cproduct\\xe2\\x80\\x9d achieved an\\r\\naccuracy of 87.46 % on the existing data set. Describable attributes were extracted from\\r\\nthe text using a rule-based system, which achieved a target-oriented result. The measured\\r\\nresults significantly exceeded previous expectations as users have the feeling of being\\r\\nunderstood by the system. This technique enables a new way of negotiating in virtual\\r\\nmarketplaces.\\r\\n\\r\\nII\\r\\n\\r\\n\\x0cINHALTSVERZEICHNIS\\r\\n\\r\\nII Inhaltsverzeichnis\\r\\nI\\r\\n\\r\\nZusammenfassung\\r\\n\\r\\nI\\r\\n\\r\\nII Abstract\\r\\n\\r\\nII\\r\\n\\r\\nII Inhaltsverzeichnis\\r\\n\\r\\nIII\\r\\n\\r\\nIV Abku\\xcc\\x88rzungsverzeichnis\\r\\n\\r\\nV\\r\\n\\r\\n1 Einleitung\\r\\n1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\r\\n1.2 Ziel der Arbeit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\r\\n1.3 Gliederung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\r\\n\\r\\n1\\r\\n1\\r\\n2\\r\\n3\\r\\n\\r\\n2 Grundlagen\\r\\n2.1 Bag\\xe2\\x80\\x93of\\xe2\\x80\\x93words . . . . . . . . .\\r\\n2.2 Word Embeddings . . . . . .\\r\\n2.2.1 Word2Vec . . . . . . .\\r\\n2.2.2 GloVe . . . . . . . . .\\r\\n2.2.3 ELMo . . . . . . . . .\\r\\n2.3 Convolutional Neural Network\\r\\n2.4 Recurrent Neural Network . .\\r\\n2.5 Unterschiede RNN und CNN .\\r\\n2.6 Long Short\\xe2\\x80\\x93Term Memory . .\\r\\n2.7 Conditional Random Fields .\\r\\n2.8 Fuzzy\\xe2\\x80\\x93Suche . . . . . . . . . .\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n4\\r\\n4\\r\\n4\\r\\n5\\r\\n5\\r\\n6\\r\\n7\\r\\n10\\r\\n11\\r\\n11\\r\\n13\\r\\n14\\r\\n\\r\\n3 Konzeption\\r\\n3.1 Annahmen . . . . . . . . . . . . . . . . .\\r\\n3.2 Anforderungen . . . . . . . . . . . . . .\\r\\n3.3 Komponenten . . . . . . . . . . . . . . .\\r\\n3.3.1 Benutzerschnittstelle . . . . . . .\\r\\n3.3.2 Hybrid named-entity recognition\\r\\n3.3.3 Tagging . . . . . . . . . . . . . .\\r\\n3.3.4 Persistierung . . . . . . . . . . .\\r\\n3.3.5 Auswertung . . . . . . . . . . . .\\r\\n3.4 Prozesse . . . . . . . . . . . . . . . . . .\\r\\n3.5 Bewertungskriterien . . . . . . . . . . . .\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n16\\r\\n16\\r\\n17\\r\\n20\\r\\n20\\r\\n21\\r\\n23\\r\\n24\\r\\n25\\r\\n25\\r\\n26\\r\\n\\r\\n4 Umsetzung\\r\\n4.1 Vorgehen . . . . . . . . . . . . . .\\r\\n4.2 Datenakquise . . . . . . . . . . .\\r\\n4.3 Hybrid named-entity recognition .\\r\\n4.3.1 SpaCy . . . . . . . . . . .\\r\\n4.3.2 Regula\\xcc\\x88re Ausdru\\xcc\\x88cke . . . .\\r\\n4.3.3 Metadaten Analyse . . . .\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n28\\r\\n28\\r\\n29\\r\\n30\\r\\n30\\r\\n31\\r\\n33\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\nIII\\r\\n\\r\\n\\x0cINHALTSVERZEICHNIS\\r\\n\\r\\n4.4\\r\\n4.5\\r\\n\\r\\n4.3.4 Targer . . . . . . . . . . . .\\r\\n4.3.5 ELMo . . . . . . . . . . . .\\r\\n4.3.6 Fuzzy Matching . . . . . . .\\r\\n4.3.7 Zusammenspiel der Pipeline\\r\\nVerwendeten Technologien . . . . .\\r\\nEntwicklung des Prototyps . . . . .\\r\\n4.5.1 Eingabemethode Inserat . .\\r\\n4.5.2 Berechnung der Metriken . .\\r\\n4.5.3 Chatbot . . . . . . . . . . .\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n.\\r\\n\\r\\n35\\r\\n39\\r\\n41\\r\\n44\\r\\n45\\r\\n46\\r\\n46\\r\\n46\\r\\n48\\r\\n\\r\\n5 Evaluation\\r\\n51\\r\\n5.1 Evaluationsmethodik . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\r\\n5.2 Auswertung der Algorithmen . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\r\\n5.3 Auswertung der Oberfla\\xcc\\x88che . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\r\\n6 Fazit\\r\\n\\r\\n58\\r\\n\\r\\n7 Ausblick\\r\\n\\r\\n58\\r\\n\\r\\n8 Quellenverzeichnis\\r\\n\\r\\n60\\r\\n\\r\\nAnhang\\r\\n\\r\\nI\\r\\n\\r\\nA Ergebnisse der Umfrage\\r\\n\\r\\nI\\r\\n\\r\\nB Metriken der Pipeline\\r\\n\\r\\nVIII\\r\\n\\r\\nIV\\r\\n\\r\\n\\x0cINHALTSVERZEICHNIS\\r\\n\\r\\nIV. Abku\\xcc\\x88rzungsverzeichnis\\r\\nbiLSTM\\r\\nbiRNN\\r\\nBoW\\r\\nCNN\\r\\nCRF\\r\\nELMo\\r\\nGB\\r\\nGloVe\\r\\nLSTM\\r\\nML\\r\\nMP\\r\\nNER\\r\\nNET\\r\\nNLP\\r\\nPOS\\r\\nREST\\r\\nRNN\\r\\nSE\\r\\nTanh\\r\\nUI\\r\\nUX\\r\\n\\r\\nbidirectional Long Short\\xe2\\x80\\x93Term Memory\\r\\nbidirectional Recurrent Neural Network\\r\\nBag\\xe2\\x80\\x93of\\xe2\\x80\\x93words\\r\\nConvolutional Neural Network\\r\\nConditional Random Field\\r\\nEmbeddings from Language Models\\r\\nGigabyte\\r\\nGlobal Vectors\\r\\nLong Short\\xe2\\x80\\x93Term Memory\\r\\nMachine Learning\\r\\nMegapixel\\r\\nNamed Entity Recognition\\r\\nNamed Entity Tagging\\r\\nNatural Language Processing\\r\\nPart of Speech\\r\\nRepresentational State Transfer\\r\\nRecurrent Neural Network\\r\\nSoftware Engineering\\r\\nTangens hyperbolicus\\r\\nUser Interface\\r\\nUser Experience\\r\\n\\r\\nV\\r\\n\\r\\n\\x0cKapitel 1\\r\\n\\r\\nEinleitung\\r\\n\\r\\n1. Einleitung\\r\\n1950 erfand der britische Mathematiker Alan Turing den nach ihm benannten \\xe2\\x80\\x9cTuringTest\\xe2\\x80\\x9d. Dieser Test sollte feststellen ob Menschen und Maschinen u\\xcc\\x88ber die gleiche Art von\\r\\nIntelligenz verfu\\xcc\\x88gen. Hierbei versucht der Mensch durch Konversation zu entscheiden, ob\\r\\nes sich bei seinem Gegenu\\xcc\\x88ber um eine Maschine oder eine Person handelt. Jedoch besteht\\r\\ndieser Test nur als theoretischer Versuch, der erst mit dem Durchbruch der ku\\xcc\\x88nstlichen\\r\\nIntelligenz zu praktischen Versuchen fu\\xcc\\x88hrte.\\r\\nBereits 1980 widerlegte der amerikanische Philosoph John Searle die Theorie des \\xe2\\x80\\x9cTuringTests\\xe2\\x80\\x9d. Mit dem Gedankenexperiment durch das sogenannte \\xe2\\x80\\x9cchinesische Zimmer\\xe2\\x80\\x9d zeigte\\r\\ner auf, dass Computer, nur weil diese immer die korrekte Antwort geben, keine Experten\\r\\nauf dem Gebiet sein mu\\xcc\\x88ssen. Das Experiment sieht folgenderma\\xc3\\x9fen aus: In einem geschlossenen Raum sitzt eine Person, die weder Chinesisch spricht noch versteht. Diese hat\\r\\ndie Aufgabe, auf chinesisch gestellte Fragen anhand einer in seiner Muttersprache verfassten Anleitung auf chinesisch zu beantworten. Personen au\\xc3\\x9ferhalb des Zimmers denken,\\r\\ndass der Mensch in dem Zimmer in der Lage ist chinesisch zu sprechen, obwohl dieser nur\\r\\neinfache Regeln befolgt.\\r\\nU\\xcc\\x88bertragen auf Computer zeigt das Gedankenexperiment, dass die Computer nur weil\\r\\nsie richtige Ergebnisse produzieren, noch lange nicht in der Lage sind die Fragen bzw.\\r\\ndie Situationen zu verstehen. Dennoch wird daran geforscht (Arel, Rose und Karnowski\\r\\n2010), (Devlin u. a. 2018), dass Computer mithilfe von verschiedensten Algorithmen eine\\r\\nArt Bewusstsein u\\xcc\\x88ber Situationen erlernen und sogar verstehen \\xe2\\x80\\x94 also eine ku\\xcc\\x88nstliche\\r\\nIntelligenz entwickeln.\\r\\nDie natu\\xcc\\x88rliche Sprachverarbeitung ist dabei auch ein Baustein, an dem stetig geforscht\\r\\nwird. Dabei wird unter anderem versucht, dem Computer die menschliche Sprache zu\\r\\nvermitteln. Bei virtuellen Marktpla\\xcc\\x88tzen hat sich seit der Einfu\\xcc\\x88hrung viel vera\\xcc\\x88ndert. So\\r\\nwird z.B. das Kundenverhalten mithilfe neuronaler Netze analysiert, um gezielt Vorschla\\xcc\\x88ge\\r\\nzu platzieren. Die eigentliche Produktsuche hat sich hingegen kaum vera\\xcc\\x88ndert. In dieser\\r\\nArbeit wird ein alternatives Verfahren untersucht, das mithilfe der natu\\xcc\\x88rlichen Sprachverarbeitung die herko\\xcc\\x88mmliche Produktsuche ersetzen soll.\\r\\n\\r\\n1.1. Motivation\\r\\nIn der heutigen Zeit ist es schwieriger Angebot und Nachfrage im E\\xe2\\x80\\x93Commerce zusammenzubringen. Die existierenden Systeme bieten nicht genug Freiheiten, um die Anfrage genau\\r\\nzu spezifizieren. Daher wird nicht nur das gesuchte Produkt, sondern auch viele andere\\r\\n\\r\\n1\\r\\n\\r\\n\\x0cKapitel 1\\r\\n\\r\\nEinleitung\\r\\n\\r\\nErgebnisse gefunden. Mit verschiedenen Eingabefeldern kann die Auswahl genauer spezifiziert werden, was aber in den meisten Fa\\xcc\\x88llen zu generisch oder schlicht zu umsta\\xcc\\x88ndlich\\r\\nist und deshalb nicht verwendet wird. Fu\\xcc\\x88r Anwender ist es viel natu\\xcc\\x88rlicher etwas direkt\\r\\nzu beschreiben, als es in starre, vorgefertigte Formulare einzutragen. Diese Art der Eingabemethode setzt allerdings voraus, dass die Maschine den Nutzer versteht und dessen\\r\\nunstrukturierte Eingabe in eine fu\\xcc\\x88r den Computer versta\\xcc\\x88ndliche Struktur u\\xcc\\x88berfu\\xcc\\x88hrt. Mit\\r\\ndiesem Vorgehen ko\\xcc\\x88nnen sowohl Angebote als auch Nachfragen ohne mehrere Formularfelder auskommen, da nicht mehr fu\\xcc\\x88r jedes Attribut ein eigenes Feld beno\\xcc\\x88tigt wird. Ein\\r\\nweiterer Vorteil dieses Vorgehens ist, dass eine eins zu eins Umsetzung zu Sprachassistenten mo\\xcc\\x88glich ist. Dazu wird die Sprache von einem bereits existierenden Assistenten (z.B.\\r\\nAmazon Alexa oder Google Assistant) erkannt und als Textform an das System u\\xcc\\x88bergeben.\\r\\nDurch den Einsatz von solchen Technologien ergeben sich Mehrwerte fu\\xcc\\x88r Unternehmen, da\\r\\nKunden bessere Vorschla\\xcc\\x88ge gemacht werden ko\\xcc\\x88nnen und diese somit ha\\xcc\\x88ufiger zum Kaufen\\r\\nangeregt werden. Auch kann durch die optimale Voraussetzung eines Sprachassistenten\\r\\neine bequeme Alternative geboten werden, wodurch die Plattform ha\\xcc\\x88ufiger verwendet\\r\\nund das Unternehmen attraktiver wird. Der Einsatz von virtuellen Marktpla\\xcc\\x88tzen erfordert ein System, welches die Anwender sowie ihre Bedu\\xcc\\x88rfnisse versteht und somit von\\r\\nNutzern verwendet wird. Zudem werden weitere Informationen der Waren beno\\xcc\\x88tigt, damit die Eingabe auf diese Attribute gepru\\xcc\\x88ft werden kann. Um diese Herausforderungen\\r\\nanzugehen, ko\\xcc\\x88nnten Technologien wie Natural Language Processing (NLP) oder Machine\\r\\nLearning (ML) verwendet werden.\\r\\n\\r\\n1.2. Ziel der Arbeit\\r\\nZiel dieser Arbeit ist es, ein Konzept und Prototyp fu\\xcc\\x88r einen virtuellen Marktplatz mit\\r\\nnatu\\xcc\\x88rlicher Sprachverarbeitung zu entwickeln anhand dessen die Bedienbarkeit und Performance untersucht wird. Im Vordergrund steht dabei das Erkennen bzw. Klassifizieren der\\r\\nAttribute aus einer Eingabesequenz. Jede Produktkategorie verfu\\xcc\\x88gt u\\xcc\\x88ber eigene Attribute,\\r\\ndie von einem solchen System erkannt werden mu\\xcc\\x88ssen. Zu Beginn werden diese reduziert\\r\\nund auf die Produktkategorie der Smartphones mit den Attributen: Produkt, Hersteller,\\r\\nPreis, Farbe, Kamera und Speicher beschra\\xcc\\x88nkt. Zudem wurde als Beispiel ein virtueller\\r\\nMarktplatz in Form eines Chatrooms betrachtet, was bedeutet, dass keine grammatikalisch, korrekte Schreibweise den Anfragen vorausgesetzt wird. Die Anwendung sollte in der\\r\\nLage sein, sowohl Abku\\xcc\\x88rzungen als auch Emojis handhaben zu ko\\xcc\\x88nnen, was eine gro\\xcc\\x88\\xc3\\x9fere\\r\\nHerausforderung an die Algorithmen stellt. Fu\\xcc\\x88r ein besseres Versta\\xcc\\x88ndnis kann folgendes\\r\\nBeispiel betrachtet werden: \\xe2\\x80\\x9cHiiii, lz woche ist mein handy kaputt gegangen :( ich suche\\r\\ndeshalb jetzt ein iphone x gerne auch gebraucht aber nicht teurer als 500 e\\xe2\\x80\\x9d. In diesem\\r\\n\\r\\n2\\r\\n\\r\\n\\x0cKapitel 1\\r\\n\\r\\nEinleitung\\r\\n\\r\\nSzenario sollte das System \\xe2\\x80\\x9ciphone x\\xe2\\x80\\x9d als Produkt und \\xe2\\x80\\x9c500 e\\xe2\\x80\\x9d als Preis erkennen. Anwendern soll das Gefu\\xcc\\x88hl vermittelt werden, als wu\\xcc\\x88rde das System sie verstehen. Dieses\\r\\nsoll zudem mit einer geringen Menge von Daten erreicht werden.\\r\\nBeschrieben wird dieses Verhalten durch die Forschungsfrage (FF1 ): \\xe2\\x80\\x9cWie kann aus\\r\\nnatu\\xcc\\x88rlicher unstrukturierter menschlicher Eingabe eine strukturierte Ausgabe erzeugt werden, die von einem Computer weiterverarbeitet werden kann?\\xe2\\x80\\x9d. Begleitend dazu werden\\r\\ndie folgenden Nebenfragen (NF1 ) beachtet: \\xe2\\x80\\x9cWie kann ein akzeptables Ergebnis mit einer\\r\\nsehr geringen Menge von Daten erzielt werden?\\xe2\\x80\\x9d und (NF2 ) \\xe2\\x80\\x9cWie ko\\xcc\\x88nnen die wichtigsten Schlu\\xcc\\x88sselwo\\xcc\\x88rter aus einem Text ausgewertet werden?\\xe2\\x80\\x9d. Um dies zu erreichen werden\\r\\nverschiedene Methoden und Tools untersucht.\\r\\n\\r\\n1.3. Gliederung\\r\\nIn Kapitel 2 werden die verwendeten Techniken und Modelle zum Erreichen des Ziels dieser\\r\\nArbeit vorgestellt. Kapitel 3 beginnt mit einer ausfu\\xcc\\x88hrlichen Betrachtung der Annahmen,\\r\\ngefolgt von den Abschnitten: Anforderungen, Komponenten, Prozesse und Bewertungskriterien. Im Anschluss wird in Kapitel 4 eine Pipeline konzipiert, die verschiedenen Algorithmen auf das Problem anwendet. Parallel zur Entwicklung der Pipeline wurde ein\\r\\nPrototyp erstellt, der mehrere Aufgaben erfu\\xcc\\x88llt: einfacheres Sammeln von Daten, visuell\\r\\nunterstu\\xcc\\x88tzte Bedienung der Pipeline, sowie das Aufstellen von Metriken bezu\\xcc\\x88glich der\\r\\nPipeline. Die Implementierung des Prototyps wird im Abschnitt 4.5 beschrieben. Eine\\r\\nausfu\\xcc\\x88hrliche Betrachtung bezu\\xcc\\x88glich der Performance des Prototyps sowie Auswertung der\\r\\nOberfla\\xcc\\x88che wird in Kapitel 5 erla\\xcc\\x88utert. Zum Abschluss wird in Kapitel 6 das Ergebnis\\r\\nzusammengefasst und weitere zuku\\xcc\\x88nftige mo\\xcc\\x88gliche Erweiterungen werden in Kapitel 7\\r\\nvorgestellt.\\r\\n\\r\\n3\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\n2. Grundlagen\\r\\nIn diesem Kapitel werden die verwendeten Technologien und theoretischen Grundlagen\\r\\nvorgestellt, welche bei der Bearbeitung dieser Arbeit verwendet wurden. Zu Beginn werden\\r\\nWord Embeddings erla\\xcc\\x88utert, welche ein wesentlicher Bestandteil dieser Arbeit darstellen.\\r\\nIm Anschluss werden die relevanten Eigenschaften der Modelle aus dem Bereich Machine\\r\\nLearning (ML) vorgestellt.\\r\\n\\r\\n2.1. Bag\\xe2\\x80\\x93of\\xe2\\x80\\x93words\\r\\nSa\\xcc\\x88tze bzw. Wo\\xcc\\x88rter ko\\xcc\\x88nnen nicht direkt von einem Computer verstanden werden. Dieser\\r\\nbeno\\xcc\\x88tigt eine andere Repra\\xcc\\x88sentation, um den Inhalt des Satzes zu verstehen. Wenn zum\\r\\nBeispiel die beiden Sa\\xcc\\x88tze: \\xe2\\x80\\x9cDas Wetter heute ist scho\\xcc\\x88n\\xe2\\x80\\x9d und \\xe2\\x80\\x9cDas Wetter heute ist toll\\xe2\\x80\\x9d\\r\\nbetrachtet werden, ergibt sich ein Vokabular mit den Worten: [Das, Wetter, heute, ist,\\r\\nscho\\xcc\\x88n, toll]. Das Vokabular muss alle Wo\\xcc\\x88rter umfassen, die vom System erkannt werden\\r\\nsollen. Mit der \\xe2\\x80\\x9cBag\\xe2\\x80\\x93of\\xe2\\x80\\x93words\\xe2\\x80\\x9d Codierung ko\\xcc\\x88nnen die beiden Sa\\xcc\\x88tze fu\\xcc\\x88r den Computer\\r\\nversta\\xcc\\x88ndlich gemacht werden (Deepu, Raj und Rajaraajeswari 2016). Dazu wird ein leerer\\r\\nVektor der Dimension entsprechend der La\\xcc\\x88nge des Vokabulars erstellt und mit 0 gefu\\xcc\\x88llt,\\r\\njede Position entspricht somit einem Wort. Im Anschluss wird fu\\xcc\\x88r jedes Wort der Eingabe\\r\\ngepru\\xcc\\x88ft, an welcher Position es sich befindet und diese Stelle im Vektor inkrementiert. Fu\\xcc\\x88r\\r\\ndie beiden Beispielsa\\xcc\\x88tze wu\\xcc\\x88rde die \\xe2\\x80\\x9cBag\\xe2\\x80\\x93of\\xe2\\x80\\x93words\\xe2\\x80\\x9d Codierung so aussehen: [1, 1, 1, 1, 1,\\r\\n0] und [1, 1, 1, 1, 0, 1]. Der Nachteil dieser Repra\\xcc\\x88sentation ist, dass die Reihenfolge der\\r\\nWo\\xcc\\x88rter verloren geht und somit keine Beziehungen mehr erkannt werden ko\\xcc\\x88nnen. Auch\\r\\nko\\xcc\\x88nnen a\\xcc\\x88hnliche Bedeutungen bei verschiedenen Wo\\xcc\\x88rtern nicht abgebildet werden, was\\r\\nbedeutet die Worte wie: \\xe2\\x80\\x9cscho\\xcc\\x88n\\xe2\\x80\\x9d und \\xe2\\x80\\x9ctoll\\xe2\\x80\\x9d genauso verschieden sind wie \\xe2\\x80\\x9cWetter\\xe2\\x80\\x9d und\\r\\n\\xe2\\x80\\x9cheute\\xe2\\x80\\x9d.\\r\\n\\r\\n2.2. Word Embeddings\\r\\nWord Embeddings bestehen aus vielen Wortvektoren (Schu\\xcc\\x88tze und Pedersen 1995) die\\r\\nWo\\xcc\\x88rter fu\\xcc\\x88r den Computer versta\\xcc\\x88ndlich darstellen. Mit Wortvektoren wird versucht die\\r\\nBeziehungen der Wo\\xcc\\x88rter zueinander beizubehalten und das Wort durch einen Vektor zu\\r\\nrepra\\xcc\\x88sentieren. Dabei liegen Wo\\xcc\\x88rter mit a\\xcc\\x88hnlicher Bedeutung im Vektorraum nah zusammen, wohingegen Wo\\xcc\\x88rter mit unterschiedlicher Bedeutung weit auseinander liegen.\\r\\nDie Dimension des Vektors spiegelt die Genauigkeit des Word Embeddings wieder. Eine\\r\\ngro\\xcc\\x88\\xc3\\x9fere Dimension beschreibt jedes Wort genauer, beno\\xcc\\x88tigt aber auch mehr Speicherplatz\\r\\nsowie mehr Zeit zum Erstellen der Vektoren. Zum Erstellen der Wortvektoren ko\\xcc\\x88nnen\\r\\n\\r\\n4\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\nverschiedene Verfahren verwendet werden (Perone, Silveira und Paula 2018). Die Verfahren Word2Vec und Global Vectors (GloVe) erzeugen pro Wort einen kontextbasierten\\r\\nWortvektor. Die Embeddings from Language Models (ELMo) Repra\\xcc\\x88sentation kann fu\\xcc\\x88r\\r\\nein Wort mehrere Wortvektoren erstellen um verschiedene Kontexte abzubilden.\\r\\n\\r\\n2.2.1. Word2Vec\\r\\nWord2vec (Tomas Mikolov u. a. 2013) ist ein Verfahren, das Algorithmen verwendet die\\r\\nbasierend auf dem Kontext einer Eingabe einen numerischen Vektor erzeugen. Im Gegensatz zu Bag\\xe2\\x80\\x93of\\xe2\\x80\\x93words (BoW) erhalten damit verschiedene Wo\\xcc\\x88rter in demselben Kontext\\r\\neinen a\\xcc\\x88hnlichen Vektor. Dazu werden vier Schritte beno\\xcc\\x88tigt (Goldberg und Levy 2014).\\r\\nAls Erstes werden die Daten fu\\xcc\\x88r eine unu\\xcc\\x88berwachte Vorhersage vorbereitet, also Eingabe\\r\\nund Ziel der Vorhersage als Tupel. Betrachtet wird dieser Satz: \\xe2\\x80\\x9cAls es an der Tu\\xcc\\x88r klingelte, rannte der Hund los.\\xe2\\x80\\x9d, die ersten Tupel wa\\xcc\\x88ren [als, es], [es, als] und [es, an]. Es wird\\r\\nu\\xcc\\x88ber jedes Wort der Eingabe iteriert, dass aktuelle Wort ist dabei immer der erste Wert\\r\\nin dem Tupel. Die Fenstergro\\xcc\\x88\\xc3\\x9fe gibt an, wie viele Wo\\xcc\\x88rter vor und nach dem aktuellen\\r\\nWort beachtet werden sollen (hier Fenstergro\\xcc\\x88\\xc3\\x9fe = 1). Die betrachteten Wo\\xcc\\x88rter durch die\\r\\nFenstergro\\xcc\\x88\\xc3\\x9fe bilden den zweiten Wert des Tupel. Ein gro\\xcc\\x88\\xc3\\x9feres Fenster bringt bessere Performance zulasten der Berechnungszeit. Im Anschluss wird eine Matrix erstellt, die fu\\xcc\\x88r\\r\\njedes Wort der gesamten Trainingsdaten einen zufa\\xcc\\x88llig erstellten Wortvektor bereitstellt.\\r\\nDann folgt die Optimierung durch das neuronale Netzwerk. Dazu werden die Tupel einzeln verarbeitet und fu\\xcc\\x88r die Eingabe wird der Wortvektor aus der Matrix verwendet. Das\\r\\nNetz berechnet basierend auf der Eingabe eine Vorhersage des na\\xcc\\x88chsten Wortes, welches\\r\\nmit dem tatsa\\xcc\\x88chlichen na\\xcc\\x88chsten Wort verglichen wird. Basierend auf dem Ergebnis wird\\r\\nsowohl das Netz als auch der Wortvektor optimiert. Nach dem Training wird die Matrix\\r\\ngespeichert und kann als Word Embedding verwendet werden.\\r\\n\\r\\n2.2.2. GloVe\\r\\nEin Nachteil der Word2Vec Repra\\xcc\\x88sentation ist, dass diese nur die umliegenden lokalen\\r\\nWo\\xcc\\x88rter betrachtet, um daraus die Wortvektoren zu erstellen. Fu\\xcc\\x88r den Satz \\xe2\\x80\\x9cDer\\r\\nHund spielt auf der Couch.\\xe2\\x80\\x9d ist nicht eindeutig ob \\xe2\\x80\\x9cder\\xe2\\x80\\x9d in besonderer Beziehung zu\\r\\n\\xe2\\x80\\x9cHund\\xe2\\x80\\x9d und \\xe2\\x80\\x9cCouch\\xe2\\x80\\x9d steht oder ob es sich bei \\xe2\\x80\\x9cder\\xe2\\x80\\x9d um ein Stoppwort handelt. Global\\r\\nVectors (GloVe) betrachtet beide Repra\\xcc\\x88sentationen, die globale sowie lokale Sicht. Wie\\r\\nvon (Pennington, Socher und Manning 2014) wird das Vokabular der Trainingsdaten in\\r\\neiner co\\xe2\\x80\\x93occurrence Matrix abgebildet. Eine beispielhafte co\\xe2\\x80\\x93occurrence Matrix kann der\\r\\nAbbildung 1 entnommen werden. Durch ein stochastisches Verfahren la\\xcc\\x88sst sich berechnen\\r\\nwie relevant ein Wort zu einem gegebenen anderen Wort ist. Dabei gilt, dass ein hoher\\r\\n\\r\\n5\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\nWert (>1) eine hohe Relevanz und ein niedriger Wert (<1) irrelevantes Verhalten\\r\\nrepra\\xcc\\x88sentiert.\\r\\n\\r\\nAbbildung 1: Die co\\xe2\\x80\\x93occurrence Matrix fu\\xcc\\x88r den Satz \\xe2\\x80\\x9dHeute gibt es Kuchen da es regnet\\xe2\\x80\\x9dmit einer Fenstergro\\xcc\\x88\\xc3\\x9fe von 1\\r\\n\\r\\n2.2.3. ELMo\\r\\nNeuronale Netze beno\\xcc\\x88tigen eine spezielle Darstellung von Wo\\xcc\\x88rtern. Bei Word Embeddings\\r\\nwird die Semantik von Wo\\xcc\\x88rtern in Form von Vektoren dargestellt. Ein bei diesem Ansatz\\r\\nnicht beachtetes Problem ist die Tatsache, dass ein Wort in unterschiedlichen Kontexten\\r\\nverschiedene Bedeutungen haben kann. \\xe2\\x80\\x9cFu\\xcc\\x88r meine Familie suche ich ein neues Schloss\\r\\nzum Wohnen\\xe2\\x80\\x9d und \\xe2\\x80\\x9cFu\\xcc\\x88r meine Tu\\xcc\\x88r suche ich ein neues Schloss\\xe2\\x80\\x9d, in beiden Sa\\xcc\\x88tzen wird\\r\\ndas Wort \\xe2\\x80\\x9cSchloss\\xe2\\x80\\x9d verwendet, aber die Bedeutung ist offensichtlich eine andere. Einfache\\r\\nWortvektoren wie die vorgestellten GloVe und Word2Vec sind nicht in der Lage den\\r\\nUnterschied dieser Wo\\xcc\\x88rter zu erkennen, sie ha\\xcc\\x88tten dieselbe Bedeutung.\\r\\nUm dieses Verhalten besser abbilden zu ko\\xcc\\x88nnen, werden contextualized word\\xe2\\x80\\x93embeddings\\r\\n(Peters, Neumann, Iyyer u. a. 2018) verwendet. Anders als bei einfachen Word Embeddings, wird eine ganze Sequenz anstelle eines einzelnen Wortes eingegeben. Dadurch ist\\r\\ndas Modell in der Lage, den Kontext der einzelnen Wo\\xcc\\x88rter zu ermitteln und kann so genauere Wortvektoren zuru\\xcc\\x88ckgeben. Wie bereits bei den Word Embeddings werden diese\\r\\nModelle nur in Ausnahmefa\\xcc\\x88llen selbst trainiert. Die beno\\xcc\\x88tigte Datenmenge, sowie die Zeit\\r\\num diese Vektoren zu berechnen ist sehr gro\\xc3\\x9f (Peters, Neumann, Zettlemoyer u. a. 2018).\\r\\nDeshalb wird auf vortrainierte Modelle zuru\\xcc\\x88ckgegriffen, welche dann auf den eigenen Anwendungsfall optimiert werden.\\r\\nZum Erstellen der Embeddings from Language Models (ELMo) wird ein Modell verwendet, dessen Aufgabe darin besteht, das na\\xcc\\x88chste Wort einer Sequenz vorherzusagen. Diese\\r\\nAufgabe kann unu\\xcc\\x88berwacht ausgefu\\xcc\\x88hrt werden und vereinfacht somit das Trainieren. Das\\r\\n\\r\\n6\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\nModell setzt dabei auf bidirectional Long Short\\xe2\\x80\\x93Term Memory (biLSTM) um ein Gefu\\xcc\\x88hl\\r\\nder vorherigen sowie nachfolgenden Wo\\xcc\\x88rter zu erhalten. Zum Erstellen der endgu\\xcc\\x88ltigen\\r\\nWortvektoren werden die Ergebnisse der einzelnen biLSTM Zellen verwendet. Im ersten\\r\\nSchritt werden die Ergebnisse aus der Vorhersagerichtung sowie der Ru\\xcc\\x88ckrichtung verkettet. Im Anschluss werden die Vektoren mit einer Gewichtung des Modells multipliziert\\r\\nund zum Schluss summiert. Das Ergebnis ist ein kontextsensitives Word Embedding jedes\\r\\nWortes eines Satzes.\\r\\n\\r\\nAbbildung 2: Beispielhafte Visualisierung der Wortvektoren fu\\xcc\\x88r das Wort Schloss\\r\\nAbbildung 2 zeigt eine stark vereinfachte Visualisierung des Word Embedding. Der Wortvektor fu\\xcc\\x88r das Wort \\xe2\\x80\\x9cSchloss\\xe2\\x80\\x9d ist, basierend auf den Kontext, verschieden. Wortvektoren\\r\\nko\\xcc\\x88nnen beliebig viele Dimensionen haben, weshalb dieses eine vereinfachte Darstellung\\r\\nist.\\r\\n\\r\\n2.3. Convolutional Neural Network\\r\\nUm eine genauere Vorhersage u\\xcc\\x88ber die Bedeutung der Worte treffen zu ko\\xcc\\x88nnen, ist die Betrachtung des Kontextes hilfreich. Es gibt verschiedene modellbasierte Ansa\\xcc\\x88tze, um diesen\\r\\nKontext zu erfassen. Fu\\xcc\\x88r die Convolutional Neural Network (CNN) liegt der Schwerpunkt\\r\\nin der Bildverarbeitung (Krizhevsky, Sutskever und Hinton 2012). Die Pixelwerte eines\\r\\nBildes werden verwendet, um daraus Vorhersagen zu treffen, was auf dem Bild zu erkennen ist. Um dieses Ziel zu erreichen werden einfache, Hardware unterstu\\xcc\\x88tzte Verfahren\\r\\nverwendet, die im Folgenden vorgestellt werden. Generell bestehen CNN aus den drei\\r\\nfolgenden, miteinander verknu\\xcc\\x88pften Ebenen (Kalchbrenner, Grefenstette und Blunsom\\r\\n2014):\\r\\nEine Faltungsebene, bei der die Eingabematrix mit Hilfe eines Filterkerns auf eine kleinere Matrix reduziert wird, z.B. 5 x 5 als Eingabematrix, 3 x 3 als Filterkern bei einer\\r\\nSchrittweite von 1 erzeugt eine 3 x 3 Matrix. Dazu wird der Filterkern u\\xcc\\x88ber die Eingabematrix um die Schrittweite verschoben. Bei jedem Schritt werden die u\\xcc\\x88bereinander\\r\\nliegende Werte der Filter- und Eingabematrix multipliziert und anschlie\\xc3\\x9fend alle Werte\\r\\n\\r\\n7\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\naddiert, um den neuen Wert der Ergebnismatrix zu erhalten.\\r\\nDurch Reduzieren der Matrix und Beibehalten der wesentlichen Informationen verringert\\r\\ndie Pooling\\xe2\\x80\\x93Schicht die Anzahl der Parameter fu\\xcc\\x88r die folgenden Ebenen. Dies wird durch\\r\\nUnterteilung der Eingabematrix erreicht. Die Werte der einzelnen Abschnitte werden auf\\r\\nverschiedene Arten verarbeitet, wie z.B. Durchschnitts\\xe2\\x80\\x93Pooling oder Max\\xe2\\x80\\x93Pooling. Bei\\r\\ndem Durchschnitts\\xe2\\x80\\x93Pooling wird der Durchschnitt der Werte eines Abschnitts gebildet\\r\\nund als neuer Wert in die Ergebnismatrix eingetragen. Bei Max\\xe2\\x80\\x93Pooling wird der maximale Wert eines Abschnittes u\\xcc\\x88bernommen.\\r\\nDie vollsta\\xcc\\x88ndig verbundene Schicht bildet die vorletzte Ebene eines CNN und ist eine\\r\\nnormale neuronale Netzstruktur. Die Matrix der vorherigen Schicht wird ausgerollt und\\r\\nan die Eingabe\\xe2\\x80\\x93Neuronen u\\xcc\\x88bergeben. Diese sind jeweils mit den Neuronen der na\\xcc\\x88chsten\\r\\nSchicht vollsta\\xcc\\x88ndig verknu\\xcc\\x88pft, bis eine Verbindung zu den Ausgabe\\xe2\\x80\\x93Neuronen besteht.\\r\\nZuletzt wird die Aktivierungsfunktion z.B. Softmax aufgerufen. Softmax\\xe2\\x80\\x93Aktivierung\\r\\nsorgt dafu\\xcc\\x88r, dass alle Werte der Ausgabe\\xe2\\x80\\x93Neuronen sich zu 1 addieren und so die Wahrscheinlichkeit der jeweiligen Ausgabe repra\\xcc\\x88sentieren.\\r\\n\\r\\n8\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\nAbbildung 3: Visualisierung eines CNN\\xe2\\x80\\x93Modells zur Satz Klassifizierung (Zhang und Wallace 2015)\\r\\nAbbildung 3 zeigt, wie Convolutional Neural Networks in der Sprachverarbeitung verwendet werden ko\\xcc\\x88nnen. Die Eingabe muss dafu\\xcc\\x88r in Form einer Matrix vorhanden sein.\\r\\nTexte mu\\xcc\\x88ssen zum Erfu\\xcc\\x88llen dieses Kriteriums zuna\\xcc\\x88chst vorverarbeitet werden. Wie im\\r\\nAbschnitt 2.2 beschrieben, ko\\xcc\\x88nnen Wo\\xcc\\x88rter auch als Vektoren repra\\xcc\\x88sentiert werden. Fu\\xcc\\x88r\\r\\njedes Wort der Eingabe wird der zugeho\\xcc\\x88rige Vektor verwendet. Die resultierende Matrix\\r\\nhat die Gro\\xcc\\x88\\xc3\\x9fe n x m, wobei n der La\\xcc\\x88nge des Satzes und m der Dimension des Wortvektors entspricht. Der Filterkern, der in der Faltungsebene angewendet wird, umfasst alle\\r\\nDimensionen der Wortvektoren in x\\xe2\\x80\\x93Richtung. Die y\\xe2\\x80\\x93Richtung umfasst typischerweise 2\\r\\n\\xe2\\x80\\x93 5 Wo\\xcc\\x88rter. Die nachfolgenden Schichten funktionieren wie fu\\xcc\\x88r Pixel bereits beschrieben.\\r\\nIm letzten Schritt wird die Eingabe in Wahrscheinlichkeitswerten den mo\\xcc\\x88glichen Klassen\\r\\nzugewiesen.\\r\\n\\r\\n9\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\n2.4. Recurrent Neural Network\\r\\nIn vielen Fa\\xcc\\x88llen der Sprachverarbeitung ist der Kontext der Eingabe essenziell fu\\xcc\\x88r das\\r\\nErzielen des gewu\\xcc\\x88nschten Ergebnisses. Um diesen Kontext in einem neuronalen Netz darstellen zu ko\\xcc\\x88nnen, muss eine gewisse Abha\\xcc\\x88ngigkeit bei den Eingabe\\xe2\\x80\\x93Neuronen gegeben\\r\\nsein. Bei anderen neuronalen Netzen agieren die Neuronen unabha\\xcc\\x88ngig voneinander. In\\r\\nder aktuellen Verarbeitung wird der vorherigen Eingabe sowie deren Ergebnis keine Bedeutung zuteil. Recurrent Neural Networks (RNNs) nach (Toma\\xcc\\x81s\\xcc\\x8c Mikolov u. a. 2010)\\r\\nbeziehen diese Informationen der vorherigen Schritte in die folgenden Verarbeitungen mit\\r\\nein um ein kontextsensitives Ergebnis zu erzielen. Um die vorherige Sequenz von Wo\\xcc\\x88rtern\\r\\nmit einzubeziehen ist die grundlegende Architektur von RNN eine Schleife.\\r\\n\\r\\nAbbildung 4: Ausgerollte Darstellung eines RNN\\xe2\\x80\\x93Modells (Olah 2015)\\r\\nWie in der Abbildung 4 zu erkennen ist, wird zuna\\xcc\\x88chst das erste Wort der Sequenz als\\r\\nEingabe an das RNN u\\xcc\\x88bergeben. Das Netz berechnet basierend auf der Eingabe ein Ergebnis, welches zusa\\xcc\\x88tzlich mit dem na\\xcc\\x88chsten Wort der Sequenz erneut an das Modell gegeben\\r\\nwird. Dieser Prozess wiederholt sich bis das letzte Wort der Sequenz verarbeitet wurde\\r\\nund ein endgu\\xcc\\x88ltiges Ergebnis entsteht. Durch dieses Verfahren ist das Ergebnis abha\\xcc\\x88ngig\\r\\nvon dem vorherigen Ergebnis, welches wiederum selbst abha\\xcc\\x88ngig von seinem vorherigen\\r\\nErgebnis ist. Dadurch wird die gesamte Sequenz beachtet. Diese Art der Struktur la\\xcc\\x88sst\\r\\nsich auch als Weiterleitung mit Speicherfunktion betrachten.\\r\\nZum Anwenden von RNN\\xe2\\x80\\x93Modellen werden die Wo\\xcc\\x88rter der Eingabesequenz in Vektoren\\r\\numgewandelt. Dafu\\xcc\\x88r ko\\xcc\\x88nnen verschiedene Repra\\xcc\\x88sentationen verwendet werden, welche bereits im Abschnitt Word Embeddings vorgestellt wurden. Die Sequenz von Vektoren wird\\r\\nnacheinander von dem RNN verarbeitet. Dazu wird der Vektor der Eingabe mit dem vorherigen Ergebnis verbunden und der entstehende Vektor wird in die Aktivierungsfunktion\\r\\nTangens hyperbolicus (Tanh) gereicht. Die Funktion Tanh sorgt dafu\\xcc\\x88r, dass die Werte\\r\\nin dem Vektor zwischen -1 und +1 bleiben, da ohne diese Funktion einzelne Werte eine\\r\\nzu starke Gewichtung bekommen und die u\\xcc\\x88brigen Werte keine Auswirkung haben. Das\\r\\n\\r\\n10\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\nErgebnis der Tanh Funktion ist die Ausgabe fu\\xcc\\x88r den Schritt, der in der na\\xcc\\x88chsten Iteration\\r\\nwieder als Eingabe verwendet wird.\\r\\nEin Nachteil dieses Modells ist das Trainieren, da jede Eingabe von demselben Modell verarbeitet wird. So haben la\\xcc\\x88ngere Sequenzen, bei denen das Ergebnis u\\xcc\\x88ber den hinteren Teil\\r\\nder Eingabe entschieden wird, mehr Einfluss auf die Bewertung der einzelnen Neuronen\\r\\nals Wo\\xcc\\x88rter zu Beginn der Sequenz. Dadurch entsteht ein Ungleichgewicht und Sequenzen\\r\\nmit stark variierender La\\xcc\\x88nge werden von dem Modell nur schwer bis gar nicht erlernt.\\r\\nDieses Problem ist unter dem Namen vanishing gradient problem bekannt. Der Gradient,\\r\\nder fu\\xcc\\x88r das Lernen verantwortlich ist, wird durch backpropagation so weit verkleinert, bis\\r\\ndieser keine Auswirkung mehr auf die Gewichtung der Neuronen nimmt. Durch diesen\\r\\nEffekt ist das Modell nicht in der Lage Neues zu erlernen.\\r\\n\\r\\n2.5. Unterschiede RNN und CNN\\r\\nAuf den ersten Blick wirken RNNs und CNNs identisch, da beide den Kontext der Eingabe betrachten. Der wesentliche Unterschied ist, dass RNNs nur aus einer Schicht bestehen\\r\\nund das Ergebnis der vorherigen Berechnung als Eingabe fu\\xcc\\x88r das na\\xcc\\x88chste Wort betrachten.\\r\\nRNNs werden meistens fu\\xcc\\x88r die Bearbeitung von Sequenzen verwendet. Bei CNNs wird die\\r\\nEingabe durch mehrere Schichten verarbeitet und es werden direkt mehrere Wo\\xcc\\x88rter in\\r\\neinem Durchlauf betrachtet. Durch dieses Vorgehen wird der lokale, umliegende Kontext\\r\\nberu\\xcc\\x88cksichtigt und nicht die gesamte Eingabe. Der Hauptanwendungsbereich dieses Modells liegt in der Bildverarbeitung. In der Arbeit von (Bai, Kolter und Koltun 2018) wurde\\r\\ngezeigt, dass RNNs durch CNNs ersetzt werden ko\\xcc\\x88nnen und diese bei Sequenzmodellierung deutlich bessere Ergebnisse erzielen als die betrachteten RNN\\xe2\\x80\\x93Modelle.\\r\\n\\r\\n2.6. Long Short\\xe2\\x80\\x93Term Memory\\r\\nRNN\\xe2\\x80\\x93Modelle haben Schwierigkeiten, die Informationen der la\\xcc\\x88ngeren Sequenzen von\\r\\nfru\\xcc\\x88heren Schritten bis hin zu den spa\\xcc\\x88teren zu propagieren. Um das Problem zu lo\\xcc\\x88sen\\r\\nwerden Long Short\\xe2\\x80\\x93Term Memory (LSTM)\\xe2\\x80\\x93Modelle (Cummins, Gers und Schmidhuber\\r\\n1999) eingesetzt, welche eine Erga\\xcc\\x88nzung zu RNN darstellen (Sherstinsky 2018). Diese\\r\\nModelle verwenden eine Art Schalter, mit dem reguliert werden kann, ob und welche\\r\\nInformationen gespeichert werden sollen. Mit diesem Vorgehen ko\\xcc\\x88nnen wesentliche Informationen der Sequenz gezielt gespeichert werden. Das Modell bezieht nicht mehr die\\r\\nvolle Sequenz zur Verarbeitung ein, wodurch das Auftreten des vanishing gradient problem\\r\\nreduziert wird.\\r\\n\\r\\n11\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\nDie Architektur des Modells basiert auf der Verwendung von drei Gates. Diese entscheiden was mit der aktuellen Eingabe geschehen soll. Zusa\\xcc\\x88tzlich bietet die Architektur einen\\r\\nZustand, der als Geda\\xcc\\x88chtnis verwendet wird. Wie bereits RNN\\xe2\\x80\\x93Modelle verwenden auch\\r\\nLSTM\\xe2\\x80\\x93Modelle zusa\\xcc\\x88tzlich das vorherige Ergebnis um die Ausgabe zu erzeugen. Als Eingabe wird auch eine Vektor Repra\\xcc\\x88sentation der Wo\\xcc\\x88rter verwendet, wie sie im Abschnitt\\r\\nWord Embeddings erla\\xcc\\x88utert wurde. Alle Gates erhalten die Wortvektoren und das Ergebnis aus der vorherigen Berechnung als Eingabe.\\r\\nFu\\xcc\\x88r jedes Wort einer Sequenz wird das LSTM\\xe2\\x80\\x93Modell aufgerufen und ab dem ersten\\r\\nWort wird der Zustand und das vorherige Ergebnis in die na\\xcc\\x88chste Berechnung u\\xcc\\x88bergeben.\\r\\nDas Forget Gate entscheidet, welche Informationen der vorherigen Schritte behalten\\r\\nwerden. Das Input Gate bestimmt, welche Informationen aktuell relevant sind und im\\r\\nGeda\\xcc\\x88chtniszustand gespeichert werden sollen. Das Output Gate berechnet das Ergebnis,\\r\\nwelches fu\\xcc\\x88r das na\\xcc\\x88chste Wort wiederverwendet wird.\\r\\n\\r\\nAbbildung 5: Verkettung und Aufbau der einzelnen LSTM Elemente (Olah 2015)\\r\\nDas Forget Gate entscheidet welche Informationen beibehalten oder verworfen werden.\\r\\nDazu wird eine Sigmoidfunktion auf den Eingabevektor angewendet, um die Werte des\\r\\nVektors zwischen 0 und 1 abzubilden. Dabei bedeutet eine 1, dass die Informationen\\r\\nbeibehalten und die 0 das diese verworfen werden.\\r\\nBei dem Input Gate wird der Eingabevektor von zwei Aktivierungsfunktionen verarbeitet. Die Sigmoidfunktion entscheidet, welche Informationen wichtig (1) oder unwichtig (0)\\r\\nsind. Die Tanh Funktion reguliert die Werte, damit sich diese zwischen -1 und 1 befinden\\r\\nund sich besser fu\\xcc\\x88r die spa\\xcc\\x88tere Verarbeitung eignen. Im Anschluss werden die Ergebnisvektoren beider Funktionen multipliziert, um einen Vektor zu erhalten.\\r\\nUm den neuen Geda\\xcc\\x88chtniszustand zu berechnen, wird der vorherige Zustand mit dem\\r\\n\\r\\n12\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\nErgebnis des Forget Gates multipliziert. Der daraus resultierende Vektor wird mit dem\\r\\nErgebnis des Input Gates addiert, daraus ergibt sich ein neuer Zustand. Als letztes wird\\r\\ndas Output Gate verwendet. Eine Sigmoidfunktion wird auf den Eingabevektor angewendet, der aktuelle Zustand wird an eine Tanh Funktion gereicht. Die Ergebnisse beider\\r\\nFunktionen werden multipliziert und wird als vorheriges Ergebnis in dem folgenden Schritt\\r\\nwieder verwendet. Das Output Gate berechnet also die Vektoren, die fu\\xcc\\x88r den na\\xcc\\x88chsten\\r\\nSchritt beno\\xcc\\x88tigt werden. Fu\\xcc\\x88r ein besseres Versta\\xcc\\x88ndnis der Elemente kann Abbildung 5\\r\\nbetrachtet werden.\\r\\nEine Erweiterung sind Bidirektionalen Netze (Schuster und Paliwal 1997), welche auch die\\r\\nvorherigen Wo\\xcc\\x88rter fu\\xcc\\x88r die Verarbeitung betrachten. Sowohl LSTM als auch RNN Netze\\r\\nko\\xcc\\x88nnen um die bidirektionale Komponente erweitert werden, um ein besseres Ergebnis\\r\\nzu erzielen. Dazu wird die Anzahl der verwendeten Zellen dupliziert und in umgekehrter Reihenfolge miteinander verbunden. Dadurch wird die Sequenz in beide Richtungen\\r\\nverarbeitet und Beziehungen \\xe2\\x80\\x94 sowohl vor als auch nach dem Wort \\xe2\\x80\\x94 werden beachtet.\\r\\n\\r\\n2.7. Conditional Random Fields\\r\\nConditional Random Field (CRF) sind diskriminierend und modellieren die bedingte\\r\\nWahrscheinlichkeitsverteilung (Lafferty, McCallum und Pereira 2001). Eingesetzt werden\\r\\ndiese Modelle unter anderem in der Bild- und Textverarbeitung. In der grundlegenden\\r\\nFunktionsweise beschreibt das Modell die Abha\\xcc\\x88ngigkeiten sowie Unabha\\xcc\\x88ngigkeiten zwischen zufa\\xcc\\x88lligen Variablen. Diese Variablen bilden einen Graphen, aus dem sich die Wahrscheinlichkeiten berechnen lassen mit der die jeweilige Variable zutrifft. Bei CRF wird die\\r\\nbedingte Wahrscheinlichkeitsverteilung betrachtet, dazu wird die Wahrscheinlichkeit der\\r\\nKlasse Y \\xe2\\x80\\x94 unter der Annahme, dass die Eingabe X gilt \\xe2\\x80\\x94 gesucht (Abbildung 6). Fu\\xcc\\x88r\\r\\nein besseres Versta\\xcc\\x88ndnis wird im folgendem ein Beispiel aus dem Bereich der natu\\xcc\\x88rlichen\\r\\nSprachverarbeitung betrachtet.\\r\\n\\r\\n13\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\nAbbildung 6: Beispielhafte Darstellung eines CRF\\r\\nDie Eingabedaten der CRFs sind sequentiell und der fru\\xcc\\x88here Kontext wird beru\\xcc\\x88cksichtigt\\r\\num eine Vorhersage treffen zu ko\\xcc\\x88nnen. Um dieses Verhalten modellieren zu ko\\xcc\\x88nnen, werden\\r\\nFeature\\xe2\\x80\\x93Funktionen mit vier Eingabewerten verwendet. Diese sind:\\r\\n\\xe2\\x80\\xa2 die Wortvektoren fu\\xcc\\x88r jedes Wort der Eingabe\\r\\n\\xe2\\x80\\xa2 die Position des Wortes, fu\\xcc\\x88r die der Bezeichner bestimmt werden soll\\r\\n\\xe2\\x80\\xa2 die korrekte Bezeichnung des vorherigen Wortes\\r\\n\\xe2\\x80\\xa2 die korrekte Bezeichnung des gesuchten Wortes\\r\\nIm Anschluss wird eine Merkmalsfunktion definiert, die das gewu\\xcc\\x88nschte Verhalten abbildet. Zum Trainieren werden die Gewichtungen zufa\\xcc\\x88llig bestimmt und mit dem Gradientenabstiegsverfahren optimiert bis die Parameterwerte konvergieren. Dieses Verfahren\\r\\nist der logistischen Regression a\\xcc\\x88hnlich, da beide die bedingte Wahrscheinlichkeitsverteilung verwenden. Der Unterschied besteht darin, dass durch die Erweiterung von Feature\\xe2\\x80\\x93\\r\\nFunktionen eine sequenzielle Eingabe mo\\xcc\\x88glich ist.\\r\\n\\r\\n2.8. Fuzzy\\xe2\\x80\\x93Suche\\r\\nDie zweiwertige Logik ermo\\xcc\\x88glicht das Modellieren von Verhalten und umfasst die Wahrheitswerte \\xe2\\x80\\x9cwahr\\xe2\\x80\\x9d und \\xe2\\x80\\x9cfalsch\\xe2\\x80\\x9d. Fuzzylogik erweitert die Menge der Wahrheitswerte (z.B.\\r\\n\\xe2\\x80\\x9cein bisschen\\xe2\\x80\\x9d, \\xe2\\x80\\x9cwenig\\xe2\\x80\\x9d und \\xe2\\x80\\x9csehr\\xe2\\x80\\x9d) um eine unscharfe Beschreibung zu ermo\\xcc\\x88glichen\\r\\n(Zadeh 1965). Abgebildet auf reelle Zahlen bedeutet das die Werte in dem Intervall [0,1].\\r\\nFuzzy (Unscha\\xcc\\x88rfe) ist eine Form der Ungenauigkeit bei der Abbildung eines Sachverhalts.\\r\\n\\r\\n14\\r\\n\\r\\n\\x0cKapitel 2\\r\\n\\r\\nGrundlagen\\r\\n\\r\\nAls Beispiel wird ein Zimmer betrachtet welches zwei Zusta\\xcc\\x88nde haben kann: warm und\\r\\nkalt. Die zweiwertige Logik legt einen Grenzwert fest, ab wann der U\\xcc\\x88bergang zwischen\\r\\nkalt zu warm ist z.B. 20 Grad Celsius. Bei Fuzzylogik wird eine weiche Grenze zwischen\\r\\nden Zusta\\xcc\\x88nden definiert und Werte wie 18,9 Grad Celsius werden beschrieben durch z.B.\\r\\nein bisschen warm oder weniger kalt.\\r\\nBei der unscharfen Suche auf Zeichenketten wird nicht auf die exakte Zeichenfolge, sondern\\r\\na\\xcc\\x88hnliche Zeichenketten gepru\\xcc\\x88ft. Die Levenshtein\\xe2\\x80\\x93Distanz ist ein Verfahren zur Messung\\r\\nder Differenz zwischen zwei Sequenzen (Levenshtein 1966). Die gesamte Distanz setzt\\r\\nsich dabei aus der beno\\xcc\\x88tigten Anzahl von Einfu\\xcc\\x88ge-, Lo\\xcc\\x88sch- und Ersetzung-Operationen\\r\\nzusammen, die beno\\xcc\\x88tigt werden, um ein Wort in das andere zu a\\xcc\\x88ndern. Betrachtet man\\r\\ndie Wo\\xcc\\x88rter \\xe2\\x80\\x9cTier\\xe2\\x80\\x9d und \\xe2\\x80\\x9cTor\\xe2\\x80\\x9d kann der Buchstabe \\xe2\\x80\\x9ci\\xe2\\x80\\x9d durch ein \\xe2\\x80\\x9co\\xe2\\x80\\x9d ersetzt werden und\\r\\ndas \\xe2\\x80\\x9ce\\xe2\\x80\\x9d muss gelo\\xcc\\x88scht werden. Somit betra\\xcc\\x88gt die Levenshtein\\xe2\\x80\\x93Distanz 2. Die Distanz\\r\\nrepra\\xcc\\x88sentiert wie hoch eine U\\xcc\\x88bereinstimmung dieser Wo\\xcc\\x88rter ist. Eine geringe Levenshtein\\xe2\\x80\\x93\\r\\nDistanz bedeutet dabei hohe U\\xcc\\x88bereinstimmung.\\r\\n\\r\\n15\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\n3. Konzeption\\r\\nZiel dieser Arbeit ist es, aus natu\\xcc\\x88rlicher unstrukturierter menschlicher Eingabe eine strukturierte Ausgabe zu erzeugen, die von einem Computer weiterverarbeitet werden kann.\\r\\nHier ko\\xcc\\x88nnte es sich beispielsweise um Empfehlungen von Produkten auf eine Suchanfrage handeln. Dabei ist es wichtig, dass die natu\\xcc\\x88rliche Eingabe des Menschen korrekt\\r\\nverstanden und ausgewertet wird.\\r\\n\\r\\n3.1. Annahmen\\r\\nIm folgendem werden verschiedene Annahmen vorgestellt, die im Rahmen dieser Arbeit\\r\\ngetroffen wurden.\\r\\n1. Annahme: Festlegen der Sprache\\r\\nSprachmodelle die mit mehreren Sprachen interagieren sollen sind wesentlich komplexer. Die Charakteristiken einer Sprache variieren sehr stark, weshalb ein Modell,\\r\\nwelches auf die englische Sprache trainiert wurde, nicht direkt mit deutscher Eingabe bedient werden kann. Um dieser Problematik nicht zu begegnen wird nur die\\r\\ndeutsche Sprache unterstu\\xcc\\x88tzt. Fu\\xcc\\x88r eine Lo\\xcc\\x88sung muss das Modell selbst in der Lage\\r\\nsein, auf die verschiedenen Sprachen zu reagieren oder es wird ein Modell verwendet, welches die eingegebene Sprache ermittelt und abha\\xcc\\x88ngig davon das passende\\r\\nSprachmodell bereitstellt.\\r\\n2. Annahme: Eingrenzung der Doma\\xcc\\x88ne\\r\\nU\\xcc\\x88ber virtuelle Marktpla\\xcc\\x88tze werden sa\\xcc\\x88mtliche Produkte gehandelt, die verschiedensten Attribute besitzen. Im Rahmen dieser Arbeit wird die Doma\\xcc\\x88ne beschra\\xcc\\x88nkt, mit\\r\\nder Mo\\xcc\\x88glichkeit diese nach Belieben zu erweitern. Technologische Artikel sind beliebte Produkte welche ha\\xcc\\x88ufig u\\xcc\\x88ber online Marktpla\\xcc\\x88tzen gehandelt werden, weshalb\\r\\ndie Doma\\xcc\\x88ne zu Beginn auf diese Produkte begrenzt wird. Um diese noch weiter\\r\\neinzuschra\\xcc\\x88nken wurde sich an der Produktgruppe der Smartphones orientiert. Basierend auf dieser Gruppe wurden 6 Attribute \\xe2\\x80\\x94 die ha\\xcc\\x88ufig verwendet werden \\xe2\\x80\\x94\\r\\ngewa\\xcc\\x88hlt, um Smartphones zu beschreiben. Diese sind in der Regel: Produkt, Hersteller, Preis, Farbe, Speicher und Kamera. Das in dieser Arbeit beschriebene Verfahren\\r\\nkann verwendet werden, um weitere Attribute bzw. Produktgruppen zu erga\\xcc\\x88nzen.\\r\\n3. Annahme: Attribute sind zusammenstehend\\r\\nEin bekanntes Problem bei Sprachmodellen ist, dass diese Schwierigkeiten haben\\r\\nAttribute zu bestimmen, bei Wo\\xcc\\x88rtern die nicht zusammenstehen. Aus diesem Grund\\r\\nwird angenommen, dass mehrere Wo\\xcc\\x88rter, die zu einem Attribut geho\\xcc\\x88ren, zusammen\\r\\n\\r\\n16\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\nstehen und nicht von anderen Wo\\xcc\\x88rtern unterbrochen werden. Ein Gegenbeispiel\\r\\ndafu\\xcc\\x88r ist: \\xe2\\x80\\x9cIch suche ein iPhone, am besten das 10.\\xe2\\x80\\x9d, da hier das gesuchte Produkt\\r\\n\\xe2\\x80\\x9ciPhone 10\\xe2\\x80\\x9d nicht zusammenha\\xcc\\x88ngt. Wird diese Annahme nicht getroffen, ko\\xcc\\x88nnte die\\r\\nEingabe durch eine Vorverarbeitung umstrukturiert werden, sodass die Attribute\\r\\nwieder zusammenstehen.\\r\\n4. Annahme: Eingaben sind nur Handelsanfragen\\r\\nEingaben zwischen normaler Konversation und Handelsanfragen zu unterscheiden\\r\\nist ein zusa\\xcc\\x88tzliches Problem, welches nicht im Fokus dieser Arbeit steht. Es wird\\r\\nangenommen, dass jede Eingabe mindestens das Attribut \\xe2\\x80\\x9cProdukt\\xe2\\x80\\x9d entha\\xcc\\x88lt und\\r\\nsomit eine Handelsanfrage darstellt \\xe2\\x80\\x94 dadurch kann sich auf das Klassifizieren der\\r\\nAttribute fokussiert werden. Alternativ mu\\xcc\\x88sste ein zusa\\xcc\\x88tzliches Modell eingesetzt\\r\\nwerden, welches auf die Differenzierung zwischen normaler Konversation und Handelsanfragen trainiert ist.\\r\\n\\r\\n3.2. Anforderungen\\r\\nVirtuelle Marktpla\\xcc\\x88tze werden von Jahr zu Jahr bedeutsamer. Auf elektronischen Marktpla\\xcc\\x88tzen finden viele Ka\\xcc\\x88ufer\\xe2\\x80\\x93Verka\\xcc\\x88ufer Situationen statt. Anwender erstellen ein digitales\\r\\nAngebot, das von potenziellen Ka\\xcc\\x88ufern gefunden werden mo\\xcc\\x88chte. Dieser Ablauf beschreibt\\r\\ngrob einen Anwendungsfall, welcher durch die natu\\xcc\\x88rliche Sprachverarbeitung unterstu\\xcc\\x88tzt\\r\\nwerden soll. Die genauen Abla\\xcc\\x88ufe ko\\xcc\\x88nnten wie folgt aussehen.\\r\\n1. Szenario: Angebotssuche\\r\\nEin Anwender kann eine Anfrage in Form einer Texteingabe an das System stellen.\\r\\nDie Eingabe wird von einer Komponente verarbeitet, in der die wesentlichen Informationen extrahiert werden. Das Ergebnis der Verarbeitung wird mit der Eingabe\\r\\nin einer Datenbank abgespeichert, damit zuku\\xcc\\x88nftige Handelsanfragen diese Anfrage\\r\\nfinden ko\\xcc\\x88nnen. Ebenfalls wird das Ergebnis an eine andere Komponente u\\xcc\\x88bergeben,\\r\\nwelche basierend auf den extrahierten Informationen ein passendes Gegenangebot\\r\\nzuru\\xcc\\x88ckgibt. Dieses wird im Anschluss dem Anwender mit den erkannten Attributen\\r\\naus seiner Eingabe pra\\xcc\\x88sentiert.\\r\\n2. Szenario: Gruppensuche\\r\\nIn einem spezielleren Szenario sucht ein Anwender nach Produkten von einem bestimmten Hersteller, ohne das gesuchte Produkt genau zu spezifizieren. Die Attribute aus der Eingabe werden wie in dem vorherigen Szenario von einer Komponente\\r\\nbestimmt. Die zweite Komponente, welche das passende Gegenangebot ermittelt\\r\\nreagiert auf die Suche nach einer Menge von Produkten. Basierend auf die u\\xcc\\x88brigen\\r\\n\\r\\n17\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\nAttribute der Eingabe wird dem Anwender ein passendes Gegenangebot angezeigt.\\r\\nDiese Szenarien verdeutlichen den Ablauf einer Suche u\\xcc\\x88ber einen virtuellen Marktplatz.\\r\\n3. Szenario: Inserat Erstellung\\r\\nIn dem letzten Szenario erstellt ein Anwender ein Inserat. Die Eingabe wird verarbeitet und das eigene Ergebnis dem Anwender pra\\xcc\\x88sentiert. Dieser entscheidet dann,\\r\\nob die erkannten Attribute korrekt sind. Ist dies nicht der Fall, so soll dem Anwender die Mo\\xcc\\x88glichkeit geboten werden die Attribute in seiner Eingabe manuell zu\\r\\nbestimmen. Im Anschluss werden die Attribute sowie die Eingabe in einer Datenbank gespeichert. Der Nutzer erha\\xcc\\x88lt kein Gegenangebot.\\r\\nAnwender sollen mit dem System interagieren ko\\xcc\\x88nnen. Deshalb wird die direkte Eingabe\\r\\nder Nutzer verwendet, was als natu\\xcc\\x88rliche Eingabe bezeichnet wird. Als Beispiel dafu\\xcc\\x88r wird\\r\\neine virtuelle Verhandlung u\\xcc\\x88ber einen Chat betrachtet in dem Produkte gehandelt werden.\\r\\nJeder Mensch verfu\\xcc\\x88gt u\\xcc\\x88ber eine eigene Art wie er sich in einem Chatroom ausdru\\xcc\\x88ckt,\\r\\nweshalb keine korrekte Rechtschreibung angenommen wird. Auch muss das System in der\\r\\nLage sein mit Abku\\xcc\\x88rzungen sowie Emojis umzugehen. Aus den genannten Anforderungen\\r\\nwird deutlich, welche Funktionen der Prototyp bereitstellen muss. Fu\\xcc\\x88r die ersten beiden\\r\\nAnwendungsfa\\xcc\\x88lle wird eine Oberfla\\xcc\\x88che erwartet, in der ein Anwender Eingaben ta\\xcc\\x88tigen\\r\\nkann und die Mo\\xcc\\x88glichkeit hat eine Antwort zu erhalten. Chatsysteme werden ha\\xcc\\x88ufig bei\\r\\nConsumer\\xe2\\x80\\x93to\\xe2\\x80\\x93Consumer Transaktionen in virtuellen Marktpla\\xcc\\x88tzen eingesetzt, weshalb\\r\\nder Aufbau dem eines Chatrooms a\\xcc\\x88hnlich sein soll. Der Anwender kann seine Anfrage dann\\r\\nin Form einer Nachricht in diesem Chat an das System senden. Wie es in einen Chatroom\\r\\nu\\xcc\\x88blich ist, wird dem Anwender seine eigene Nachricht angezeigt und nach der Verarbeitung\\r\\nauch die Antwort des Systems. Die Verarbeitung darf nicht zu lange dauern, da sonst das\\r\\nInteresse der Anwender verloren geht. In der Oberfla\\xcc\\x88che soll es dem Benutzer mo\\xcc\\x88glich sein,\\r\\nmehrere Anfragen nacheinander an das System zu senden mit der Mo\\xcc\\x88glichkeit weiterhin\\r\\ndie vorherigen Ergebnisse angezeigt zu bekommen. Die Nachrichten des Anwenders und\\r\\nSystems sollten farblich differenzierbar und links bzw. rechtsbu\\xcc\\x88ndig ausgerichtet sein.\\r\\nAnwender sind an diesen Aufbau von anderen Nachrichtensystem vertraut, wodurch der\\r\\nEinstieg in die Bedienung erleichtert wird.\\r\\nFu\\xcc\\x88r das letzte Szenario wird eine andere, simplere Oberfla\\xcc\\x88che verwendet. Es wird keine\\r\\nAntwort von dem System erwartet, weshalb nur die Eingabe des Anwenders im Vordergrund steht. Durch eine Texteingabe wird die Anfrage des Anwenders entgegengenommen\\r\\nund ausgewertet. Der Prototyp stellt im Anschluss die Eingabe mit den gefundenen Attributen sowie der Mo\\xcc\\x88glichkeit das Ergebnis zu besta\\xcc\\x88tigen oder abzulehnen dem Anwender\\r\\ndar. Der Anwendungsfall bietet dem Anwender die Mo\\xcc\\x88glichkeit die eigene Anfrage manuell\\r\\n\\r\\n18\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\nmit Attributen zu versehen. Um diese Funktionalita\\xcc\\x88t anzubieten wird fu\\xcc\\x88r jedes Attribut\\r\\neine Schaltfla\\xcc\\x88che verwendet, mit der die ausgewa\\xcc\\x88hlte Sequenz dem jeweiligen Attribut\\r\\nzugewiesen werden kann. Formalisiert lassen sich aus den Beschreibungen der Szenarien\\r\\nsowie dem Ziel der Arbeit die folgenden Anforderungen erfassen. Die Anforderungen werden mit den Buchstaben FA und NA fu\\xcc\\x88r funktionale bzw. nicht funktionale Anforderungen\\r\\ngekennzeichnet.\\r\\nFA1: Das System muss Eingaben in Form von Handelsanfragen von Anwendern\\r\\nermo\\xcc\\x88glichen.\\r\\nFA2: Das System muss basierend auf die Handelsanfragen passend antworten.\\r\\nFA3: Das System muss den Anwendern die Mo\\xcc\\x88glichkeit bieten, die Eingabe manuell mit\\r\\nAttributen zu versehen.\\r\\nFA4: Das System muss Gruppensuchen ermo\\xcc\\x88glichen und mit einem passenden Angebot\\r\\nreagieren.\\r\\nFA5: Das System muss alle Anfragen persistieren.\\r\\nFA6: Das System muss mit bestimmte Anwenderfehler wie z.B. Rechtschreibfehler umgehen ko\\xcc\\x88nnen.\\r\\nNA1: Aufrufe der Anwender mu\\xcc\\x88ssen schnell (<3 s) verarbeitet und beantwortet werden.\\r\\nNA2: Anwendern wird das Gefu\\xcc\\x88hl vermittelt, von dem System verstanden zu werden.\\r\\nNA3: Die Antworten des Systems sind begru\\xcc\\x88ndet und ko\\xcc\\x88nnen von den Anwendern nachvollzogen werden.\\r\\n\\r\\n19\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\n3.3. Komponenten\\r\\n\\r\\nAbbildung 7: Aufbau der Anwendung mit den Komponenten\\r\\nUm die vorgestellten Szenarien aus Abschnitt 3.2 zu erfu\\xcc\\x88llen werden fu\\xcc\\x88nf Komponenten\\r\\nbeno\\xcc\\x88tigt, um einen Prototyp zu erstellen wie in Abbildung 7 dargestellt. In den folgenden\\r\\nAbschnitten werden die Komponenten genauer vorgestellt.\\r\\n\\r\\n3.3.1. Benutzerschnittstelle\\r\\nDer Prototyp kann mit verschiedenen Oberfla\\xcc\\x88chen realisiert werden z.B. Webanwendung, Desktop\\xe2\\x80\\x93Anwendung, Android\\xe2\\x80\\x93App oder Kommandozeile. Was verwendet wird\\r\\nist abha\\xcc\\x88ngig von dem Ziel, dass der Prototyp verfolgt. Ein Kriterium ist die einfache\\r\\nZuga\\xcc\\x88nglichkeit, sodass viele Anwender den Prototypen problemlos benutzen ko\\xcc\\x88nnen. Am\\r\\neinfachsten zuga\\xcc\\x88nglich ist eine Webanwendung, da diese im Webbrowser aufgerufen werden kann. Die anderen Mo\\xcc\\x88glichkeiten beno\\xcc\\x88tigen eine Installation oder zumindest eine\\r\\nausfu\\xcc\\x88hrbare Projektdatei auf dem Endgera\\xcc\\x88t.\\r\\nDie wesentliche Aufgabe des Prototyps ist es, Text entgegenzunehmen und zu verarbeiten (FA1 ). Aus diesem Grund ist ein weiteres Kriterium die Unterstu\\xcc\\x88tzung der einfachen\\r\\nTexteingabe von der Oberfla\\xcc\\x88che. In Smartphone Apps wird Text meist nur u\\xcc\\x88ber die Bildschirmtastatur eingegeben was umsta\\xcc\\x88ndlicher ist als z.B. an einen Computer. In einer\\r\\nKommandozeilen\\xe2\\x80\\x93Anwendung ist der Umgang mit langen Texteingaben ebenfalls nicht\\r\\noptimal da per Mausklick nicht an die gewu\\xcc\\x88nschte Stelle gesprungen wird.\\r\\nDas na\\xcc\\x88chste Kriterium ist eine leicht versta\\xcc\\x88ndliche Oberfla\\xcc\\x88che, die intuitiv bedient werden\\r\\nkann. Die Oberfla\\xcc\\x88che der Kommandozeile ist nicht benutzerfreundlich, weshalb viele Anwender davor zuru\\xcc\\x88ckschrecken wu\\xcc\\x88rden eine solche Anwendung zu benutzen. Bei Desktop\\xe2\\x80\\x93\\r\\nAnwendungen neigen Entwickler dazu ein komplett eigenes und kein einheitliches Design\\r\\nzu verwenden. Die Folge davon ist, dass Anwender sich erst an die Bedienung gewo\\xcc\\x88hnen\\r\\n\\r\\n20\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\nmu\\xcc\\x88ssen. Bei Webanwendungen und Smartphone Apps wird mehr Wert auf ein einheitliches Design gelegt und sich an bereits existierende Anwendungen orientiert.\\r\\nZum Erstellen dieser Arbeit wird eine Webanwendung erstellt. Webanwendungen bieten\\r\\nden Anwendern eine vertraute Oberfla\\xcc\\x88che, die einfach zu bedienen ist. Webseiten ko\\xcc\\x88nnen\\r\\nvon den meisten Endgera\\xcc\\x88ten aus aufgerufen werden, was die Verwendung von Smartphones miteinschlie\\xc3\\x9ft. Das ha\\xcc\\x88ufige Eingeben von Text wird durch die Verwendung einer\\r\\nComputertastatur erleichtert. Anwender mu\\xcc\\x88ssen keinen Client updaten, um die neueste\\r\\nVersion des Prototyps verwenden zu ko\\xcc\\x88nnen. Es wird ein Server beno\\xcc\\x88tigt, auf dem die\\r\\nWebanwendung ausgefu\\xcc\\x88hrt wird damit diese verfu\\xcc\\x88gbar ist.\\r\\n\\r\\n3.3.2. Hybrid named-entity recognition\\r\\nDie natu\\xcc\\x88rliche Eingabe des Anwenders wird an eine Komponente u\\xcc\\x88bergeben, welche die\\r\\nAttribute bestimmt um spa\\xcc\\x88ter eine passende Antwort generieren zu ko\\xcc\\x88nnen. Bei der erhaltenen Eingabe kann von keiner korrekten Rechtschreibung ausgegangen werden (FA6 ).\\r\\nDie Attribute zeichnen sich durch besondere Charaktereigenschaften aus. So besteht der\\r\\nPreis meist aus einem beschreibenden Wort z.B. \\xe2\\x80\\x9cmindestens\\xe2\\x80\\x9d oder \\xe2\\x80\\x9cmaximal\\xe2\\x80\\x9d gefolgt\\r\\nvon einer Zahl (z.B. 300) mit einer abschlie\\xc3\\x9fenden Einheit (z.B. \\xe2\\x80\\x9ce\\xe2\\x80\\x9d, \\xe2\\x80\\x9ceuro\\xe2\\x80\\x9d). Der strukturelle Aufbau der Attribute SSpeicheru\\xcc\\x88nd \\xe2\\x80\\x9dKamera\\xc4\\xb1\\xcc\\x88st identisch, nur die Einheit ist eine\\r\\nAndere (\\xe2\\x80\\x9cGigabyte (GB)\\xe2\\x80\\x9d bzw. \\xe2\\x80\\x9cMegapixel (MP)\\xe2\\x80\\x9d).\\r\\nAttribute wie Hersteller und Farbe bestehen in den allermeisten Fa\\xcc\\x88llen nur aus einzelnen Wo\\xcc\\x88rtern oder einer kleinen Wortkette z.B. \\xe2\\x80\\x9cApple\\xe2\\x80\\x9d und \\xe2\\x80\\x9chelles grau\\xe2\\x80\\x9d. Das Produkt\\r\\nhingegen besteht nicht nur aus Wo\\xcc\\x88rtern oder Wortketten, sondern es beinhaltet ha\\xcc\\x88ufig\\r\\ngenaue Artikelbezeichnungen, die in Form von Buchstaben konkateniert mit Zahlen dargestellt werden (z.B. \\xe2\\x80\\x9cGalaxy S10\\xe2\\x80\\x9d). Auch ko\\xcc\\x88nnen Produkte den Namen des Herstellers\\r\\nbeinhalten, was das Differenzieren beider Attribute erschwert. Abbildung 8 zeigt eine beispielhafte Eingabe in der die Attribute farblich hervorgehoben wurden: Hersteller (grau),\\r\\nProdukt (blau), Farbe (schwarz), Kamera (tu\\xcc\\x88rkis), Speicher (gelb) und Preis (rot).\\r\\n\\r\\nAbbildung 8: Visuelle Unterstu\\xcc\\x88tzung einer beispielhaften Eingabe\\r\\nAufgrund der unterschiedlichen Eigenschaften der Attribute, wird eine Menge von Algorithmen verwendet, die gemeinsam eine Pipeline bilden. Diese erzeugt aus einer unstruktu-\\r\\n\\r\\n21\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\nrierten Eingabe eine mit korrekten Bezeichnungen versehene Ausgabe. Die Pipeline setzt\\r\\nsich dabei aus unterschiedlichen Algorithmen zusammen, die nacheinander angewendet\\r\\nwerden, um so ein optimales Ergebnis zu erzielen. Der Fokus dieser Arbeit beschra\\xcc\\x88nkt\\r\\nsich auf das Erkennen des Attributes \\xe2\\x80\\x9cProdukt\\xe2\\x80\\x9d, da dieses bei allen Handelsanfragen\\r\\nenthalten sein muss. Die u\\xcc\\x88brigen Attribute (Hersteller, Preis, Farbe, Speicher und Kamera) sollen zeigen, dass eine Erweiterung auf mehrere Attribute mo\\xcc\\x88glich ist. Die einzelnen\\r\\nSchritte der Pipeline sind aufsteigend gewichtet. Das bedeutet, dass die spa\\xcc\\x88teren Schritte\\r\\nTeilergebnisse der vorherigen u\\xcc\\x88berschreiben, weshalb die Sta\\xcc\\x88rken verschiedener Algorithmen kombiniert werden ko\\xcc\\x88nnen. Der Aufbau der Pipeline ermo\\xcc\\x88glicht ein einfaches Hinzufu\\xcc\\x88gen, Verschieben oder Entfernen von Algorithmen, welches Anpassungen an spezielle\\r\\nAnforderungen ermo\\xcc\\x88glicht.\\r\\n\\r\\nAbbildung 9: Aufbau der Pipeline\\r\\nAbbildung 9 zeigt den konzeptionellen Aufbau der Pipeline. Wie zu erkennen besteht die\\r\\nPipeline aus mehreren Bauteilen, die sich auf verschiedene charakteristische Eigenschaften\\r\\nder Attribute fokussieren. Mit diesem Aufbau werden die Sta\\xcc\\x88rken der einzelnen Schritte\\r\\nkombiniert, wodurch die Erkennung optimiert werden kann.\\r\\nDen ersten Schritt bildet ein neuronales Netz, dessen Hauptaufgabe das Erkennen des\\r\\nAttributes \\xe2\\x80\\x9cProdukt\\xe2\\x80\\x9d ist. Es gibt sehr viele verschiedene Produktbezeichnungen mit variierender La\\xcc\\x88nge und Anzahl der Wo\\xcc\\x88rter, sodass neuronale Netze fu\\xcc\\x88r diese Aufgabe beno\\xcc\\x88tigt\\r\\nwerden. Die Netze sind durch Trainieren in der Lage, bestimmte Muster in den verschiedenen Eingaben zu erkennen, die zuvor von Menschen nicht erkannt wurden. Durch die\\r\\nVielzahl von mo\\xcc\\x88glichen Produkten und dem Ziel alle mo\\xcc\\x88glichen Produkte zu erkennen wurde ein einfaches Vergleichsverfahren an dieser Stelle ausgeschlossen. Das System wu\\xcc\\x88rde\\r\\nnur die zuvor definierten Produkte erkennen und neue Produkte mu\\xcc\\x88ssten dauerhaft manuell hinzugefu\\xcc\\x88gt werden was nicht zielfu\\xcc\\x88hrend ist. Das neuronale Netz muss in der Lage\\r\\nsein, Wo\\xcc\\x88rter bzw. ganze Sa\\xcc\\x88tze als Eingabe entgegenzunehmen und eine Wortsequenz \\xe2\\x80\\x94\\r\\ndie dem passenden Attribut zugewiesen wird \\xe2\\x80\\x94 als Ausgabe zu erzeugen.\\r\\nDer na\\xcc\\x88chste Schritt dient zum Erkennen von Attributen, die durch einen regelbasierten\\r\\nAnsatz erkannt werden ko\\xcc\\x88nnen. Einige Attribute wie Preis, Speicher und Kamera folgen\\r\\n\\r\\n22\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\nimmer einem a\\xcc\\x88hnlichen Muster, das durch regula\\xcc\\x88re Ausdru\\xcc\\x88cke beschrieben werden kann.\\r\\nDie Werte dieser Attribute sind deutlich weniger variabel als die der u\\xcc\\x88brigen Attribute.\\r\\nZudem ist es unwahrscheinlich, dass in naher Zukunft neue Werte zu den Attributen hinzugefu\\xcc\\x88gt werden und diese somit sehr starr sind. Ein alternatives Vorgehen zur Erkennung\\r\\ndieser Attribute ist mit neuronalen Netzen. Das Trainieren eines neuronalen Netzes zum\\r\\nErkennen dieser Attribute ist wesentlich aufwa\\xcc\\x88ndiger und fehleranfa\\xcc\\x88lliger. Aus diesem\\r\\nGrund wurde sich gegen dieses Vorgehen und fu\\xcc\\x88r die regula\\xcc\\x88ren Ausdru\\xcc\\x88cke entschieden.\\r\\nIn dem letzten Schritt wird ein einfacher Vergleich der Eingabe mit zuvor definierten Attribut Auspra\\xcc\\x88gungen vorgenommen. Dieser Schritt wird fu\\xcc\\x88r Attribute verwendet, welche\\r\\nnicht durch regula\\xcc\\x88re Ausdru\\xcc\\x88cke beschrieben werden ko\\xcc\\x88nnen. Die Eingabe wird mit zuvor\\r\\ndefinierten Werten, wie z.B. \\xe2\\x80\\x9ciPhone\\xe2\\x80\\x9d abgeglichen, um sicher zu stellen das zumindest\\r\\ndiese Werte korrekt klassifiziert werden. Anders als der erste Schritt, in dem sa\\xcc\\x88mtliche\\r\\nProdukte identifiziert werden sollen, ist das Ziel des letzten Schrittes nur wenige, bestimmte Attribute zu erkennen. Aufgrund des anderen Zieles wird das folgende Verfahren\\r\\nin Betracht gezogen. Die gegebene Eingabe wird Wort fu\\xcc\\x88r Wort mit den zuvor definierten\\r\\nAuspra\\xcc\\x88gungen abgeglichen und bei einer U\\xcc\\x88bereinstimmung ist das Attribut in der Eingabe enthalten. Der Nachteil dieses Ansatzes ist, dass die definierten Werte eine exakte\\r\\nU\\xcc\\x88bereinstimmung in der Eingabe voraussetzen, da diese sonst nicht gefunden werden.\\r\\nEinen besseren Ansatz verfolgt die Fuzzylogik (Zadeh 1965). Die Wo\\xcc\\x88rter beno\\xcc\\x88tigen keine\\r\\nexakte U\\xcc\\x88bereinstimmung da auch ungenaue Ergebnisse zugelassen werden. Der Nachteil\\r\\nder exakten U\\xcc\\x88bereinstimmung ist dadurch nicht mehr gegeben, weshalb fu\\xcc\\x88r den letzten\\r\\nSchritt die Fuzzylogik betrachtet wird (Mansouri, Affendey und Mamat 2008).\\r\\n\\r\\n3.3.3. Tagging\\r\\nFalsche Ergebnisse sind bei der Verwendung von neuronalen Netzen nicht auszuschlie\\xc3\\x9fen, weshalb diese beru\\xcc\\x88cksichtigt werden mu\\xcc\\x88ssen. Um zu verhindern, das falschen Daten\\r\\npersistiert werden wird eine Komponente beno\\xcc\\x88tigt, mit der das Ergebnis der Pipeline\\r\\nmanuell nachgebessert werden kann (FA3 ). Die Komponente unterteilt sich dabei in zwei\\r\\nUnterfunktionen, zum einen das manuelle Setzen von Attributen und zum anderen das\\r\\nBestimmen der Rolle (Ka\\xcc\\x88ufer oder Verka\\xcc\\x88ufer) aus einer Anfrage. Durch das richtige Setzen\\r\\nvon Attributen ko\\xcc\\x88nnen diese Anfragen korrekt in der Auswertungs\\xe2\\x80\\x93Komponente verwendet werden. Aus falsch persistiert Daten ko\\xcc\\x88nnen unpassende Ergebnisse entstehen die dem\\r\\nAnwender auf seine Anfrage als Antwort vorgeschlagen werden. Selbiges gilt fu\\xcc\\x88r falsch zugewiesene Rollen, auf eine Kaufanfrage ko\\xcc\\x88nnte mit einer weiteren Kaufanfrage von dem\\r\\nSystem geantwortet werden.\\r\\n\\r\\n23\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\nEine solche Komponente, in der Anwender die Daten selbst annotieren ko\\xcc\\x88nnen, kann\\r\\nverwendet werden, um Daten zu sammeln. Es kann auf keine Datengrundlage aufgebaut\\r\\nwerden, die die Anforderungen erfu\\xcc\\x88llen, weshalb dieses Vorgehen geeignet ist. Die gesammelten Daten ko\\xcc\\x88nnen verwendet werden, um das beno\\xcc\\x88tigte neuronale Netz zu trainieren\\r\\nund so die Performance zu verbessern. Durch die manuelle Annotation der Daten ko\\xcc\\x88nnen\\r\\ndiese, ohne zusa\\xcc\\x88tzliche Bearbeitungsschritte verwendet werden, um den Ablauf zu vereinfachen. Mit dieser Struktur kann ein iterativer Ansatz zum Verbessern der Modelle erstellt\\r\\nwerden. Es werden Daten gesammelt, die durch den Anwender korrekt annotiert sind. Ab\\r\\neiner gewissen Menge von neuen Daten wird der gesamte Datenbestand verwendet, um\\r\\nein neues Modell zu trainieren welches das vorherige ersetzt. Anhand der Daten aus den\\r\\nspa\\xcc\\x88teren Iterationen lassen sich die Modelle evaluieren und ko\\xcc\\x88nnen so verglichen werden.\\r\\nZudem kann die Skalierung der Modelle mit mehr Daten gemessen werden, indem diese\\r\\nerneut trainiert und auf eine Verbesserung der Genauigkeit gepru\\xcc\\x88ft werden. Durch eine\\r\\nAutomatisierung der Iteration wa\\xcc\\x88re das System in der Lage sich kontinuierlich selbst zu\\r\\nverbessern und so immer mehr Eingaben korrekt zu erkennen.\\r\\n\\r\\n3.3.4. Persistierung\\r\\nDer Handel zwischen Kunden ist ein wesentlicher Bestandteil eines virtuellen Marktplatzes. Um diesen zu ermo\\xcc\\x88glichen, muss das System in der Lage sein, die Angebote und\\r\\nggf. Nachfragen zu persistieren, damit diese von Kunden gefunden werden ko\\xcc\\x88nnen (FA5 ).\\r\\nZudem ist ein virtueller Marktplatz erst dann fu\\xcc\\x88r Kunden attraktiv, wenn dieser u\\xcc\\x88ber\\r\\neine Vielzahl von Produkten im Sortiment verfu\\xcc\\x88gt. Zum Verwalten von gro\\xc3\\x9fen Mengen\\r\\nan Daten wird meist auf Datenbanken zuru\\xcc\\x88ckgegriffen. In der Datenbank werden die Benutzereingaben sowie die erkannten Attribute gespeichert. Wurde das Ergebnis der Verarbeitung von dem Anwender manuell verbessert wird das ebenfalls persistiert, um einen\\r\\nkorrekt klassifizierten Datensatz zu erhalten. Fu\\xcc\\x88r diese Arbeit wurde zwischen Graphdatenbanken und relationale Datenbank nach (Vicknair u. a. 2010) entschieden. Aus den\\r\\nvorgestellten Anwendungsfa\\xcc\\x88llen in Abschnitt 3.2 ist ersichtlich, dass die Daten keine Indizierung beno\\xcc\\x88tigen und u\\xcc\\x88berwiegend nur aus Text bestehen. Bezogen auf die Performance,\\r\\nsind Relationale Datenbanken den Graphdatenbanken in diesem Szenario unterlegen. Der\\r\\nzweite Anwendungsfall bezieht sich auf eine Gruppensuche, die viele Beziehungen der\\r\\neinzelnen Daten voraussetzt (z.B. Knowledge Graph). Vordefinierte Produkte ko\\xcc\\x88nnen Beziehungen zu Herstellern haben und es ko\\xcc\\x88nnen Obergruppen fu\\xcc\\x88r bestimmte Kategorien\\r\\nangelegt werden. Die Komponente welche passende Gegenangebote ermittelt kann auf\\r\\ndiese Daten zuru\\xcc\\x88ckgreifen, um so bessere Ergebnisse zu erzielen. Dieses ist ein weiterer\\r\\nVorteil der Graphdatenbanken nach (Vicknair u. a. 2010) weshalb diese im Rahmen dieser\\r\\n\\r\\n24\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\nArbeit verwendet werden.\\r\\n\\r\\n3.3.5. Auswertung\\r\\nDie letzte Komponente erstellt die Antwort zu einer gegebenen Eingabe. Damit vorherigen\\r\\nAnfragen ausgewertet werden ko\\xcc\\x88nnen, beno\\xcc\\x88tigt die Komponente Zugriff auf die Datenbank. Dabei muss die Rolle des Benutzers (Ka\\xcc\\x88ufer oder Verka\\xcc\\x88ufer) beachtet werden damit\\r\\nnur Anfragen der anderen Rolle ausgewertet werden. In dem speziellen Szenario aus Abschnitt 3.2 muss die Komponente erkennen, dass eine Gruppensuche erwartet wird (FA4 ).\\r\\nAus den gefundenen Mengen der Ergebnisse muss anhand einer Strategie ein optimales\\r\\nGegenangebot gefunden werden, welches zuru\\xcc\\x88ckgegeben wird (FA2 ). Eine geeignete Strategie sucht das Angebot mit den meisten u\\xcc\\x88bereinstimmenden Attributen aus der Anfrage.\\r\\nDas Attribut \\xe2\\x80\\x9cProdukt\\xe2\\x80\\x9d muss mindestens u\\xcc\\x88bereinstimmen da es sich sonst um verschiedene Produkte handelt. Anhand der Rolle kann eine Regel fu\\xcc\\x88r den Preis erstellt werden,\\r\\nals Verka\\xcc\\x88ufer wird der ho\\xcc\\x88chste Preis bevorzugt, als Ka\\xcc\\x88ufer der niedrigste. Mit dieser Strategie kann ein Matchmaking erstellt werden welches immer das passende Gegenangebot\\r\\nfu\\xcc\\x88r eine Anfrage findet. Wenn kein Angebot gefunden werden konnte, sollte dieses ebenfalls wiedergegeben werden. Die erkannten Attribute aus der Eingabe sind auch in der\\r\\nzuru\\xcc\\x88ckgegeben Antwort enthalten, um diese dem Anwender zu zeigen (NA3 ).\\r\\n\\r\\n3.4. Prozesse\\r\\nAus den in Abschnitt 3.2 vorgestellten Anwendungsfa\\xcc\\x88llen sind die im Abschnitt 3.3\\r\\nerla\\xcc\\x88uterten Komponente entstanden, welche alle Anforderungen (FA1 - FA6 ) erfu\\xcc\\x88llen.\\r\\nDie Anwendungsfa\\xcc\\x88lle beschreiben bereits einen groben Ablauf in welcher Reihenfolge die\\r\\nKomponente aufgerufen werden. Im folgendem wird anhand der Szenarien deutlich, wie\\r\\ndie Kommunikation zwischen den Komponenten dargestellt wird und welche Funktionen\\r\\ndiese bereitstellen mu\\xcc\\x88ssen.\\r\\n1. / 2. Szenario:\\r\\nDie Szenarien 1. und 2. unterscheiden sich nur in der Art der Suche. In dem einen Szenario wird ein explizites Produkt gesucht und in dem anderen wird nach einem Produkt\\r\\naus einer Produktgruppe gesucht. Der Ablauf der Szenarien wird durch diesen Unterschied nicht beeinflusst, weshalb beide Anwendungsfa\\xcc\\x88lle gemeinsam betrachtet werden.\\r\\nEingeleitet wird die Suche durch das Eingeben einer Anfrage durch den Anwender. Diese\\r\\nwird an die Hybrid Named Entity Recognition (NER)\\xe2\\x80\\x93Komponente u\\xcc\\x88bergeben, welche\\r\\neine Funktion bereitstellen muss, die eine Anfrage entgegennimmt. Die Eingabe sowie das\\r\\nErgebnis der Verarbeitung wird an die Datenverwaltung zum Persistieren u\\xcc\\x88bergeben. Die\\r\\n\\r\\n25\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\nDaten aus diesen Szenarien mu\\xcc\\x88ssen mit einem zusa\\xcc\\x88tzlichen Vermerk gespeichert werden,\\r\\nda das Ergebnis nicht manuell verifiziert wurde und mo\\xcc\\x88glicherweise fehlerhaft sein kann.\\r\\nIm Anschluss wird das Ergebnis an die Auswertungs\\xe2\\x80\\x93Komponente u\\xcc\\x88bergeben. Dort wird\\r\\nbestimmt ob es sich um eine Gruppen- oder Produktsuche handelt und eine passende\\r\\nAnfrage an die Datenbank gestellt. Die Datenverwaltung beno\\xcc\\x88tigt zwei Funktionen. Die\\r\\nerste Funktion nimmt das gesuchte Produkt und die Rolle der Anfrage entgegen und\\r\\ngibt die gefundenen Anfragen mit enthaltenen Attributen zuru\\xcc\\x88ck. Der zweiten Funktion\\r\\nwird eine Produktgruppe anstelle eines bestimmten Produktes mit der Rolle u\\xcc\\x88bergeben,\\r\\ndie Ru\\xcc\\x88ckgabe bleibt identisch. Die Ergebnisse der Datenbankanfrage werden ausgewertet\\r\\nund ein mo\\xcc\\x88gliches Gegenangebot mit den erkannten Attributen der eigenen Eingabe an\\r\\ndie Oberfla\\xcc\\x88che zuru\\xcc\\x88ck u\\xcc\\x88bergeben. Die Oberfla\\xcc\\x88che wird um die Antwort erweitert und die\\r\\nSuchanfrage ist beendet.\\r\\n3. Szenario:\\r\\nDie Erstellung eines Inserats wird durch eine Benutzereingabe eingeleitet. Die Hybrid\\r\\nNER\\xe2\\x80\\x93Komponente muss eine Schnittstelle bereitstellen, die diese Eingabe entgegennimmt. Das Ergebnis wird zuru\\xcc\\x88ck an die Oberfla\\xcc\\x88che u\\xcc\\x88bergeben, um es dem Anwender\\r\\nzu pra\\xcc\\x88sentieren. Basierend auf der Ru\\xcc\\x88ckmeldung wird die Eingabe sofort gespeichert oder\\r\\neiner manuellen Bearbeitung unterzogen. Der Tagging\\xe2\\x80\\x93Komponente wird die Eingabe\\r\\nu\\xcc\\x88bergeben und bietet dem Anwender in einer Oberfla\\xcc\\x88che die Mo\\xcc\\x88glichkeit die Attribute der Eingabe manuell zu bestimmen. Die Datenverwaltung beno\\xcc\\x88tigt eine Funktion, an\\r\\ndie die Eingabe, sowie das erkannte bzw. manuell bestimmte Ergebnis u\\xcc\\x88bergeben werden kann. Das Inserat wurde erstellt und der Ablauf ist abgeschlossen. Die Auswertungs\\xe2\\x80\\x93\\r\\nKomponente wird in diesem Szenario nicht beno\\xcc\\x88tigt, da der Anwender nach dem Erstellen\\r\\neines Inserats keine Antwort des Systems erha\\xcc\\x88lt.\\r\\n\\r\\n3.5. Bewertungskriterien\\r\\nEs werden verschiedene Algorithmen verwendet, um alle Attribute aus einer Eingabe zu\\r\\nerkennen. Damit die Algorithmen verglichen werden ko\\xcc\\x88nnen, werden einheitliche Metriken\\r\\nverwendet. Die meisten neuronalen Netze werden anhand der Werte: Accuracy, Precision, Recall und F1\\xe2\\x80\\x93Score bemessen (Faruqui und Pado\\xcc\\x81 2010). Diese Werte werden aus\\r\\nden Feldern einer Confusion Matrix berechnet. Damit die berechneten Ergebnisse aus\\r\\nder Evaluation auch mit anderen Arbeiten vergleichbar sind, werden dieselben Metriken\\r\\naufgestellt. Fu\\xcc\\x88r eine ausfu\\xcc\\x88hrliche Evaluation wird eine zusa\\xcc\\x88tzliche Bewertung nach (Jiang, Banchs und Li 2016) durchgefu\\xcc\\x88hrt. Die Attribute ko\\xcc\\x88nnen dabei in folgende Klassen\\r\\neingeordnet werden:\\r\\n\\r\\n26\\r\\n\\r\\n\\x0cKapitel 3\\r\\n\\r\\nKonzeption\\r\\n\\r\\n\\xe2\\x80\\xa2 Erkannt, richtige Klasse\\r\\n\\xe2\\x80\\xa2 Erkannt, falsche Klasse\\r\\n\\xe2\\x80\\xa2 Zu viel/wenig erkannt, richtige Klasse\\r\\n\\xe2\\x80\\xa2 Zu viel/wenig erkannt, falsche Klasse\\r\\n\\xe2\\x80\\xa2 Falsch erkanntes Wort\\r\\n\\xe2\\x80\\xa2 Attribut nicht erkannt\\r\\nDurch eine genauere Aufteilung ko\\xcc\\x88nnen so die Algorithmen gezielter untersucht werden, um eine mo\\xcc\\x88gliche spa\\xcc\\x88tere Nachverarbeitung zu vereinfachen. In dem Bereich der\\r\\nnatu\\xcc\\x88rlichen Sprachverarbeitung gibt es viele Modelle die Named Entity Tagging (NET)\\r\\nunterstu\\xcc\\x88tzen. Aus diesem Grund soll der Prototyp die Metriken automatisch generieren.\\r\\nDadurch wa\\xcc\\x88ren die Modelle einheitlich gestaltet und sind somit besser nachvollziehbar.\\r\\nSo kann die Performance der Pipeline jederzeit nachvollzogen werden. Zeitmessungen\\r\\nwurden auf einem Laptop (i7-4710MQ mit 2,50 GHz und 16 GB RAM) mit den vorhandenen Testdaten ausgefu\\xcc\\x88hrt. Dabei wurden externe Einflussfaktoren so weit wie mo\\xcc\\x88glich\\r\\nausgeschlossen (keine weiteren laufenden Programme, keine Internetverbindung) und die\\r\\nTestdurchla\\xcc\\x88ufe wurden zehnmal wiederholt, um ein mo\\xcc\\x88glichst genaues Ergebnis zu erzielen.\\r\\n\\r\\n27\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\n4. Umsetzung\\r\\nDer folgende Abschnitt beschreibt das Sammeln der Daten, die in dieser Arbeit verwendet\\r\\nwurden. Im Anschluss wird die Implementierung der einzelnen Komponenten, die zusammen eine Pipeline bilden, vorgestellt. Abschlie\\xc3\\x9fend wird auf die Oberfla\\xcc\\x88che des Prototyps\\r\\neingegangen.\\r\\n\\r\\n4.1. Vorgehen\\r\\nDie Umsetzung erfolgt in zwei Iterationsschritten, die auf Abbildung 10 dargestellt werden. In der ersten Iteration wird eine gewisse Menge von Daten akquiriert, auf die die\\r\\nverschiedenen Modelle trainiert und evaluiert werden, um diese vergleichen zu ko\\xcc\\x88nnen.\\r\\nAnhand dieser Ergebnisse werden die Modelle gewichtet und zusammen kombiniert, um\\r\\ndie Pipeline zu erstellen. Im Anschluss wird die erste Version des Prototyps realisiert, der\\r\\ndas Erstellen von Inserats unterstu\\xcc\\x88tzt.\\r\\n\\r\\nAbbildung 10: Ablaufdiagramm der Umsetzung dieser Arbeit\\r\\nIn der zweiten Iteration werden mehr Daten mithilfe des Prototyps gesammelt. Die bereits trainierten Modelle werden anhand dieser Daten evaluiert, um die Genauigkeit der\\r\\nModelle besser zu bestimmen. Die verwendeten Modelle werden mit dem gesamten Datensatz erneut trainiert und die vorherigen Ergebnisse mit den neuen verglichen. Die neuen\\r\\nModelle werden mit den vorhandenen in der Pipeline ausgetauscht, um das Ergebnis des\\r\\nPrototyps zu verbessern.\\r\\n\\r\\n28\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\n4.2. Datenakquise\\r\\nEin wichtiger Bestandteil, um mit maschinellen Lernen Probleme lo\\xcc\\x88sen zu ko\\xcc\\x88nnen sind\\r\\nrelevante Daten. Mit einer gro\\xc3\\x9fen Menge von Daten ko\\xcc\\x88nnen die verwendeten Modelle\\r\\nbessere Ergebnisse erzielen, da Abweichungen weniger Gewichtung haben. Zudem sind\\r\\ndie Daten vielfa\\xcc\\x88ltiger und ko\\xcc\\x88nnen somit mehrere verschiedene Situationen abdecken.\\r\\nZu Beginn der Arbeit waren keine Daten vorhanden weshalb die Datenakquise ein wesentlicher Bestandteil darstellt. Die ersten Daten wurden in einer Umfrage erhoben. Die\\r\\nArbeit beschra\\xcc\\x88nkt sich auf das Erkennen des Attributes \\xe2\\x80\\x9cProdukt\\xe2\\x80\\x9d weshalb die Teilnehmer\\r\\nSa\\xcc\\x88tze bilden sollten, in denen nach einem Produkt gesucht wird. Das enthaltene Produkt\\r\\nsollte zudem in einem zusa\\xcc\\x88tzlichen Feld eingetragen werden, um so die spa\\xcc\\x88tere Vorverarbeitung der Daten zu vereinfachen. In der ersten Iteration wurden so 70 Datensa\\xcc\\x88tze\\r\\nerhoben, die in dem na\\xcc\\x88chsten Schritt vorverarbeitet wurden. Die Algorithmen sollen nur\\r\\nProdukte erkennen, welche in dem gegebenen Satz enthalten sind. So wurden Sa\\xcc\\x88tze wie:\\r\\n\\xe2\\x80\\x9cAm Wochenende lade ich wieder zu einer Grillparty ein, ich suche noch jemand der\\r\\nFleisch mitbringen kann\\xe2\\x80\\x9d mit dem angegebenen Produkt \\xe2\\x80\\x9cGrillfleisch\\xe2\\x80\\x9d gea\\xcc\\x88ndert, sodass\\r\\ndas gesuchte Wort exakt in dem Satz enthalten ist, in diesem Fall: \\xe2\\x80\\x9cFleisch\\xe2\\x80\\x9d. Basierend\\r\\nauf diesen Daten wurden die Algorithmen in der ersten Iteration trainiert.\\r\\nIn dem zweiten Iterationsschritt konnte auf einen lauffa\\xcc\\x88higen Prototyp aufgebaut werden,\\r\\num so das Sammeln der Daten zu unterstu\\xcc\\x88tzen. Die Probanden wurden gebeten, sich auf\\r\\ndie Produktgruppe der Smartphones zu fokussieren damit die vorgegebenen mo\\xcc\\x88glichen\\r\\nAttribute in der Eingabe enthalten sein ko\\xcc\\x88nnen. In einer Eingabemaske wird das Angebot bzw. die Nachfrage eingegeben und auf der na\\xcc\\x88chsten Seite wird das Ergebnis des\\r\\nAlgorithmus dargestellt. Dabei wurde sich auf 6 mo\\xcc\\x88gliche Attribute beschra\\xcc\\x88nkt: Produkt,\\r\\nHersteller, Preis, Farbe, Speicher und Kamera. Die Probanden sollten entscheiden, ob ihre\\r\\nEingabe richtig erkannt wurde, oder ob Attribute falsch gesetzt wurden bzw. komplett fehlen. Im letzten Fall sollten die Anwender selbst die Attribute markieren, um die Daten fu\\xcc\\x88r\\r\\neine spa\\xcc\\x88tere Verarbeitung vorzubereiten. Der Vorteil in dieser Methode liegt darin, dass\\r\\ndeutlich mehr Datensa\\xcc\\x88tze direkt verwendet werden ko\\xcc\\x88nnen und keine Vorverarbeitung der\\r\\nDaten wie in der ersten Iteration no\\xcc\\x88tig ist. Die Oberfla\\xcc\\x88che erlaubt nur das Markieren von\\r\\nzusammenstehenden Wo\\xcc\\x88rtern, die tatsa\\xcc\\x88chlich in dem Satz enthalten sind und so das Attribut bilden. Beides sind Annahmen die im Rahmen dieser Arbeit getroffen wurden und\\r\\nim Abschnitt 3.1 genauer beschrieben werden. Dieses Vorgehen ermo\\xcc\\x88glicht das Sammeln\\r\\neines dynamisch wachsenden Datensatzes, welcher zum Evaluieren und Optimieren der\\r\\nAlgorithmen verwendet wird.\\r\\n\\r\\n29\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\n4.3. Hybrid named-entity recognition\\r\\nZum Erkennen der Attribute werden verschiedene, bereits existierende Verfahren kombiniert, um gemeinsam eine Pipeline zu bilden. Die Algorithmen ko\\xcc\\x88nnen vorherige Teilergebnisse u\\xcc\\x88berschreiben, um das endgu\\xcc\\x88ltige Resultat zu verbessern. Die Verfahren werden\\r\\npassend zu der Reihenfolge in der Pipeline in den folgenden Abschnitten vorgestellt. Abbildung 11 zeigt einen U\\xcc\\x88berblick, welche Algorithmen verwendet werden.\\r\\n\\r\\nAbbildung 11: Reihenfolge der verwendeten Algorithmen\\r\\n\\r\\n4.3.1. SpaCy\\r\\nZu Beginn der Arbeit wurde das vorhandene und bereits trainierte deutsche Modell von SpaCy evaluiert. Das Modell unterstu\\xcc\\x88tzt das Setzen von Part of Speech\\r\\n(POS), Abha\\xcc\\x88ngigkeiten und NER welches fu\\xcc\\x88r diesen Teil verwendet wurde. Das Modell verwendet eine eigene Word Embedding Strategie mit Unterwortmerkmalen und\\r\\n\\xe2\\x80\\x9cBloom\\xe2\\x80\\x9d\\xe2\\x80\\x93Einbettungen sowie ein tiefes CNN um die Ergebnisse zu berechnen (SpaCy\\xe2\\x80\\x93\\r\\nDokumentation 2019). Trainiert wurde das Modell auf einem Korpus von mehreren tausend, deutschen Wikipedia Artikeln mit 4 ausschlaggebenden Attributen: Lokation, Organisation, Personen und sonstigen. Getestet wurde auf Erkennen der Organisation, welches \\xe2\\x80\\x94 in dem gegebenen Anwendungsfall \\xe2\\x80\\x94 gleichbedeutend mit dem Hersteller des\\r\\nProduktes ist. Das Ergebnis eines Testszenarios zeigte, dass die Satzstruktur zwischen\\r\\ndem Anwendungsfall und dem Wikipediakorpus zu unterschiedlich ist, sodass das Attribut nicht erkannt wurde. Basierend auf dem Testszenario\\xe2\\x80\\x93Datensatz, der 14 verschiedene\\r\\nEingaben entha\\xcc\\x88lt, wurde ein neues Modell trainiert. Abbildung 12 zeigt die Ergebnisse\\r\\nbeider Modelle mit derselben Eingabe.\\r\\n\\r\\n30\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nAbbildung 12: Ergebnisse der verschiedenen SpaCy\\xe2\\x80\\x93Modelle\\r\\nDas neue Modell wurde auf das Erkennen aller sechs Attribute trainiert. Dieses sollte\\r\\nzeigen, ob das Framework mit einer sehr geringen Menge an Daten lernen kann. Wie der\\r\\nAbbildung 12 zu entnehmen ist hat sich das Ergebnis gegenu\\xcc\\x88ber dem vortrainierten Modell deutlich verbessert. Das bedeutet, dass SpaCy, selbst mit einer geringen Menge an\\r\\nDaten, in der Lage ist entsprechende Ergebnisse zu erzeugen.\\r\\nMit den Trainingsdaten aus dem ersten Iterationsschritt zeigte sich, dass sich das Modell stark verbesserte. Basierend auf der Annahme, dass mehr Trainingsdaten zu einem\\r\\ndeutlich besseren und weiterhin performanten Modell fu\\xcc\\x88hren, bildet der Named Enitity\\r\\nTagger aus dem SpaCy Framework den ersten Schritt in der Pipeline. SpaCy bietet zudem\\r\\neine Tokenizing Funktion welche die Eingabe in einzelne Token (z.B. Wo\\xcc\\x88rter, Satzzeichen\\r\\nusw.) unterteilt die in den nachfolgenden Schritten verwendet werden. Ein wesentlicher\\r\\nNachteil der SpaCy NER Funktion ist, dass es die Eingaben von Bezeichnungen an der\\r\\nfalschen Stelle erkennt. So werden Wo\\xcc\\x88rter als Produkt klassifiziert die keine sind. Aus\\r\\ndiesem Grund wurde in der Pipeline eine Gewichtung eingebaut, die den folgenden Algorithmen das Recht gibt, vorherige Teilergebnisse zu u\\xcc\\x88berschreiben nicht jedoch zu lo\\xcc\\x88schen.\\r\\nDieses ist von Vorteil da sich einzelne Schritte nur auf das Finden einiger Attribute fokussieren ko\\xcc\\x88nnen, welche zum Ende der Pipeline ausgefu\\xcc\\x88hrt werden, die zum Ausbessern\\r\\nvorheriger Fehler geeignet sind.\\r\\n\\r\\n4.3.2. Regula\\xcc\\x88re Ausdru\\xcc\\x88cke\\r\\nUm eine der Schwa\\xcc\\x88chen des SpaCy\\xe2\\x80\\x93Modells auszugleichen, wurde ein regelbasierter Ansatz verwendet. Das sprachliche Modell ist fu\\xcc\\x88r das Erkennen und richtige Unterscheiden\\r\\nvon Zahlenwerten weniger geeignet. So wurden die Attribute Preis, Speicher und Kamera\\r\\nvon der SpaCy Komponente ha\\xcc\\x88ufig falsch klassifiziert. Der einzige wesentliche Unterschied\\r\\nist die Einheit nach dem Zahlenwert wie z.B. 300 e, 256 GB und 13 MP. Zum Erkennen\\r\\n\\r\\n31\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nsolcher Attribute werden regula\\xcc\\x88re Ausdru\\xcc\\x88cke verwendet. Die Eingabe wird nach einem\\r\\nZahlenwert durchsucht und anhand der folgenden Einheit klassifiziert. Um das Erstellen\\r\\nder regula\\xcc\\x88ren Ausdru\\xcc\\x88cke zu vereinfachen, wird ein Ausdruck dreigeteilt. Das Pra\\xcc\\x88fix steht\\r\\nvor dem gesuchten Wert und beschreibt diesen z.B. \\xe2\\x80\\x9cmax\\xe2\\x80\\x9d, \\xe2\\x80\\x9cho\\xcc\\x88chstens\\xe2\\x80\\x9d oder \\xe2\\x80\\x9cmid\\xe2\\x80\\x9d. Nach\\r\\ndem Pra\\xcc\\x88fix kommt der Stamm, dieser beschreibt den Aufbau des gesuchten Zahlenwertes,\\r\\nin Python ko\\xcc\\x88nnte es fu\\xcc\\x88r europa\\xcc\\x88ische Preise wie folgt aussehen:\\r\\n1\\r\\n\\r\\nr e T a g g e r = ReTagging ( )\\r\\n\\r\\n2\\r\\n3\\r\\n4\\r\\n5\\r\\n\\r\\np r e f i x = [ \\xe2\\x80\\x99 max \\xe2\\x80\\x99 , \\xe2\\x80\\x99 maximal \\xe2\\x80\\x99 , \\xe2\\x80\\x99 b i s zu \\xe2\\x80\\x99 , \\xe2\\x80\\x99 ab \\xe2\\x80\\x99 , \\xe2\\x80\\x99 mid \\xe2\\x80\\x99 ,\\r\\nstam = [ \\xe2\\x80\\x99 ( \\\\ d+\\\\ ,\\\\d { 1 , 2 } ) \\xe2\\x80\\x99 , \\xe2\\x80\\x99 ( \\\\ d+) \\xe2\\x80\\x99 ]\\r\\ns u f f i x = [ \\xe2\\x80\\x99 e \\xe2\\x80\\x99 , \\xe2\\x80\\x99 euro \\xe2\\x80\\x99 ]\\r\\n\\r\\n\\xe2\\x80\\x99 \\xe2\\x80\\x99]\\r\\n\\r\\n6\\r\\n7\\r\\n\\r\\nr e T a g g e r . add ( \\xe2\\x80\\x99MONEY\\xe2\\x80\\x99 , p r e f i x , s u f f i x , stam )\\r\\n\\r\\nListing 1: Regel zum Erstellen des regula\\xcc\\x88ren Ausdruck zum Erkennen des Preises\\r\\nZum Schluss folgt das Suffix, es beschreibt die Einheit, die dieses Attribut haben ko\\xcc\\x88nnte.\\r\\nDiese drei Mengen werden mit dem Attributbezeichner (z.B \\xe2\\x80\\x9cMONEY\\xe2\\x80\\x9d) der Methode\\r\\nu\\xcc\\x88bergeben, die alle Kombinationen aus den Mengen bildet, um daraus den regula\\xcc\\x88ren\\r\\nAusdruck zu erzeugen.\\r\\nDie Tatsache das es ein regelbasierter Ansatz ist, eru\\xcc\\x88brigt das genaue Evaluieren. Dieses\\r\\nVerfahren bietet sich fu\\xcc\\x88r Attribute an, die hauptsa\\xcc\\x88chlich aus Zahlen bestehen und diese\\r\\nAnhand von Regeln erkannt werden ko\\xcc\\x88nnen. Es ist von Vorteil, da keine Modelle trainiert werden mu\\xcc\\x88ssen und direkt eingesetzt werden ko\\xcc\\x88nnen. Dadurch wird ein schnelles\\r\\nReagieren auf Ausdru\\xcc\\x88cke, die neu hinzugefu\\xcc\\x88gt werden mu\\xcc\\x88ssen, ermo\\xcc\\x88glicht. Selbiges zeigt\\r\\ndie Unflexibilita\\xcc\\x88t von regula\\xcc\\x88ren Ausdru\\xcc\\x88cken, da diese nur Werte erkennen, die zuvor mit\\r\\nRegeln beschrieben wurden und zudem manuell gepflegt werden mu\\xcc\\x88ssen. Zum Klassifizieren von Produkten sind regula\\xcc\\x88re Ausdru\\xcc\\x88cke nicht geeignet, da weder ein Stamm noch ein\\r\\nSuffix genau definiert werden kann. Das Pra\\xcc\\x88fix allein ist nicht ausreichend (z.B. \\xe2\\x80\\x9csuche []\\xe2\\x80\\x9d,\\r\\n\\xe2\\x80\\x9cverkaufe []\\xe2\\x80\\x9d). Regula\\xcc\\x88re Ausdru\\xcc\\x88cke sind schlicht zu unflexibel. Der regelbasierte Ansatz\\r\\nbildet den zweiten Schritt der Pipeline, damit dieser mo\\xcc\\x88gliche Fehler bei Attributen mit\\r\\nZahlenwerten der SpaCy Komponente korrigieren kann.\\r\\nIn der ersten Iterationsstufe wurden einige Regeln zum passenden Erkennen der Testdaten\\r\\nerstellt. Diese wurden geringfu\\xcc\\x88gig in der spa\\xcc\\x88teren Iterationen der Pipeline modifiziert.\\r\\n\\r\\n32\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\n4.3.3. Metadaten Analyse\\r\\nWo\\xcc\\x88rter haben neben ihrer Bedeutung noch Wortklassen, die basierend der grammatikalischen Eigenschaften des Wortes gesetzt werden. Abbildung 13 zeigt die erkannten Wortklassen (z.B.Verben, Nomen, numerisch oder Satzzeichen) sowie die Beziehungen zwischen\\r\\nden einzelnen Wo\\xcc\\x88rter. Das trainierte Modell von SpaCy ist in der Lage die Wortklassen\\r\\nden Wo\\xcc\\x88rtern zuzuordnen. Auch werden weitere Metadaten von SpaCy erkannt und den\\r\\neinzelnen Wo\\xcc\\x88rtern der Eingabe zugeordnet. Diese sind unter anderem, ob das Token nur\\r\\naus Buchstaben besteht und ob es sich hierbei um ein Stoppwort handelt. Stoppwo\\xcc\\x88rter\\r\\nsind Wo\\xcc\\x88rter, die keinen Mehrwert fu\\xcc\\x88r die Aussage beinhalten, weshalb diese in der Regel\\r\\nin der Datenauswertung ignoriert werden. Auch sind es Wo\\xcc\\x88rter, die u\\xcc\\x88berdurchschnittlich\\r\\nha\\xcc\\x88ufig in einer Sprache vorkommen und ha\\xcc\\x88ufig als Fu\\xcc\\x88llwo\\xcc\\x88rter eingesetzt werden. Diese\\r\\nWo\\xcc\\x88rter sind unter anderem: \\xe2\\x80\\x9calso\\xe2\\x80\\x9d, \\xe2\\x80\\x9cbei\\xe2\\x80\\x9d oder \\xe2\\x80\\x9chat\\xe2\\x80\\x9d und sind bei SpaCy in dem Modell\\r\\nhinterlegt. Weitere Metadaten, die erfasst werden, sind die Position des Wortes in dem\\r\\nText, die La\\xcc\\x88nge des Wortes und ob der erste Buchstabe des Wortes gro\\xc3\\x9fgeschrieben ist.\\r\\n\\r\\nAbbildung 13: Beispiel fu\\xcc\\x88r erkannte Wortklassen des SpaCy Frameworks\\r\\nBasierend auf diese Informationen wurde ein einfaches, neuronales Netz trainiert, dass\\r\\ndie Metadaten des einzelnen Wortes als Eingabe verwendet. Das Modell besteht aus drei\\r\\nvoll vernetzten Schichten, von der eine Schicht ein versteckter Layer ist. Der letzte Layer\\r\\ndes Netzes verwendet die \\xe2\\x80\\x9cBina\\xcc\\x88rer Schritt\\xe2\\x80\\x9d Aktivierungsfunktion welche das Ergebnis auf\\r\\ndie Werte 0 (kein Produkt) und 1 (Produkt) beschra\\xcc\\x88nkt. Trainiert wurde das Modell auf\\r\\ndemselben Datensatz wie auch schon zuvor das SpaCy\\xe2\\x80\\x93Modell. Der Datensatz besteht\\r\\naus ausschlie\\xc3\\x9flich grammatikalisch, korrekten Anfragen mit einer Maximalla\\xcc\\x88nge von 12\\r\\nWo\\xcc\\x88rtern. Die folgenden Abbildungen 14 und 15 zeigen die Performance des Modells nach\\r\\nder ersten Iteration der Datenakquise.\\r\\n\\r\\n33\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nAbbildung 14: Auswertung der Metadaten Analyse auf 70 Datensa\\xcc\\x88tzen\\r\\n\\r\\nAbbildung 15: Confusion Matrix der Metadaten Analyse auf 70 Datensa\\xcc\\x88tzen\\r\\nKu\\xcc\\x88rzere Anfragen sind die Sta\\xcc\\x88rke des Netzes, da es bei diesen u\\xcc\\x88ber eine ho\\xcc\\x88here Genauigkeit\\r\\nverfu\\xcc\\x88gt. Wie der Metrik zu entnehmen ist, erkennt das Modell etwas mehr als ein Drittel\\r\\nder Produkte korrekt. Unter optimalen Bedingungen ist die Erkennung des Produktes\\r\\n\\r\\n34\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nsehr hoch und die Laufzeit des Algorithmus mit im Durchschnitt 25 ms sehr kurz.\\r\\nEiner genaueren Evaluation der Daten (Abbildung 14) zeigte, dass das Modell keine Produkte erkennt, die aus mehreren Wo\\xcc\\x88rtern bestehen. So wird zum Beispiel \\xe2\\x80\\x9ciPhone 8\\xe2\\x80\\x9d nicht\\r\\nerkannt, sondern nur der erste Teil des Wortes: \\xe2\\x80\\x9ciPhone\\xe2\\x80\\x9d. Dieses ist auf die Auswertung,\\r\\nin der die Tokens einzeln bewertet werden, zuru\\xcc\\x88ckzufu\\xcc\\x88hren. Auch setzt das Modell eine\\r\\nkorrekte Rechtschreibung der Eingabe voraus, da sonst den Wo\\xcc\\x88rtern falsche Metadaten\\r\\nzugeordnet werden, die das Ergebnis verfa\\xcc\\x88lschen.\\r\\nIn der zweiten Iteration der Datenakquise wurde das Modell erneut auf die dann vorhandenen Daten trainiert. Der Datensatz erho\\xcc\\x88hte die maximale La\\xcc\\x88nge der Eingabe und\\r\\nbeinhaltete grammatikalisch, inkorrekte Eingaben. Das Ergebnis verschlechterte sich im\\r\\nVergleich zum vorherigen erheblich, was auf die grammatikalisch, inkorrekte Eingabe\\r\\nzuru\\xcc\\x88ckzufu\\xcc\\x88hren ist. Nach einer Vorverarbeitung, in der fehlerhafte Daten entfernt wurden,\\r\\nwurde das Modell erneut trainiert. Dieses erbrachte keine Verbesserung des urspru\\xcc\\x88nglichen\\r\\nModells, weshalb das erste Modell in dem Prototyp verwendet wurde.\\r\\nWerden nur die Metadaten betrachtet, gehen viele Informationen der Eingabe verloren,\\r\\ndie bei einer Auswertung nicht beachtet werden. Auch werden Produkte, die aus mehreren Wo\\xcc\\x88rtern bestehen nie erkannt, da sich die Metadaten zu stark zu den einfachen\\r\\nProdukten unterscheiden. Aus diesen Gru\\xcc\\x88nden ist die Genauigkeit der Vorgehensweise\\r\\nlimitiert. Durch die gute Performance bei optimaler Eingabe wird dieses Verfahren an\\r\\ndritter Stelle der Pipeline verwendet. Fehler der vorherigen Schritte werden korrigiert,\\r\\nwobei die Klassifizierung der Metadaten kaum bis gar keine Wo\\xcc\\x88rter falsch zuordnet.\\r\\n\\r\\n4.3.4. Targer\\r\\nDas Attribut Produkt wurde in den vorherigen Schritten nur unter bestimmten\\r\\nUmsta\\xcc\\x88nden richtig klassifiziert, da unter anderem der Aufbau der Eingabe nicht beachtet\\r\\nwurde. In dem Abschnitt 2.2 wurden Word Embeddings vorgestellt, welche Wo\\xcc\\x88rter in\\r\\nForm eines Vektors beschreiben. Diese Repra\\xcc\\x88sentation beinhaltet Informationen, anhand\\r\\ndas folgende Modell in der Lage ist, Wo\\xcc\\x88rter mit Attributen zu versehen.\\r\\n\\r\\n35\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nAbbildung 16: Aufbau und Funktionsweise des Targer\\xe2\\x80\\x93Modells nach (Chernodub 2018)\\r\\nDas Targer\\xe2\\x80\\x93Modell (Chernodub u. a. 2019) besteht aus der Kombination der Architekturen bidirectional Recurrent Neural Network (biRNN), CNN und CRF. Als RNN wird ein\\r\\nbiLSTM\\xe2\\x80\\x93Modell verwendet welche im Kapitel 2 genauer erla\\xcc\\x88utert wurde. Eine beispielhafte visuelle Darstellung des Modells kann Abbildung 16 entnommen werden. Bei dem\\r\\nTrainieren des Modells werden die GloVe Word Embeddings verwendet, um mit diesen Informationen die Buchstaben\\xe2\\x80\\x93Features der Eingabe zu erstellen. Die Buchstaben\\xe2\\x80\\x93Features\\r\\noder auch Char\\xe2\\x80\\x93level features werden nach dem Trainieren mit dem Modell gespeichert.\\r\\nBei der Verwendung des Modells werden nur die Char\\xe2\\x80\\x93level features beno\\xcc\\x88tigt und nicht\\r\\nmehr die gesamten Wortvektoren. Fu\\xcc\\x88r den Ablauf des Netzes wird zuna\\xcc\\x88chst die Eingabe in die Buchstaben\\xe2\\x80\\x93Features umgewandelt, welche dann an die erste Ebene \\xe2\\x80\\x94 also\\r\\nbiLSTM \\xe2\\x80\\x94 u\\xcc\\x88bergeben werden. Dort werden die Vektoren wie bereits in dem Abschnitt\\r\\n2.6 erla\\xcc\\x88utert verarbeitet. Die daraus resultierenden Ergebnisse werden im Anschluss von\\r\\ndem CNN Netz verarbeitet. In dem letzten Schritt werden die Werte von einem CRF\\r\\nverarbeitet.\\r\\nFu\\xcc\\x88r diese Arbeit wurden GloVe Wortvektoren mit 300\\xe2\\x80\\x93Dimension verwendet, um die\\r\\nho\\xcc\\x88chstmo\\xcc\\x88gliche Genauigkeit zu erzielen. Aufgrund der langen Trainingsdauer, sowie der\\r\\ngro\\xc3\\x9fen Menge an beno\\xcc\\x88tigten Trainingsdaten wurde ein bereits trainiertes Modell verwendet (Deepset o.D.). Das Vokabular des Modells umfasst 400000 Wo\\xcc\\x88rter und wurde auf\\r\\ndeutsche Wikipedia Artikel trainiert.\\r\\nDem trainierten Modell wird eine Liste mit den einzelnen Wo\\xcc\\x88rtern der Eingabe u\\xcc\\x88bergeben.\\r\\nDie Ru\\xcc\\x88ckgabe ist eine Liste mit gesetzten Attributen in dem CoNLL Format (Tjong Kim\\r\\nSang und De Meulder 2003). In diesem Format entspricht ein \\xe2\\x80\\x9cO\\xe2\\x80\\x9d das fu\\xcc\\x88r dieses Token kein\\r\\nAttribut gefunden wurde. Fu\\xcc\\x88r das Produkt \\xe2\\x80\\x9ciPhone X\\xe2\\x80\\x9d werden die Bezeichnungen \\xe2\\x80\\x9cB\\xe2\\x80\\x93\\r\\n\\r\\n36\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nPRODUCT\\xe2\\x80\\x9d und \\xe2\\x80\\x9cI\\xe2\\x80\\x93PRODUCT\\xe2\\x80\\x9d verwendet. Der erste Teil der Bezeichnung beschreibt,\\r\\nob es sich um einen Anfang des gesuchten Wortes handelt (\\xe2\\x80\\x9cB\\xe2\\x80\\x93\\xe2\\x80\\x9d). Besteht das gefundene\\r\\nAttribut aus mehreren Wo\\xcc\\x88rtern, werden alle folgenden Wo\\xcc\\x88rter mit \\xe2\\x80\\x9cI\\xe2\\x80\\x93\\xe2\\x80\\x9d als Pra\\xcc\\x88fix markiert.Trainiert wurde das Modell nur auf das Erkennen des Attributes Produkt welches\\r\\nin den folgenden Metriken (Abbildung 17 und 18) evaluiert wurde.\\r\\n\\r\\nAbbildung 17: Auswertung des Targer\\xe2\\x80\\x93Modells auf 70 Datensa\\xcc\\x88tzen\\r\\n\\r\\n37\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nAbbildung 18: Confusion Matrix des Targer\\xe2\\x80\\x93Modells auf 70 Datensa\\xcc\\x88tzen\\r\\nWie auf der Abbildung 17 zu erkennen erreicht das Modell eine hohe Genauigkeit, bei\\r\\ndem Erkennen des Produktes. Dieses ist darauf zuru\\xcc\\x88ckzufu\\xcc\\x88hren, dass der Aufbau bzw.\\r\\ndie Bedeutung des Satzes betrachtet wird und nicht die einzelnen Wo\\xcc\\x88rter. Die beno\\xcc\\x88tigte\\r\\nLaufzeit, um die Eingabe mit den entsprechenden Attributen zu versehen, wird durch diesen Schritt geringfu\\xcc\\x88gig (im Durchschnitt 125 ms pro Anfrage) beeinflusst, welches bei der\\r\\nVerarbeitung von einzelnen Anfragen den Ablauf nicht merkbar verla\\xcc\\x88ngert. Die Berechnung der Metriken wird sta\\xcc\\x88rker beeinflusst, da der gesamte bisherige Datensatz von der\\r\\nPipeline nacheinander verarbeitet wird. Die gute Performance ist auf die Verwendung der\\r\\nChar\\xe2\\x80\\x93level features zuru\\xcc\\x88ckzufu\\xcc\\x88hren, da nicht mehr die gesamten Wortvektoren beno\\xcc\\x88tigt\\r\\nwerden.\\r\\nDas Targer\\xe2\\x80\\x93Modell ist nicht kontextsensitiv weshalb es Schwierigkeiten hat, Sa\\xcc\\x88tze mit\\r\\nmehreren Produkten bzw. Beziehungen zwischen den Produkten korrekt zu klassifizieren.\\r\\nAls Beispiel dient die folgende Eingabe \\xe2\\x80\\x9cMein altes Smartphone ist leider kaputt gegangen\\r\\nweshalb ich dringend ein neues iPhone X beno\\xcc\\x88tige!\\xe2\\x80\\x9d richtig zu erkennen. Es tendiert dazu,\\r\\ndas Attribut \\xe2\\x80\\x9dProdukt\\xe2\\x80\\x9ddoppelt zu setzen, zum einen fu\\xcc\\x88r das Wort \\xe2\\x80\\x9cSmartphone\\xe2\\x80\\x9d und\\r\\n\\xe2\\x80\\x9ciPhone X\\xe2\\x80\\x9d. Ein alternatives Verhalten ist, dass nur das erste Wort der beiden Elemente\\r\\nmit dem Attribut versehen wird, was in diesem Fall \\xe2\\x80\\x9cSmartphone\\xe2\\x80\\x9d wa\\xcc\\x88re und somit falsch\\r\\nist. Durch eine Regel, die besagt, dass immer das zuletzt gefundene Element fu\\xcc\\x88r ein\\r\\n\\r\\n38\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nAttribut wiedergegeben werden soll, konnte das erste Szenario teilweise gelo\\xcc\\x88st werden,\\r\\naber nicht alle Eingaben folgen dieser Regel.\\r\\n\\r\\n4.3.5. ELMo\\r\\nIn dem Abschnitt 2.2.3 wurde das ELMo Word Embedding vorgestellt. Der Vorteil dieser\\r\\nRepra\\xcc\\x88sentation liegt darin, dass die Vektoren der Wo\\xcc\\x88rter abha\\xcc\\x88ngig von dem Kontext\\r\\nsind und somit das Szenario expliziter beschreiben. Wie bereits erwa\\xcc\\x88hnt, ist das Targer\\xe2\\x80\\x93\\r\\nModell nicht kontextsensitiv weshalb es Schwierigkeiten hat, bestimmte Eingaben korrekt\\r\\nmit Attributen zu versehen. In diesem Schritt wird das grundlegende Modell von Targer\\r\\n(also biLSTM, CNN, CRF) mit der ELMo Repra\\xcc\\x88sentation als Eingabe verwendet, um so\\r\\ndie Vorteile beider Methoden zu kombinieren.\\r\\nIn dem vorherigen Kapitel wurde bereits beschrieben, wie das Modell aufgebaut ist und\\r\\nauch wie die einzelnen Schichten zusammenarbeiten. Der wesentliche Unterschied zwischen diesen beiden Ansa\\xcc\\x88tzen ist, dass keine Char\\xe2\\x80\\x93level features mehr verwendet werden.\\r\\nDies bedeutet, dass fu\\xcc\\x88r die Verwendung des Modells immer die GloVe Word Embeddings\\r\\ngeladen sein mu\\xcc\\x88ssen. Zusa\\xcc\\x88tzlich dazu werden die bereits trainierten Gewichtungen, sowie\\r\\ndie dazugeho\\xcc\\x88rigen Einstellungen, zum Verwenden des Modells beno\\xcc\\x88tigt. Die Gewichtungen wurden trainiert, um den jeweiligen Kontext einer Eingabe zu bestimmen und so die\\r\\ndazugeho\\xcc\\x88rigen Wortvektoren zu ermitteln, die in dem Modell verwendet werden. Diese\\r\\nVorgehensweise wurde in Abschnitt 2.2.3 genauer erla\\xcc\\x88utert.\\r\\nFu\\xcc\\x88r selbst trainierte ELMo Word Embeddings wird eine gro\\xc3\\x9fe Menge von Daten und\\r\\nZeit beno\\xcc\\x88tigt. Das in dieser Arbeit verwendete Modell (May 2019), (Reimers und Gurevych 2019) wurde auf einen deutschen Wikipedia Korpus trainiert. Zusa\\xcc\\x88tzlich wurden die\\r\\nKommentare der verwendeten Artikel genutzt, um Umgangssprache in den Datensatz mit\\r\\neinzubeziehen. Au\\xc3\\x9ferdem werden die zum Modell geho\\xcc\\x88renden Gewichtungen und Optionen verwendet.\\r\\nDa das Modell immer die gesamten Word Embeddings beno\\xcc\\x88tigt um verwendet werden zu\\r\\nko\\xcc\\x88nnen, muss die 4 GB gro\\xc3\\x9fe ELMo Datei dauerhaft im RAM verfu\\xcc\\x88gbar sein. Aus diesem Grund wurde das Modell in eine separate Anwendung ausgelagert. Dieses bietet eine\\r\\nRepresentational State Transfer (REST) Schnittstelle, an die eine Eingabe u\\xcc\\x88bergeben\\r\\nwird. Diese wird von dem Modell verarbeitet und ein Dictionary mit dem Attributbezeichner als Schlu\\xcc\\x88ssel und dem gefundenen Ergebnis als Wert zuru\\xcc\\x88ckgesendet. Der Pipeline selbst wurde ein Schritt hinzugefu\\xcc\\x88gt, welche diese Schnittstelle verwendet, um die\\r\\nentsprechenden Ergebnisse zu erhalten. Durch diese Designentscheidung war es mo\\xcc\\x88glich,\\r\\ndie beno\\xcc\\x88tigten Ressourcen der hauptsa\\xcc\\x88chlichen Anwendung gering zu halten und weitere\\r\\n\\r\\n39\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nAlgorithmen ko\\xcc\\x88nnen mittels der REST Schnittstelle hinzugefu\\xcc\\x88gt werden.\\r\\n\\r\\nAbbildung 19: Auswertung des ELMo\\xe2\\x80\\x93Modells auf 70 Datensa\\xcc\\x88tzen\\r\\n\\r\\nAbbildung 20: Confusion Matrix des ELMo\\xe2\\x80\\x93Modells auf 70 Datensa\\xcc\\x88tzen\\r\\n\\r\\n40\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nDas Modell weist die ho\\xcc\\x88chste Genauigkeit aller verwendeten Algorithmen auf, wie den\\r\\nAbbildungen 19 und 20 zu entnehmen ist. Dadurch wird deutlich, dass die Betrachtung\\r\\ndes Kontextes fu\\xcc\\x88r den Anwendungsfall zielfu\\xcc\\x88hrend ist. Als Beispiel dient folgende Eingabe\\r\\n\\xe2\\x80\\x9challo, wir mo\\xcc\\x88chten am kommenden wochenende mit den nachbarn grillen und ich wollte\\r\\ndafu\\xcc\\x88r einen salat machen weshalb ich auf der suche nach einer salatschu\\xcc\\x88ssel bin da mir\\r\\naufgefallen ist, dass ich keine habe\\xe2\\x80\\x9d in der das gesuchte Produkt \\xe2\\x80\\x9csalatschu\\xcc\\x88ssel\\xe2\\x80\\x9d korrekt\\r\\nerkannt wird. Ein anderes Produkt an derselben Stelle wird ebenfalls mit hoher Wahrscheinlichkeit vom Algorithmus korrekt erkannt. Dieses zeigt, dass der Algorithmus nicht\\r\\ndie charakteristischen Eigenschaften eines jeden Produktes lernt, sondern die Position, an\\r\\nder ein Produkt stehen wu\\xcc\\x88rde. Durch dieses Verhalten ist das Modell in der Lage, mit\\r\\nwenigen Trainingsdaten ein u\\xcc\\x88beraus gutes Ergebnis zu erzielen.\\r\\n\\r\\n4.3.6. Fuzzy Matching\\r\\nDer letzte Schritt der Pipeline stellt sicher, dass bestimmte Attribute erkannt werden. So\\r\\nko\\xcc\\x88nnen bestimmte Werte, auf die die Pipeline bisher nicht trainiert wurde, den passenden Attributen zugewiesen werden. Dadurch ist ein schnelles Hinzufu\\xcc\\x88gen einzelner Werte\\r\\nmo\\xcc\\x88glich, bevor die verwendeten Modelle trainiert werden.\\r\\nUm verschiedene Schreibweisen des Wortes abzudecken, wird ein Fuzzy Matching (Seatgeek 2015) verwendet. Fu\\xcc\\x88r jedes zuvor definierte Wort wird gepru\\xcc\\x88ft mit welcher Wahrscheinlichkeit dieses sich in dem Satz befindet. Dafu\\xcc\\x88r wird die Levenshtein Entfernung zwischen\\r\\neinem definierten Wort und einem Wort aus dem Satz gebildet. Da Fuzzy Matching (oder\\r\\nauch Approximation Matching) die Eigenschaft besitzt immer Ergebnisse zu liefern, wird\\r\\nein zuvor definierter Grenzwert angelegt, wie hoch die U\\xcc\\x88bereinstimmung mindestens sein\\r\\nmuss, bevor die Wo\\xcc\\x88rter als identisch gelten. Bei Produkten wird ein Grenzwert von 95\\r\\n% U\\xcc\\x88bereinstimmung angelegt, damit die Unterschiede zwischen den einzelnen Versionsnummern noch erkannt werden, wie z.B. bei Smartphones (iPhone 8 und iPhone X). Der\\r\\nNachteil bei diesem hohen Grenzwert ist, dass die verschiedenen Schreibweisen fu\\xcc\\x88r ein\\r\\nProdukt einzeln angegeben werden mu\\xcc\\x88ssen (z.B. \\xe2\\x80\\x9ciphone 8\\xe2\\x80\\x9d und \\xe2\\x80\\x9ciPhone 8\\xe2\\x80\\x9d), da diese\\r\\nsonst unter Umsta\\xcc\\x88nden nicht mehr erkannt werden. Bei anderen Attributen zeigte sich,\\r\\ndass eine U\\xcc\\x88bereinstimmung von 80 % ausreicht, um ein genaues Ergebnis zu erzielen, da\\r\\nsich Attribute wie \\xe2\\x80\\x9cHersteller\\xe2\\x80\\x9d u\\xcc\\x88blicherweise nicht nur in einem einzelnen Buchstaben\\r\\nunterscheiden.\\r\\nEin weiteres Problem bei Fuzzy Matching ist, dass nicht nur auf die ho\\xcc\\x88chste\\r\\nU\\xcc\\x88bereinstimmung geachtet werden darf, sondern auch auf die La\\xcc\\x88nge der Wo\\xcc\\x88rter. Befinden sich beispielsweise die Wo\\xcc\\x88rter \\xe2\\x80\\x9ciPhone\\xe2\\x80\\x9d und \\xe2\\x80\\x9ciPhone X\\xe2\\x80\\x9d in dem Fuzzy Matcher\\r\\n\\r\\n41\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nund als Eingabe erfolgt der Satz: \\xe2\\x80\\x9cHey ich bin auf der suche nach einem iPhone X\\xe2\\x80\\x9d werden\\r\\ndie hinterlegten Werte der Reihe nach mit der Eingabe auf teilweiser U\\xcc\\x88bereinstimmung\\r\\ngepru\\xcc\\x88ft. Beide Werte erreichen eine Genauigkeit von 100 % und das zuru\\xcc\\x88ckgegebene Ergebnis ha\\xcc\\x88ngt von der Reihenfolge der Pru\\xcc\\x88fung ab. Um immer den spezifischen Ausdruck\\r\\nzu identifizieren werden stets la\\xcc\\x88ngere Werte den ku\\xcc\\x88rzeren gegenu\\xcc\\x88ber bevorzugt, solange\\r\\ndiese sich noch u\\xcc\\x88ber dem definierten Grenzwert befinden. Dadurch wird sichergestellt,\\r\\ndass in dem Beispielszenario der Wert \\xe2\\x80\\x9ciPhone X\\xe2\\x80\\x9d erkannt wird.\\r\\n\\r\\n42\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nAbbildung 21: Vergleich der Genauigkeit nur des ELMo\\xe2\\x80\\x93Modells (oben) und mit anschlie\\xc3\\x9fendem Fuzzy Matching (unten)\\r\\n\\r\\n43\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nDie Abbildung 21 zeigt zwei Messungen, die korrekt erkannten Produkte ohne Fuzzy\\r\\nMatching (oben) und mit Fuzzy Matching als letzten Schritt (unten). Wie der Abbildung\\r\\nzu entnehmen ist, hat das Fuzzy Matching in diesem Fall das Ergebnis verschlechtert. Dem\\r\\nFuzzy Matcher wurden Produkte hinzugefu\\xcc\\x88gt, welche bereits von der vorherigen Pipeline\\r\\nerkannt worden sind, aber der Fuzzy Matcher nicht alle Schreibweisen kennt. Das Produkt\\r\\nwird in einer leicht anderen Schreibweise gefunden und durch die Gewichtung der Pipeline\\r\\nwird das vorherige Ergebnis u\\xcc\\x88berschrieben. Dadurch ist das Produkt, welches am Ende\\r\\nvon der Pipeline erkannt wurde, nicht korrekt in der Eingabe vorhanden und es wird nicht\\r\\nals korrekt klassifiziert geza\\xcc\\x88hlt.\\r\\nDie Laufzeit des Fuzzy Matching unter der Verwendung der Levenshtein Entfernung ist\\r\\nabha\\xcc\\x88ngig der Anzahl der Werte, auf die die Eingabe gepru\\xcc\\x88ft werden soll. So wird der Prototyp mit acht Werten betrieben, die mit 3 ms pro Eingabe die Laufzeit nicht wesentlich\\r\\nbeeinflussen. Weitere Tests zeigten, dass die Laufzeit ab 250 Werten bereits durchschnittlich 254 ms betra\\xcc\\x88gt. Dieses zeigt wie bereits in Abbildung 21 dargestellt, dass Fuzzy\\r\\nMatching nur fu\\xcc\\x88r wenige Szenarien verwendet werden sollte, um so das Ergebnis bis zum\\r\\nTrainieren der neuen Modelle zu verbessern.\\r\\n\\r\\n4.3.7. Zusammenspiel der Pipeline\\r\\nIn den vorherigen Abschnitten wurden die Funktionalita\\xcc\\x88ten sowie die einzelnen Vorteile\\r\\nund Nachteile jeder Komponente vorgestellt. Es wurden verschiedene Algorithmen angewendet, um das Ergebnis mo\\xcc\\x88glichst genau abbilden zu ko\\xcc\\x88nnen. Alle Algorithmen zeigten\\r\\nSchwierigkeiten mit dem Erkennen von Produktversionen wie sie ha\\xcc\\x88ufig bei Smartphones\\r\\nzu finden sind (z.B. Galaxy S10). Um diese Szenarien abfangen zu ko\\xcc\\x88nnen, wird nach\\r\\nder Ausfu\\xcc\\x88hrung der Pipeline eine Nachverarbeitung der Ergebnisse vorgenommen. Dazu\\r\\nwird jedes Token nach dem gefundenen Produkt analysiert. Es wird gepru\\xcc\\x88ft, ob dieses\\r\\nToken eine Kombination aus Buchstaben und Zahlen ist oder ob es ausschlie\\xc3\\x9flich aus\\r\\nGro\\xc3\\x9fbuchstaben besteht. In beiden Fa\\xcc\\x88llen wird das Token zu dem Produkt hinzugefu\\xcc\\x88gt\\r\\nund es wird erneut das folgende Token betrachtet. Trifft keiner der beiden Fa\\xcc\\x88lle zu, so\\r\\nwird der Prozess beendet und die Nachverarbeitung ist abgeschlossen. Dieses Vorgehen\\r\\nverbessert die Genauigkeit der Pipeline was im Abschnitt Evaluation zusammen mit den\\r\\nELMo Algorithmus genauer betrachtet wird. Abbildung 22 zeigt den gesamten Aufbau der\\r\\nPipeline mit allen Algorithmen die verwendet werden. Die Laufzeit der gesamten Pipeline\\r\\nbetra\\xcc\\x88gt 837 ms und liegt somit unter den geforderten drei Sekunden aus NF1.\\r\\n\\r\\n44\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nAbbildung 22: Pipeline mit allen Algorithmen und den ausgelegten Attributen\\r\\n\\r\\n4.4. Verwendeten Technologien\\r\\nDie Oberfla\\xcc\\x88che ist als Webanwendung verfu\\xcc\\x88gbar und wurde mit der Programmiersprache\\r\\nPython und dem Webframework Flask realisiert. Flask ist ein leichtgewichtiges Framework\\r\\nwelches nur die Template\\xe2\\x80\\x93Engine Jinja2 als Abha\\xcc\\x88ngigkeit besitzt. Die einzelnen Seiten\\r\\nwurden in HTML erstellt und mit Jinja2 dynamisch gestaltet, um eine hohe Flexibilita\\xcc\\x88t\\r\\nder Seiten zu erhalten. Jede Funktionalita\\xcc\\x88t ist durch einen Flask Endpoint zuga\\xcc\\x88nglich\\r\\nund wird durch die Webseite aufgerufen.\\r\\nDas Aussehen der Weboberfla\\xcc\\x88che wurde mit dem CSS\\xe2\\x80\\x93Framework Bootstrap gestaltet.\\r\\nBootstrap ist ein weit verbreitet Framework und wird von vielen verschiedenen Webseiten\\r\\neingebunden. Durch die Verwendung von Bootstrap wird ein einheitliches Aussehen mit\\r\\nanderen Webseiten hergestellt. Dieses hat zufolge, dass durch den Wiedererkennungswert\\r\\nder Bedienelemente die Nutzung fu\\xcc\\x88r Anwender erleichtert wird.\\r\\nFu\\xcc\\x88r die Persistierung der Daten wird eine Neo4J Datenbank verwendet. Neo4J ist eine\\r\\nGraphdatenbank und wurde von (Vicknair u. a. 2010) den relationalen Datenbanken gegenu\\xcc\\x88bergestellt und bewertet. Die verschiedenen Datenbankzugriffe wurden in Methoden\\r\\ngekapselt, um diese separiert von der Anwendung zu verwalten.\\r\\nDie Pipeline wird als eigene Komponente eingebunden und stellt zwei Methoden zur\\r\\nVerfu\\xcc\\x88gung, u\\xcc\\x88ber die der Webserver die Funktionalita\\xcc\\x88t aufrufen kann. Die resolve Methode\\r\\nerha\\xcc\\x88lt als U\\xcc\\x88bergabeparameter eine Anfrage, die ausgewertet wird. Zuru\\xcc\\x88ckgegeben wird ein\\r\\nDictionary bei dem der Schlu\\xcc\\x88ssel dem Attributbezeichner und der Wert der gefundenen\\r\\nSequenz entspricht. Die zweite Methode wird zum Berechnen der Metriken verwendet und\\r\\nerha\\xcc\\x88lt eine Liste mit allen Datensa\\xcc\\x88tzen sowie den zugeordneten Attributen. Zuru\\xcc\\x88ckgegeben\\r\\nwird ein Container, der die Ergebnisse fu\\xcc\\x88r jeden Algorithmus sowie der gesamten Pipeline\\r\\nentha\\xcc\\x88lt.\\r\\n\\r\\n45\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\n4.5. Entwicklung des Prototyps\\r\\nIn den vorherigen Kapiteln wurde beschrieben wie die Pipeline funktioniert, die zum Erkennen der einzelnen Attribute eingesetzt wird. Simultan zur Entwicklung der Pipeline\\r\\nentstand ein Prototyp, der zur Verbesserung der Pipeline entstand. Spa\\xcc\\x88ter wurden weitere Funktionen erga\\xcc\\x88nzt, die sowohl eine Verwendung der Pipeline zeigen als auch das\\r\\nHinzufu\\xcc\\x88gen und Bearbeiten des Datenbestandes vereinfachen. Der Prototyp beschra\\xcc\\x88nkt\\r\\nsich auf das Erkennen und Taggen von 6 Attributen (Produkt, Hersteller, Preis, Farbe,\\r\\nSpeicher, Kamera) welche alle in der Smartphone\\xe2\\x80\\x93Doma\\xcc\\x88ne vertreten sind. Auch stellt der\\r\\nPrototyp keine nutzerorientierte Anwendung dar, sondern lediglich eine funktionsorientierte Oberfla\\xcc\\x88che zum Bedienen der Pipeline.\\r\\n\\r\\n4.5.1. Eingabemethode Inserat\\r\\nAuf der Startseite wird dem Nutzer die Mo\\xcc\\x88glichkeit geboten eine Eingabe zu ta\\xcc\\x88tigen. Beim\\r\\nBesta\\xcc\\x88tigen der Eingabe wird die eingegebene Anfrage von der Pipeline verarbeitet und die\\r\\ngefundenen Ergebnisse werden \\xe2\\x80\\x94 damit diese fu\\xcc\\x88r den Benutzer besser nachvollziehbar sind\\r\\n\\xe2\\x80\\x94 farblich hervorgehoben. Der Anwender entscheidet, ob alle gesuchten Attribute durch\\r\\ndie Pipeline korrekt klassifiziert werden. Ist die Klassifizierung falsch wird der Anwender\\r\\naufgefordert, die eigene Anfrage selbst mit den passenden Tags zu versehen. Das Zuweisen\\r\\nder Attribute geschieht in der Oberfla\\xcc\\x88che des Taggers. Erst wird eine Wortsequenz aus\\r\\nder Eingabesequenz hervorgehoben und im Anschluss die passende Schaltfla\\xcc\\x88che beta\\xcc\\x88tigt,\\r\\num der Wortkette das Attribut zuzuweisen. Der Tagger kann auf beliebige Attribute\\r\\nerweitert werden. Dazu reicht es aus, eine neue Schaltfla\\xcc\\x88che hinzuzufu\\xcc\\x88gen und diese mit\\r\\neinem nicht verwendeten Bezeichner zu versehen. Dem Attribut wird eine neue Farbe\\r\\nzugeteilt. Das neue Attribut kann verwendet werden, um zuku\\xcc\\x88nftige Daten zu annotieren.\\r\\nDamit das Attribut automatisch erkannt wird, muss die Pipeline erneut trainiert werden.\\r\\nWie bereits in der Datenakquise vorgestellt, wurde dieser Teil des Prototyps verwendet,\\r\\num die Datenbasis zu erweitern.\\r\\n\\r\\n4.5.2. Berechnung der Metriken\\r\\nDie in dem Kapitel 4 gezeigten Diagramme werden durch den Prototypen, basierend auf\\r\\nden zugrundeliegenden Daten, automatisiert erstellt. Zum Erstellen der Diagramme werden die Daten aus der Datenbank verwendet, die zuvor von Anwendern in die Oberfla\\xcc\\x88che\\r\\ndes Prototyps eingegeben wurden. Die Sa\\xcc\\x88tze werden erneut an die Pipeline u\\xcc\\x88bergeben,\\r\\nsodass die Algorithmen das Ergebnis berechnen. Dieses wird mit den korrekten Attributen\\r\\naus der Datenbank verglichen und die unterschiedlichen Diagramme werden berechnet. Al-\\r\\n\\r\\n46\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nle Diagramme betrachten dabei die gesamte Eingabe, bewerten also nicht einzelne Wo\\xcc\\x88rter.\\r\\nDie erstellten Diagramme sind: Confusion Matrix, Piechart und Barchart.\\r\\nAbbildung 23 zeigt die Confusion Matrix fu\\xcc\\x88r das Attribut \\xe2\\x80\\x9cProdukt\\xe2\\x80\\x9d mit dem verwendeten Algorithmus ELMo. Die vertikale Achse gibt an, ob sich das Attribut in der Eingabe\\r\\nbefindet oder nicht. Auf der horizontalen Achse wird das Ergebnis des Algorithmus angegeben. Bei einem guten Ergebnis des Algorithmus sind die Felder mit u\\xcc\\x88bereinstimmenden\\r\\nAchsen\\xe2\\x80\\x93Bezeichner ho\\xcc\\x88her als die u\\xcc\\x88brigen Felder. Erst bei einer exakten U\\xcc\\x88bereinstimmung,\\r\\nAlgorithmus\\xe2\\x80\\x93Ergebnis und Eingabe\\xe2\\x80\\x93Ergebnis, wird der Wert des u\\xcc\\x88bereinstimmenden Feldes des Attributes erho\\xcc\\x88ht. Durch eine Fehlermeldung verhindert die Oberfla\\xcc\\x88che Eingaben\\r\\ndie nicht mindestens das Attribut \\xe2\\x80\\x9cProdukt\\xe2\\x80\\x9d enthalten, weshalb wie auf der Abbildung\\r\\n23 zu erkennen, alle Eingaben dieses Attribut besitzen. Aus dem Ergebnis der Confusion\\r\\nMatrix werden die Werte Accuracy, Precision, Recall und somit auch der F1\\xe2\\x80\\x93Score berechnet. Der Prototyp bietet die Mo\\xcc\\x88glichkeit, die Confusion Matrix fu\\xcc\\x88r jedes Attribut mit\\r\\njedem Algorithmus darzustellen.\\r\\n\\r\\nAbbildung 23: Confusion Matrix fu\\xcc\\x88r den ELMo Algorithmus und dem Attribut Produkt\\r\\nDie Confusion Matrix beinhaltet nicht alle Information, die beno\\xcc\\x88tigt werden, um die\\r\\nPerformance der Pipeline messen zu ko\\xcc\\x88nnen. Die Balkendiagramme zeigen wie oft die\\r\\n\\r\\n47\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\neinzelnen Attribute vorkommen und erkannt werden. Dabei zeigt der blaue Balken an,\\r\\nwie oft das einzelne Attribut in dem Datenbestand vorkommt. Der rote Balken zeigt, wie\\r\\noft das einzelne Attribut komplett korrekt erkannt wird (Angaben in Prozent). Aus dieser\\r\\nMetrik la\\xcc\\x88sst sich sehr einfach die effektive Performance der Algorithmen beurteilen, da\\r\\ndie korrekte Klassifizierung der Attribute der Ha\\xcc\\x88ufigkeit gegenu\\xcc\\x88bergestellt wird. Dieses\\r\\nDiagramm zeigt im Wesentlichen die Genauigkeit des Algorithmus fu\\xcc\\x88r jedes Attribut, weshalb das Balkendiagramm fu\\xcc\\x88r jeden Algorithmus sowie der gesamten Pipeline dargestellt\\r\\nwerden kann.\\r\\nIn den Kuchendiagrammen wird die Unterteilung der Klassifizierung weiter aufgesplittet.\\r\\nDie Attribute werden anhand von 6 Teilgruppen bewertet, um ein besseres Versta\\xcc\\x88ndnis\\r\\nder Klassifizierung des Algorithmus zu erhalten. Die Attribute aus den getesteten Anfragen ko\\xcc\\x88nnen dabei einer dieser Gruppen zugeordnet werden: Erkannt, richtige Klasse,\\r\\nErkannt, falsche Klasse; Zu viel/wenig erkannt, richtige Klasse; Zu viel/wenig erkannt,\\r\\nfalsche Klasse; Falsch erkanntes Wort und Attribut nicht erkannt. Durch die Aufteilung\\r\\nwird deutlich, dass, auch wenn der Algorithmus das Attribut nicht komplett korrekt klassifizieren konnte, dennoch akzeptable Teile der Lo\\xcc\\x88sung erkannt werden. So wurde ha\\xcc\\x88ufig die\\r\\nProduktbezeichnung wie \\xc4\\xb1\\xcc\\x88Phonee\\xcc\\x88rkannt, nicht aber der Zusatz \\xe2\\x80\\x9dXo\\xcc\\x88der SSE\\xe2\\x80\\x9d, was durch\\r\\ndieses Diagramm deutlich wurde. Wie die Confusion Matrix kann das Kuchendiagramm\\r\\nfu\\xcc\\x88r alle Attribute und Komponenten der Pipeline erstellt werden.\\r\\n\\r\\n4.5.3. Chatbot\\r\\nAls beispielhafte Anwendung bietet der Prototyp eine Chatbot Funktion. Hier ko\\xcc\\x88nnen\\r\\nAnwender Anfragen oder Angebote stellen, auf die das System nach einem passenden\\r\\nGegenstu\\xcc\\x88ck sucht. Als Beispiel ko\\xcc\\x88nnte die Eingabe \\xe2\\x80\\x9cHey, letzte Woche ist mein Handy\\r\\nkaputt gegangen, weshalb ich jetzt auf der Suche nach einem neuen Apple iPhone X in\\r\\nWei\\xc3\\x9f fu\\xcc\\x88r unter 800 e bin\\xe2\\x80\\x9d dienen. Nach dem Absenden wird die Eingabe der Pipeline\\r\\nu\\xcc\\x88bergeben und die wesentlichen Attribute werden extrahiert. Basierend auf dieser Eingabe wird eine Anfrage an die Datenbank gestellt, welche passende Gegenangebote und die\\r\\ndazugeho\\xcc\\x88rigen Ergebnisse liefert. In einem einfachen Matchmaking wird gepru\\xcc\\x88ft, welches\\r\\ndieser Angebote am ehesten zur gegebenen Anfrage passen wu\\xcc\\x88rde. Dabei wird versucht,\\r\\nmo\\xcc\\x88glichst viele u\\xcc\\x88bereinstimmende Attribute zu finden. Beim Preis wird die Rolle beachtet: stellt der Anwender eine Anfrage so wird ein geringerer Preis bevorzugt. Handelt es\\r\\nsich hingegen um ein Angebot, wird die Kaufanfrage mit dem ho\\xcc\\x88chst genannten Preis bevorzugt. Auf die beispielhafte Eingabe ko\\xcc\\x88nnte folgende Ausgabe erfolgen \\xe2\\x80\\x9cHey ich biete\\r\\nhier mein neues Apple iPhone X in wei\\xc3\\x9f fu\\xcc\\x88r 800 e\\xe2\\x80\\x9d. Die Antwort entha\\xcc\\x88lt 3 Attribute von\\r\\nInteresse auf die das Matchmaking pru\\xcc\\x88fen kann, die alle auf die Suchanfrage zutreffen.\\r\\n\\r\\n48\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nAbbildung 24 zeigt die Oberfla\\xcc\\x88che mit dem Beispiel als Eingabe.\\r\\n\\r\\nAbbildung 24: Beispielverlauf einer Anfrage u\\xcc\\x88ber den Chatbot (gelesen von unten nach\\r\\noben)\\r\\nDie Gruppensuche (Abschnitt 3.2) wird durch zuvor definierte Relationen in dem Knowledge Graph ermo\\xcc\\x88glicht. Eine mo\\xcc\\x88gliche Eingabe ko\\xcc\\x88nnte dann wie folgt aussehen: \\xe2\\x80\\x9cHallo,\\r\\nfu\\xcc\\x88r meinen Sohn bin ich auf der Suche nach einem Apple Smartphone\\xe2\\x80\\x9d. Diese Eingabe entha\\xcc\\x88lt weniger konkrete Informationen als das vorherige Beispiel. Die Pipeline hat\\r\\nzwei Attribute gefunden: Hersteller Apple und Produkt Smartphone. Mit dem vorherigen Ansatz wu\\xcc\\x88rde kein Produkt gefunden werden da die Firma Apple kein Produkt mit\\r\\ndem Namen Smartphone herstellt, sondern nur Gera\\xcc\\x88te, die der Kategorie Smartphone\\r\\nangeho\\xcc\\x88ren. Um diese Fa\\xcc\\x88lle zu identifizieren wird gepru\\xcc\\x88ft, ob das gesuchte Produkt in\\r\\nder Wissensdatenbank vorhanden ist. Trifft dieses zu, wird u\\xcc\\x88ber Relationen gepru\\xcc\\x88ft auf\\r\\nwelche anderen Produkte der Eintrag verweist. Basierend auf dem Beispiel ko\\xcc\\x88nnte das\\r\\nErgebnis diese Werte enthalten: \\xe2\\x80\\x9ciPhone 5\\xe2\\x80\\x9d, \\xe2\\x80\\x9ciPhone 6\\xe2\\x80\\x9d, \\xe2\\x80\\x9ciPhone 7\\xe2\\x80\\x9d, \\xe2\\x80\\x9ciPhone 8\\xe2\\x80\\x9d oder\\r\\n\\xe2\\x80\\x9ciPhone X\\xe2\\x80\\x9d. Im Anschluss wird der bereits oben beschriebene Vorgang wiederholt, nur\\r\\ndass anstelle eines Produktes in der Datenbank auf jedes dieser Attribute verglichen wird.\\r\\n\\r\\n49\\r\\n\\r\\n\\x0cKapitel 4\\r\\n\\r\\nUmsetzung\\r\\n\\r\\nZum Schluss folgt ein Matchmaking, um den besten Treffer zu finden, welcher dann dem\\r\\nAnwender angezeigt wird wie es bereits vorgestellt wurde.\\r\\nFu\\xcc\\x88r diese Art der Produktfindung wird das genutzte Wissen vorausgesetzt. Es wurde im\\r\\nVorfeld definiert, dass es die Kategorie Smartphone gibt und auch welche Produkte zu\\r\\ndieser Kategorie geho\\xcc\\x88ren. Das System la\\xcc\\x88sst sich beliebig auf weitere Kategorien erweitern.\\r\\nSo ko\\xcc\\x88nnte die Kategorie Tablet hinzugefu\\xcc\\x88gt werden, in dem der Bezeichner der Kategorie\\r\\n(hier Tablet) der Wissensdatenbank angehangen wird. Im Anschluss mu\\xcc\\x88ssen die mo\\xcc\\x88glichen\\r\\nAuspra\\xcc\\x88gungen der Kategorie (z.B. \\xe2\\x80\\x98iPad\\xe2\\x80\\x99, \\xe2\\x80\\x98iPad Air\\xe2\\x80\\x99, \\xe2\\x80\\x98iPad Pro\\xe2\\x80\\x99) hinterlegt werden. Dann\\r\\nwu\\xcc\\x88rde die Eingabe: \\xe2\\x80\\x9cFu\\xcc\\x88r meinen Neffen suche ich ein neues Tablet, gerne gebraucht aber\\r\\nunter 300 e\\xe2\\x80\\x9d sa\\xcc\\x88mtliche der Kategorie Tablet enthaltenen Produkte finden.\\r\\n\\r\\n50\\r\\n\\r\\n\\x0cKapitel 5\\r\\n\\r\\nEvaluation\\r\\n\\r\\n5. Evaluation\\r\\nDieses Kapitel unterteilt sich in die Evaluation zweier Aspekte. In dem ersten Abschnitt\\r\\nwerden die verwendete Evaluationsmethodiken vorgestellt. In dem na\\xcc\\x88chsten Abschnitt\\r\\nwird die Performance der verwendeten Algorithmen sowie der gesamten Pipeline untersucht. Es werden die im Abschnitt 3.5 vorgestellten Bewertungskriterien verwendet, um\\r\\neinen genauen Einblick der Ergebnisse zu erhalten. Der dritte Abschnitt befasst sich mit\\r\\nder Evaluation der Oberfla\\xcc\\x88che des Prototyps. Die im Abschnitt 3.2 aufgestellten Anwendungsfa\\xcc\\x88lle wurden mit einen Fragebogen an zehn Probanden gestellt. Die Ergebnisse\\r\\nwerden im Abschnitt 5.3 analysiert.\\r\\n\\r\\n5.1. Evaluationsmethodik\\r\\nDas Ziel dieser Arbeit ist es, ein System zu erstellen, welches mit einer geringen Menge von\\r\\nTrainingsdaten dem Anwender das Gefu\\xcc\\x88hl vermittelt verstanden zu werden. Um dieses\\r\\nbeurteilen zu ko\\xcc\\x88nnen wurde eine Nutzerevaluation und mehrere Messungen durchgefu\\xcc\\x88hrt.\\r\\nFu\\xcc\\x88r die Messungen werden die Daten aus beiden Iterationen der Datenakquise verwendet,\\r\\num diese Ergebnisse mit den Daten aus der ersten Iteration zu vergleichen. Der F1\\xe2\\x80\\x93\\r\\nScore beschreibt dabei die Genauigkeit der jeweiligen Algorithmen. Zusa\\xcc\\x88tzlich werden\\r\\ndie Werte: Accuracy, Precision und Recall betrachtet, um die Forschungsfrage NF1 zu\\r\\nbeantworten und damit die Ergebnisse mit anderen Arbeiten verglichen werden ko\\xcc\\x88nnen.\\r\\nIn dem Abschnitt 3.5 wurden noch sechs weitere Klassen vorgestellt, die ebenfalls fu\\xcc\\x88r eine\\r\\nausfu\\xcc\\x88hrlichere Evaluation betrachtet werden. Die NA2 ist durch Zahlenwerte schwer zu\\r\\nbeantworten, weshalb eine Nutzerevaluation durchgefu\\xcc\\x88hrt wurde.\\r\\nUm u\\xcc\\x88berpru\\xcc\\x88fen zu ko\\xcc\\x88nnen ob Anwender das Gefu\\xcc\\x88hl haben von dem System verstanden\\r\\nzu werden reicht es nicht aus, eine bestimmte Genauigkeit zu erreichen. Anhand mehrerer\\r\\nAnwendungsfa\\xcc\\x88lle sowie einen Fragebogen wird eine Nutzerevaluation durchgefu\\xcc\\x88hrt, um\\r\\ndie Oberfla\\xcc\\x88che sowie das Versta\\xcc\\x88ndnis auszuwerten.\\r\\n\\r\\n5.2. Auswertung der Algorithmen\\r\\nDas vorherige Kapitel befasste sich mit verschiedenen Algorithmen, die zusammen kombiniert wurden, um ein optimales Ergebnis zu erzielen. Die ho\\xcc\\x88chste Gewichtung wurde\\r\\ndem ELMo Algorithmus zugeteilt, da dieser in der ersten Evaluation die ho\\xcc\\x88chste Genauigkeit aufweisen konnte. In diesem Abschnitt wird dieser Algorithmus, sowie die gesamte\\r\\nPipeline einer ausfu\\xcc\\x88hrlichen Evaluation unterzogen, um die Performance genauer zu charakterisieren.\\r\\n\\r\\n51\\r\\n\\r\\n\\x0cKapitel 5\\r\\n\\r\\nEvaluation\\r\\n\\r\\nZu Beginn wurden alle Modelle, bis auf eines, in der Pipeline mit 70 Datensa\\xcc\\x88tzen verschiedener La\\xcc\\x88nge und Form trainiert. Das u\\xcc\\x88brige Modell wurde zuna\\xcc\\x88chst mit 16 Datensa\\xcc\\x88tzen\\r\\nund fu\\xcc\\x88r eine Evaluation erneut mit 70 Datensa\\xcc\\x88tzen trainiert. Basierend auf diesen Ergebnissen wurden die Modelle bewertet, ob und wie diese sich in die Pipeline einbauen lassen.\\r\\nDer aktuelle Datensatz umfasst 193 Eintra\\xcc\\x88ge, die im Laufe der Entwicklung gesammelt\\r\\nwurden.\\r\\n\\r\\nAbbildung 25: Performance der gesamten Pipeline\\r\\nAbbildung 25 zeigt die Performance der gesamten Pipeline mit den anfa\\xcc\\x88nglich trainierten\\r\\nModellen. Bei dem Attribut \\xe2\\x80\\x9cProdukt\\xe2\\x80\\x9d wird eine Genauigkeit von 80,8 % erzielt, fu\\xcc\\x88r die\\r\\nu\\xcc\\x88brigen Attribute wurden keine Modelle trainiert. Die u\\xcc\\x88brigen Werte werden nur durch\\r\\nAnsa\\xcc\\x88tze wie Regula\\xcc\\x88re Ausdru\\xcc\\x88cke bzw. Fuzzy Matching ermo\\xcc\\x88glicht. Dieses Ergebnis zeigt\\r\\ndas bereits mit einer geringen Menge an Daten, das Modell in der Lage ist in 4 von 5\\r\\nFa\\xcc\\x88llen das Produkt korrekt zu klassifizieren. 79,8 % werden von dem ELMo Algorithmus\\r\\nerkannt, die Nachverarbeitung der gesamten Pipeline verbessert das Ergebnis auf 80,8\\r\\n%. Szenarien, die in dieser Statistik nicht beru\\xcc\\x88cksichtigt werden, sind unter anderem\\r\\nAttribute, die nur in Teilen erkannt wurden. \\xe2\\x80\\x9cGalaxy S10\\xe2\\x80\\x9d ist ein beispielhaftes Produkt,\\r\\ndass ha\\xcc\\x88tte erkannt werden sollen, von der Pipeline wurde \\xe2\\x80\\x9cGalaxy\\xe2\\x80\\x9d erkannt, was teilweise\\r\\nkorrekt ist. Abbildung 26 zeigt eine genauere Analyse des ELMo Algorithmus. Es werden\\r\\nzusa\\xcc\\x88tzlich zu den Klassen \\xe2\\x80\\x9cErkannt, richtige Klasse\\xe2\\x80\\x9d und \\xe2\\x80\\x9cAttribut nicht erkannt\\xe2\\x80\\x9d noch\\r\\nvier weitere Klassen erfasst: \\xe2\\x80\\x9cErkannt, falsche Klasse\\xe2\\x80\\x9d, \\xe2\\x80\\x9cZu viel/wenig erkannt, richtige\\r\\nKlasse\\xe2\\x80\\x9d, \\xe2\\x80\\x9cZu viel/wenig erkannt, falsche Klasse\\xe2\\x80\\x9d und \\xe2\\x80\\x9cFalsch erkanntes Wort\\xe2\\x80\\x9d.\\r\\n\\r\\n52\\r\\n\\r\\n\\x0cKapitel 5\\r\\n\\r\\nEvaluation\\r\\n\\r\\nAbbildung 26: Piechart Analyse der ELMo Komponente\\r\\nWie der Abbildung 26 zu entnehmen ist wurden 9,3 % (\\xe2\\x80\\x9cAttribut nicht erkannt\\xe2\\x80\\x9d und\\r\\n\\xe2\\x80\\x9cFalsch erkanntes Wort\\xe2\\x80\\x9d) der Anfragen unzureichend verarbeitet. In 10,9 % der Fa\\xcc\\x88lle\\r\\nwurde zu viel bzw. zu wenig des gesuchten Produktes erkannt, was \\xe2\\x80\\x94 je nach Aufgabenstellung \\xe2\\x80\\x94 bereits zielfu\\xcc\\x88hrend ist. Durch Optimierung der Nachverarbeitung wa\\xcc\\x88re die\\r\\nPipeline imstande gegenu\\xcc\\x88ber den bisher erzielten 1 %, die Eingabe um 10,9 % selbststa\\xcc\\x88ndig\\r\\nzu verbessern. Alternativ ko\\xcc\\x88nnte das Modell mit einem gro\\xcc\\x88\\xc3\\x9feren Datensatz trainiert werden, um eine allgemeine Verbesserung der Ergebnisse zu erzielen.\\r\\nDurch die Datenakquise sowie den Testdaten sind insgesamt 260 Datensa\\xcc\\x88tze gesammelt\\r\\nworden, die zum Trainieren und Verifizieren verwendet wurden. Die Daten fokussierten\\r\\nsich hauptsa\\xcc\\x88chlich auf Produkte aus der Kategorie Smartphone, aber auch andere Produktkategorien waren vertreten. Die La\\xcc\\x88nge der Sa\\xcc\\x88tze war variabel, die Rechtschreibung\\r\\nwird nicht beachtet. Die Daten wurden durch die Oberfla\\xcc\\x88che des Prototyps gesammelt,\\r\\nweshalb keine Vorverarbeitung des Datensatzes notwendig war. Zum Trainieren des Modells wurden die Daten aufgeteilt. Auf 90 % der Datensa\\xcc\\x88tze \\xe2\\x80\\x94 also 234 Eintra\\xcc\\x88ge \\xe2\\x80\\x94 wurde\\r\\ndas Modell trainiert. Die restlichen 10 % wurden fu\\xcc\\x88r die Verifizierung verwendet. Aufgrund\\r\\nder geringen Datenmenge war es mo\\xcc\\x88glich, dass bestimmte Formulierungen der Sa\\xcc\\x88tze nur\\r\\nzum Testen und nicht zum Trainieren verwendet wurden. Um diese Problematik zu umgehen wurde das Modell in zehn Durchga\\xcc\\x88ngen mit verschiedenen Daten zum Verifizieren\\r\\ntrainiert. Fu\\xcc\\x88r ein endgu\\xcc\\x88ltiges Ergebnis wurde der Durchschnitt der Trainingsdurchla\\xcc\\x88ufe\\r\\nverwendet.\\r\\n\\r\\n53\\r\\n\\r\\n\\x0cKapitel 5\\r\\n\\r\\nEvaluation\\r\\n\\r\\nDurchlauf\\r\\n1.\\r\\n2.\\r\\n3.\\r\\n4.\\r\\n5.\\r\\n6.\\r\\n7.\\r\\n8.\\r\\n9.\\r\\n10.\\r\\nAvg.\\r\\n\\r\\nPrecision\\r\\n0,857\\r\\n0,889\\r\\n0,905\\r\\n0,880\\r\\n0,815\\r\\n0,885\\r\\n0,889\\r\\n0,963\\r\\n0,793\\r\\n0,815\\r\\n0,869\\r\\n\\r\\nRecall\\r\\n0,923\\r\\n0,923\\r\\n0,942\\r\\n0,846\\r\\n0,846\\r\\n0,885\\r\\n0,923\\r\\n0,963\\r\\n0,767\\r\\n0,771\\r\\n0,879\\r\\n\\r\\nF1\\xe2\\x80\\x93Score\\r\\n0,8889\\r\\n0,9057\\r\\n0,9231\\r\\n0,8627\\r\\n0,8302\\r\\n0,8850\\r\\n0,9057\\r\\n0,9630\\r\\n0,7797\\r\\n0,7925\\r\\n0,8736\\r\\n\\r\\nTabelle 1: Ergebnisse der 10 Trainingsdurchla\\xcc\\x88ufe\\r\\nWie der Tabelle 1 zu entnehmen ist, wurde ein durchschnittlicher F1\\xe2\\x80\\x93Score von 87,36\\r\\n% erreicht. Dieser setzt sich aus den Werten Precision sowie dem Recall zusammen und\\r\\nvereint beide Werte in einem. Ein ho\\xcc\\x88herer F1\\xe2\\x80\\x93Score bedeutet im Allgemeinen, dass die\\r\\nPerformance des Modells gestiegen ist. In gewissen Situationen kann es Ziel sein, eine\\r\\nhohe Precision auf Kosten des Recalls zu erreichen und umgekehrt, was bei dieser Aufgabenstellung nicht zutrifft. Berechnet wurden die Werte basierend auf jedem Wort der\\r\\nVerifikationsdaten. Bei den Metriken des Prototyps wird die gesamte Sequenz der Eingabe fu\\xcc\\x88r die Bewertung beachtet, weshalb ein direkter Vergleich nicht mo\\xcc\\x88glich ist. Damit\\r\\ndie Werte verglichen werden ko\\xcc\\x88nnen, wurde das vorhandene ELMo\\xe2\\x80\\x93Modell der Pipeline\\r\\nnacheinander mit jedem einzelnen der zehn berechneten Modelle ausgetauscht und die\\r\\ngleiche Metrik wurde erstellt.\\r\\nDurch die neu trainierten Modelle verbesserte sich die Genauigkeit der Pipeline im Durchschnitt auf 87,46 %. Das vorherige ELMo\\xe2\\x80\\x93Modell wurde durch die Nachverarbeitung um\\r\\n1 % verbessert. Die durchschnittliche Genauigkeit der neu trainierten ELMo\\xe2\\x80\\x93Modelle\\r\\nerreichte 87,21 % was bedeutete, dass die Nachverarbeitung das Ergebnis um 0,25 %\\r\\nverbesserte. Durch die Tatsache, dass die gesamte Eingabe zum Berechnen der Metrik\\r\\nbetrachtet wurde und jede Eingabesequenz mindestens das Attribut Produkt enthalten\\r\\nmusste, war die Confusion Matrix einseitig. Die Werte Precision und Recall wurden aus\\r\\nden Werten der Confusion Matrix berechnet weshalb der daraus resultierende F1\\xe2\\x80\\x93Score\\r\\nvon 93,1 % nicht mit dem vorherigen F1\\xe2\\x80\\x93Score verglichen werden konnte. Das vorherige\\r\\nELMo\\xe2\\x80\\x93Modell erreichte ein F1\\xe2\\x80\\x93Score von 89 %, dieses entsprach einer Verbesserung von\\r\\netwa 4 %. Die allgemeine Genauigkeit verbesserte sich um ungefa\\xcc\\x88hr 7 %. Daraus resultierte, dass der ELMo Algorithmus \\xe2\\x80\\x94 mit fast der vierfachen Menge an Daten \\xe2\\x80\\x94 nur\\r\\nmarginal besser wurde.\\r\\n\\r\\n54\\r\\n\\r\\n\\x0cKapitel 5\\r\\n\\r\\nEvaluation\\r\\n\\r\\n5.3. Auswertung der Oberfla\\xcc\\x88che\\r\\nDie vorgestellte Anwendung soll dem Nutzer die Bedienung bzw. den Umgang mit der\\r\\nPipeline na\\xcc\\x88herbringen. Dazu wird ein grundlegendes Versta\\xcc\\x88ndnis der Anwendung durch\\r\\ndie Benutzung der einfachen Eingabe vermittelt. Dieses beinhaltet das manuelle Setzen\\r\\nvon Attributen. Diese Funktion ist ein wesentlicher Bestandteil der Arbeit, da zum Trainieren aller Modelle mit Bezeichner versehene Daten beno\\xcc\\x88tigt werden. Zusa\\xcc\\x88tzlich wird das\\r\\nmanuelle Setzen der Attribute in jeder Realisierung einer solchen Anwendung beno\\xcc\\x88tigt, da\\r\\ndas System nicht immer alle Attribute korrekt erfasst. Eine mo\\xcc\\x88gliche Anwendung fu\\xcc\\x88r die\\r\\nPipeline ist ein Chatbot welcher ebenfalls Teil des Prototyps ist. Dieser soll Anwendern\\r\\nzeigen, welche Vorteile ein virtueller Marktplatz gegenu\\xcc\\x88ber herko\\xcc\\x88mmlichen Marktpla\\xcc\\x88tzen\\r\\nbesitzt.\\r\\nAll diese Funktionen wurden von mehreren Probanden getestet und bewertet. Die Probanden wurden aufgrund ihrer verschiedenen Fachkenntnisse ausgewa\\xcc\\x88hlt, so wurden User\\r\\nExperience (UX), User Interface (UI)-Designer sowie Software Engineering (SE) befragt\\r\\num ein umfassendes Feedback zu erhalten. Insgesamt haben an der Evaluation zehn Personen teilgenommen, wobei jeder dieselben Szenarien zu bewa\\xcc\\x88ltigen hatte. Zu Beginn wurde das Umfeld des Tests vorgestellt: Der Proband befindet sich in der Facebook Gruppe\\r\\n\\xe2\\x80\\x9cFlohmarkt Karlsruhe\\xe2\\x80\\x9d und versucht in dieser Gruppe sein altes Smartphone zu verkaufen. In dem ersten Durchlauf wurde das Ergebnis der Pipeline nur angezeigt, damit die\\r\\nTestperson sieht, wie die Anfrage verarbeitet wird und welche Attribute von der Pipeline\\r\\nerkannt werden. In dem zweiten Durchlauf sollten die Probanden eine Anfrage erzeugen,\\r\\ndie nicht erkannt wird. Im Anschluss wurde das manuelle Tagging getestet. In dem letzten Testszenario sollten die Probanden die Eingabe der ersten Anfrage in dem Chatbot\\r\\nwiederholen. Wa\\xcc\\x88hrend der Tests wurden die Probanden beobachtet wie diese den Prototypen bedienen. Den Abschluss bildete ein Fragebogen (siehe Anhang). Die Ergebnisse\\r\\nder Evaluation werden im folgenden Absatz vorgestellt.\\r\\nDas Szenario, in dem die Probanden die einfache Eingabemaske zum Erstellen eines Inserats bedienen sollten, wurde von 9 Teilnehmern direkt verstanden und es wurde eine\\r\\npassende Anfrage an das System geschickt. Die Ansicht mit der farblichen Hervorhebung\\r\\nwurde von allen Probanden auf Anhieb verstanden. 30 % der Probanden waren unsicher\\r\\nbezu\\xcc\\x88glich der erkannten Attribute. So wurde z.B. bei der Eingabe: \\xe2\\x80\\x9cHey ich verkaufe mein\\r\\naltes Handy. Es ist ein Huawei P30 preis verhandelbar\\xe2\\x80\\x9d Huawei P30 als Produkt erkannt.\\r\\nFu\\xcc\\x88r den Probanden sollte Handy das Produkt sein, Huawei die Marke und P30 das Modell. In dem Abschnitt 3.1 wurde bereits erla\\xcc\\x88utert, warum von der Pipeline Huawei P30\\r\\nkorrekterweise als Produkt\\r\\n\\r\\n55\\r\\n\\r\\n\\x0cKapitel 5\\r\\n\\r\\nEvaluation\\r\\n\\r\\nDurch die erste Aufgabe haben die Probanden erkannt, welche Attribute von der Pipeline erkannt werden sollten, was die Bearbeitung der zweiten Aufgabe erleichterte. Die\\r\\nAnwender werden nach der Eingabe vom System gefragt, ob die erkannten Ergebnisse\\r\\nkorrekt sind. Bei einer Verneinung wird die Anfrage an den Tagger weitergeleitet und der\\r\\nAnwender wird aufgefordert seine Eingabe manuell mit Attributen zu versehen. Wird das\\r\\nErgebnis abgelehnt, war jedem Probanden bewusst, dass die Attribute manuell gesetzt\\r\\nwerden sollen, ohne dass eine solche Anweisung von der Oberfla\\xcc\\x88che angezeigt wird. Alle\\r\\nProbanden versuchten zuna\\xcc\\x88chst die farblichen Schaltfla\\xcc\\x88chen der Attribute auf die passenden Begriffe der Eingabe per Drag\\xe2\\x80\\x93and\\xe2\\x80\\x93Drop zu ziehen. Erst nach einigen Versuchen\\r\\nwurde die Bedienung des Taggers verstanden. Das vorherige erwa\\xcc\\x88hnte Problem der Unsicherheit \\xe2\\x80\\x94 was genau mit welchem Attribut zu versehen ist \\xe2\\x80\\x94 hatten hier 6 von 10\\r\\nProbanden.\\r\\nIn dem letzten Szenario wurde der Chatbot evaluiert. Durch die vorherigen Aufgaben\\r\\nund die kleine Beschreibung des Chatbots war eine problemlose Bedienung mo\\xcc\\x88glich. Je\\r\\nnach Anfrage erhielten die Anwender eine Antwort, entweder dass ein passendes Angebot\\r\\ngefunden werden konnte oder die Ru\\xcc\\x88ckmeldung, dass kein Angebot vorhanden ist. In\\r\\nbeiden Fa\\xcc\\x88llen wurde deutlich welche Attribute in der Anfrage enthalten waren. Dadurch\\r\\nkonnten die Probanden nachvollziehen, dass kein passendes Angebot fu\\xcc\\x88r die jeweilige\\r\\nEingabe gefunden werden konnte. Von allen Teilnehmern wurde die Zustandslosigkeit\\r\\nbzw. das nicht Fortfu\\xcc\\x88hren der Verhandlung des Chatbots negativ wahrgenommen.\\r\\nDer Fragebogen teilt sich in vier Hauptkategorien auf: Oberfla\\xcc\\x88che, Funktionalita\\xcc\\x88t,\\r\\nnatu\\xcc\\x88rliche Sprachverarbeitung und Feedback. Die gesamten Antworten ko\\xcc\\x88nnen dem Fragebogen aus dem Anhang entnommen werden. Im Folgenden werden einige der Antworten\\r\\nvorgestellt.\\r\\nDer Chatbot stellt eine reale Anwendung dar, der dem Nutzer die Vorteile der natu\\xcc\\x88rlichen\\r\\nSprachverarbeitung zeigen soll. In dem Testdurchlauf wurde bereits deutlich, dass die\\r\\nProbanden davon ausgingen, dass der Chat fortgefu\\xcc\\x88hrt werden wu\\xcc\\x88rde. Diese Erkenntnis\\r\\nspiegelt sich deutlich in der Umfrage wieder, da die Stimmen bei \\xe2\\x80\\x9cZielfu\\xcc\\x88hrend\\xe2\\x80\\x9d gleich\\r\\nzwischen -1 und +1 aufgeteilt sind. Zudem erwarteten einige Probanden, dass mehr als\\r\\nnur ein Resultat auf die gegebene Anfrage angezeigt werden wu\\xcc\\x88rde. Auch wurde mehrfach\\r\\nversucht, die Suche durch weitere Anfragen zu spezifizieren, was aufgrund der Zustandslosigkeit nicht mo\\xcc\\x88glich war.\\r\\nDas Tagging spielt eine wesentliche Rolle bei allen NLP Anwendungen. Selbst gut funktionierende Anwendungen sollten Nutzern die Mo\\xcc\\x88glichkeit geben, die eigene Eingabe manuell mit Attributen zu versehen, falls diese nicht korrekt erkannt wurden. Ist dieses\\r\\n\\r\\n56\\r\\n\\r\\n\\x0cKapitel 5\\r\\n\\r\\nEvaluation\\r\\n\\r\\nnicht mo\\xcc\\x88glich, wird der Nutzer nicht verstanden und eine Benutzung der Anwendung ist\\r\\nunmo\\xcc\\x88glich. In der Evaluation sollte der Tagger verwendet werden, ohne dass dieser erkla\\xcc\\x88rt\\r\\nwird. Wie der Abbildung 27 zu entnehmen ist war dieser Test teilweise erfolgreich: der\\r\\nTagger ist sowohl zielfu\\xcc\\x88hrend als auch optisch ansprechend. Die Intuitivita\\xcc\\x88t hingegen wurde besser bewertet als in der Evaluation beobachtet werden konnte, da alle Probanden erst\\r\\nnach einigen Versuchen die Bedienung verstanden haben. Durch die vorherige Aufgabe\\r\\nwurde bereits ein gewisses Versta\\xcc\\x88ndnis der farblichen Hervorhebung vermittelt, weshalb\\r\\ndie Versta\\xcc\\x88ndlichkeit des Taggers gut ist. Die meisten Teilnehmer hatten das Gefu\\xcc\\x88hl, dass\\r\\ndie Anwendung die gegebene Anfrage verstehen wu\\xcc\\x88rden. Diese Frage wurde u\\xcc\\x88berwiegend\\r\\ndurch den ersten Eindruck beantwortet, da die meisten Probanden weniger als 6 Anfragen an das System stellten. Dies ist ein wesentliches Kriterium fu\\xcc\\x88r eine reale Anwendung,\\r\\nda der erste Eindruck entscheidend dafu\\xcc\\x88r ist, ob das Programm weiterhin verwendet wird\\r\\noder nicht. Somit hatten Anwender das Gefu\\xcc\\x88hl, von dem System verstanden zu werden was\\r\\nNA2 erfu\\xcc\\x88llt. Ebenfalls relevant ist die Frage, ob diese Art der Produktsuche gegenu\\xcc\\x88ber der\\r\\nherko\\xcc\\x88mmlichen Schlagwortsuche bevorzugt werden wu\\xcc\\x88rde. 9 von 10 Probanden stimmten\\r\\ndem zu.\\r\\n\\r\\nAbbildung 27: Ergebnisse der Umfrage bezu\\xcc\\x88glich der Tagging Funktion\\r\\nZusammenfassend war die Evaluation erfolgreich, da alle Probanden mit dem Prototyp\\r\\nzufrieden waren. Was genau mit welchen Attributen versehen werden sollte sowie die\\r\\nOberfla\\xcc\\x88che des Taggers, beno\\xcc\\x88tigt eine kurze Erkla\\xcc\\x88rung, damit Nutzer genau wissen was die\\r\\nAnwendung erwartet. Ebenfalls sollte das Aussehen der meisten Funktionen u\\xcc\\x88berarbeitet\\r\\nwerden, da diese bei der Evaluation u\\xcc\\x88berwiegend neutral bewertet wurden.\\r\\n\\r\\n57\\r\\n\\r\\n\\x0cKapitel 7\\r\\n\\r\\nFazit\\r\\n\\r\\n6. Fazit\\r\\nDiese Arbeit befasst sich mit dem Umwandeln von unstrukturierter Eingabe in strukturierte Ausgabe, die von einem Computer weiterverarbeitet wird. Um dieses Ziel zu erreichen\\r\\nwurden verschiedene Methoden und Algorithmen angewendet und evaluiert. Im Rahmen\\r\\ndieser Arbeit wurde ein generisches Konzept entwickelt, durch das ein virtueller Marktplatz mit der natu\\xcc\\x88rlichen Sprachverarbeitung unterstu\\xcc\\x88tzt werden kann. Die Konzeption\\r\\nwurde prototypisch umgesetzt, um zusa\\xcc\\x88tzlich zu den Anforderungen, das Sammeln von\\r\\nDaten und Bewerten der Performance zu unterstu\\xcc\\x88tzen. Die Forschungsfragen FF1 und\\r\\nNF2 ko\\xcc\\x88nnen mit der Pipeline beantwortet werden. Im Bereich des ML ist die vorhandene Menge der Daten ein wesentlicher Faktor um zielfu\\xcc\\x88hrende Modelle zu erstellen. Der\\r\\nmit dieser Arbeit verbundene Datensatz umfasste lediglich 260 Eintra\\xcc\\x88ge. Das auf diesem\\r\\nDatensatz erzielte Ergebnis von 87,46 % Genauigkeit, welches im Abschnitt 5.2 hergeleitet wurde, zeigt dass auch mit einer kleinen Menge von Daten ein solides Ergebnis\\r\\nentstehen kann, was NF1 beantwortet. Dieses Ergebnis u\\xcc\\x88bertrifft die anfa\\xcc\\x88nglichen Erwartungen deutlich, da vermutet wurde das die ganzen Produkte zu verschieden sind, um\\r\\ndiese so pra\\xcc\\x88zise zu bestimmen. Somit konnten alle anfa\\xcc\\x88nglich gestellten Forschungsfragen\\r\\nbeantwortet werden.\\r\\nMit der prototypischen Implementierung konnte das Versta\\xcc\\x88ndnis der Anwender gegenu\\xcc\\x88ber\\r\\neinem solchen System untersucht werden. Die Evaluation zeigt sowohl eine hohe Akzeptanz als auch das Interesse der Nutzer gegenu\\xcc\\x88ber der neuen Art auf virtuellen Marktpla\\xcc\\x88tzen zu handeln. Diese Erkenntnisse erzeugen, zusa\\xcc\\x88tzlich zu den bereits erwa\\xcc\\x88hnten aus\\r\\nAbschnitt 1.1, weitere Mehrwerte die ein Unternehmen erhalten wu\\xcc\\x88rde wie z.B. ein innovatives, akzeptiertes Verfahren der Anfragenverarbeitung. Die Oberfla\\xcc\\x88che sowie Funktionsweise des Taggers wurde wa\\xcc\\x88hrend der Verwendung des Prototyps positiv wahrgenommen,\\r\\nwas zeigt, dass dieser als Vorlage fu\\xcc\\x88r eine reale Anwendung verwendet werden kann.\\r\\n\\r\\n7. Ausblick\\r\\nEin Tool das beliebige Attribute in einer Eingabesequenz klassifizieren kann, hat viele\\r\\nverschiedene Anwendungsbereiche. Der Prototyp umfasst bereits alle Funktionalita\\xcc\\x88ten,\\r\\ndie fu\\xcc\\x88r eine neue Applikation beno\\xcc\\x88tigt werden. So werden beispielsweise Daten gesammelt\\r\\nund gegebenenfalls nachtra\\xcc\\x88glich u\\xcc\\x88berarbeitet. Auch wird dem Nutzer mit dem Chatbot\\r\\neine Anwendung geboten, die die Vorteile eines solchen Systems darstellt. Das automatische Generieren der Metriken zeigt die Sta\\xcc\\x88rken des Systems und durch die verschiedenen\\r\\nGraphen wird das Finden von Schwa\\xcc\\x88chen erleichtert. Weitere Ideen fu\\xcc\\x88r Funktionalita\\xcc\\x88ten\\r\\n\\r\\n58\\r\\n\\r\\n\\x0cKapitel 7\\r\\n\\r\\nAusblick\\r\\n\\r\\nwurden bereits wa\\xcc\\x88hrend der Entwicklung des Prototyps deutlich, die Aufgrund des Umfangs dieser Arbeit nicht realisiert wurden. Ein Feature war das automatische Trainieren\\r\\nder Pipeline, sobald eine gewisse Menge von neuen Daten zur Verfu\\xcc\\x88gung stand. Dieses\\r\\nwu\\xcc\\x88rde dafu\\xcc\\x88r sorgen, dass die Performance der Anwendung sich von selbst verbessert,\\r\\nohne dass das Training manuell gestartet werden mu\\xcc\\x88sste. Auch ko\\xcc\\x88nnte der Tagger in\\r\\nseiner Funktionalita\\xcc\\x88t erweitert werden. So besteht fu\\xcc\\x88r den Anwender die Mo\\xcc\\x88glichkeit eigene Attribute hinzuzufu\\xcc\\x88gen, welche dann im Tagger verwendet werden ko\\xcc\\x88nnen. Durch\\r\\ndiese A\\xcc\\x88nderung ko\\xcc\\x88nnten bereits Daten fu\\xcc\\x88r andere Kategorien gesammelt werden, welches ein spa\\xcc\\x88teres Erweitern der Pipeline erleichtert. Durch das Feedback der Evaluation\\r\\nwurde deutlich, dass eine andere Art der Bedienung des Taggers den Umgang verbessern ko\\xcc\\x88nnte. Eine mo\\xcc\\x88gliche Realisierung wa\\xcc\\x88re, dass Nutzer ein Attribut auswa\\xcc\\x88hlen und\\r\\nim Anschluss die passenden Wo\\xcc\\x88rter anklicken wodurch diese farblich hervorgehoben werden. In dem 1.1. Kapitel wurde die Bedienung u\\xcc\\x88ber Sprachinterfaces vorgestellt, welches\\r\\nebenfalls eine interessante Erweiterung fu\\xcc\\x88r den Prototypen darstellt. Die Matchmaking\\r\\nFunktion des Chatbots ko\\xcc\\x88nnte u\\xcc\\x88berarbeitet werden, da diese bisher nur auf die genaue\\r\\nU\\xcc\\x88bereinstimmung von Attributen achtet. Auch ko\\xcc\\x88nnten dem Chatbot Zusta\\xcc\\x88nde hinzugefu\\xcc\\x88gt werden, wodurch dem Anwender eine echte Konversation suggeriert wird.\\r\\nZum Schluss dieser Arbeit ergeben sich neue Fragen, wie z.B.: \\xe2\\x80\\x9cWie gut skaliert die\\r\\nPipeline?\\xe2\\x80\\x9d bzw. \\xe2\\x80\\x9cWie viele Attribute ko\\xcc\\x88nnen die einzelnen Modelle unterscheiden, ohne\\r\\ndass die Genauigkeit beeinflusst wird?\\xe2\\x80\\x9d. Hierbei handelt es sich um wesentliche Aspekte,\\r\\ndie fu\\xcc\\x88r die Realisierung eines virtuellen Marktplatzes in dieser Form beno\\xcc\\x88tigt werden.\\r\\nDie Pipeline selbst ko\\xcc\\x88nnte durch Erga\\xcc\\x88nzen von mehreren Attributen aus verschiedenen\\r\\nProduktklassen erweitert werden. Dadurch wa\\xcc\\x88re es mo\\xcc\\x88gliche, die Frage der Skalierbarkeit\\r\\nzu beantworten.\\r\\n\\r\\n59\\r\\n\\r\\n\\x0cKapitel 8\\r\\n\\r\\nQuellenverzeichnis\\r\\n\\r\\n8. Quellenverzeichnis\\r\\nZadeh, Lotfi A (1965). Fuzzy sets\\xe2\\x80\\x9c. In: Information and control 8.3, S. 338\\xe2\\x80\\x93353.\\r\\n\\xe2\\x80\\x9d\\r\\nLevenshtein, Vladimir I (1966). Binary codes capable of correcting deletions, insertions,\\r\\n\\xe2\\x80\\x9d\\r\\nand reversals\\xe2\\x80\\x9c. In: Soviet physics doklady. Bd. 10. 8, S. 707\\xe2\\x80\\x93710.\\r\\nSchu\\xcc\\x88tze, Hinrich und Jan O Pedersen (1995). Information retrieval based on word senses\\xe2\\x80\\x9c.\\r\\n\\xe2\\x80\\x9d\\r\\nIn: Citeseer.\\r\\nSchuster, Mike und Kuldip K Paliwal (1997). Bidirectional recurrent neural networks\\xe2\\x80\\x9c.\\r\\n\\xe2\\x80\\x9d\\r\\nIn: IEEE transactions on Signal Processing 45.11, S. 2673\\xe2\\x80\\x932681.\\r\\nCummins, F., F.A. Gers und J. Schmidhuber (1999). Learning to forget: continual pre\\xe2\\x80\\x9d\\r\\ndiction with LSTM\\xe2\\x80\\x9c. In: IET Conference Proceedings, 850\\xe2\\x80\\x93855(5).\\r\\nLafferty, John D., Andrew McCallum und Fernando C. N. Pereira (2001). Conditional\\r\\n\\xe2\\x80\\x9d\\r\\nRandom Fields: Probabilistic Models for Segmenting and Labeling Sequence Data\\xe2\\x80\\x9c. In:\\r\\nProceedings of the Eighteenth International Conference on Machine Learning, S. 282\\xe2\\x80\\x93\\r\\n289.\\r\\nTjong Kim Sang, Erik F. und Fien De Meulder (2003). Introduction to the CoNLL-2003\\r\\n\\xe2\\x80\\x9d\\r\\nShared Task: Language-Independent Named Entity Recognition\\xe2\\x80\\x9c. In: Proceedings of the\\r\\nSeventh Conference on Natural Language Learning at HLT-NAACL 2003, S. 142\\xe2\\x80\\x93147.\\r\\nMansouri, Alireza, Lilly Suriani Affendey und Ali Mamat (2008). Named entity recogni\\xe2\\x80\\x9d\\r\\ntion approaches\\xe2\\x80\\x9c. In: International Journal of Computer Science and Network Security\\r\\n8.2, S. 339\\xe2\\x80\\x93344.\\r\\nArel, Itamar, Derek C Rose und Thomas P Karnowski (2010). Deep machine learning-a\\r\\n\\xe2\\x80\\x9d\\r\\nnew frontier in artificial intelligence research [research frontier]\\xe2\\x80\\x9c. In: IEEE computational intelligence magazine 5.4, S. 13\\xe2\\x80\\x9318.\\r\\nFaruqui, Manaal und Sebastian Pado\\xcc\\x81 (2010). Training and Evaluating a German Named\\r\\n\\xe2\\x80\\x9d\\r\\nEntity Recognizer with Semantic Generalization\\xe2\\x80\\x9c. In: KONVENS, S. 129\\xe2\\x80\\x93133.\\r\\nMikolov, Toma\\xcc\\x81s\\xcc\\x8c u. a. (2010). Recurrent neural network based language model\\xe2\\x80\\x9c. In: Ele\\xe2\\x80\\x9d\\r\\nventh annual conference of the international speech communication association.\\r\\nVicknair, Chad u. a. (2010). A comparison of a graph database and a relational database:\\r\\n\\xe2\\x80\\x9d\\r\\na data provenance perspective\\xe2\\x80\\x9c. In: Proceedings of the 48th annual Southeast regional\\r\\nconference, S. 1\\xe2\\x80\\x936.\\r\\nKrizhevsky, Alex, Ilya Sutskever und Geoffrey E Hinton (2012). Imagenet classification\\r\\n\\xe2\\x80\\x9d\\r\\nwith deep convolutional neural networks\\xe2\\x80\\x9c. In: Advances in neural information processing\\r\\nsystems, S. 1097\\xe2\\x80\\x931105.\\r\\nMikolov, Tomas u. a. (2013). Distributed representations of words and phrases and their\\r\\n\\xe2\\x80\\x9d\\r\\ncompositionality\\xe2\\x80\\x9c. In: Advances in neural information processing systems, S. 3111\\xe2\\x80\\x933119.\\r\\n\\r\\n60\\r\\n\\r\\n\\x0cKapitel 8\\r\\n\\r\\n8. Quellenverzeichnis\\r\\n\\r\\nGoldberg, Yoav und Omer Levy (2014). word2vec Explained: deriving Mikolov et al.\\xe2\\x80\\x99s\\r\\n\\xe2\\x80\\x9d\\r\\nnegative-sampling word-embedding method\\xe2\\x80\\x9c. In: arXiv preprint arXiv:1402.3722.\\r\\nKalchbrenner, Nal, Edward Grefenstette und Philip Blunsom (2014). A convolutional\\r\\n\\xe2\\x80\\x9d\\r\\nneural network for modelling sentences\\xe2\\x80\\x9c. In: 52nd Annual Meeting of the Association\\r\\nfor Computational Linguistics.\\r\\nPennington, Jeffrey, Richard Socher und Christopher D Manning (2014). Glove: Global\\r\\n\\xe2\\x80\\x9d\\r\\nvectors for word representation\\xe2\\x80\\x9c. In: Proceedings of the 2014 conference on empirical\\r\\nmethods in natural language processing (EMNLP), S. 1532\\xe2\\x80\\x931543.\\r\\nOlah, Christopher (2015). Understanding LSTM Networks. http://colah.github.io/\\r\\nposts/2015-08-Understanding-LSTMs/. (besucht am 22.11.2019).\\r\\nSeatgeek (2015). Fuzzywuzzy. https://github.com/seatgeek/fuzzywuzzy. (besucht am\\r\\n16.10.2019).\\r\\nZhang, Ye und Byron Wallace (2015). A sensitivity analysis of (and practitioners\\xe2\\x80\\x99 gui\\xe2\\x80\\x9d\\r\\nde to) convolutional neural networks for sentence classification\\xe2\\x80\\x9c. In: arXiv preprint\\r\\narXiv:1510.03820.\\r\\nDeepu, S, Pethuru Raj und S Rajaraajeswari (2016). A Framework for Text Analytics\\r\\n\\xe2\\x80\\x9d\\r\\nusing the Bag of Words (BoW) Model for Prediction\\xe2\\x80\\x9c. In: Proceedings of the 1st International Conference on Innovations in Computing & Networking, S. 12\\xe2\\x80\\x9313.\\r\\nJiang, Ridong, Rafael E Banchs und Haizhou Li (2016). Evaluating and combining name\\r\\n\\xe2\\x80\\x9d\\r\\nentity recognition systems\\xe2\\x80\\x9c. In: Proceedings of the Sixth Named Entity Workshop, S. 21\\xe2\\x80\\x93\\r\\n27.\\r\\nBai, Shaojie, J Zico Kolter und Vladlen Koltun (2018). An empirical evaluation of ge\\xe2\\x80\\x9d\\r\\nneric convolutional and recurrent networks for sequence modeling\\xe2\\x80\\x9c. In: arXiv preprint\\r\\narXiv:1803.01271.\\r\\nChernodub, Artem (2018). Targer. https://github.com/achernodub/targer. (besucht\\r\\nam 28.10.2019).\\r\\nDevlin, Jacob u. a. (2018). Bert: Pre-training of deep bidirectional transformers for lan\\xe2\\x80\\x9d\\r\\nguage understanding\\xe2\\x80\\x9c. In: arXiv preprint arXiv:1810.04805.\\r\\nPerone, Christian S, Roberto Silveira und Thomas S Paula (2018). Evaluation of sen\\xe2\\x80\\x9d\\r\\ntence embeddings in downstream and linguistic probing tasks\\xe2\\x80\\x9c. In: arXiv preprint arXiv:1806.06259.\\r\\nPeters, Matthew E, Mark Neumann, Mohit Iyyer u. a. (2018). Deep contextualized word\\r\\n\\xe2\\x80\\x9d\\r\\nrepresentations\\xe2\\x80\\x9c. In: arXiv preprint arXiv:1802.05365.\\r\\nPeters, Matthew E, Mark Neumann, Luke Zettlemoyer u. a. (2018). Dissecting con\\xe2\\x80\\x9d\\r\\ntextual word embeddings: Architecture and representation\\xe2\\x80\\x9c. In: arXiv preprint arXiv:1808.08949.\\r\\n\\r\\n61\\r\\n\\r\\n\\x0cKapitel 8\\r\\n\\r\\n8. Quellenverzeichnis\\r\\n\\r\\nSherstinsky, Alex (2018). Fundamentals of Recurrent Neural Network (RNN) and Long\\r\\n\\xe2\\x80\\x9d\\r\\nShort-Term Memory (LSTM) Network\\xe2\\x80\\x9c. In: arXiv preprint arXiv:1808.03314.\\r\\nChernodub, Artem u. a. (2019). Targer: Neural argument mining at your fingertips\\xe2\\x80\\x9c. In:\\r\\n\\xe2\\x80\\x9d\\r\\nProceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, S. 195\\xe2\\x80\\x93200.\\r\\nMay, Philip (2019). German ELMo Model. https://github.com/t-systems-on-siteservices-gmbh/german-elmo-model. (besucht am 24.10.2019).\\r\\nReimers, Nils und Iryna Gurevych (2019). Alternative Weighting Schemes for ELMo\\r\\n\\xe2\\x80\\x9d\\r\\nEmbeddings\\xe2\\x80\\x9c. In: arXiv preprint arXiv:1904.02954.\\r\\nSpaCy\\xe2\\x80\\x93Dokumentation (2019). Library architecture. https : / / spacy . io. (besucht am\\r\\n14.10.2019).\\r\\nDeepset (o.D.). German Word Embeddings. https : / / deepset . ai / german - word embeddings. (besucht am 25.10.2019).\\r\\n\\r\\n62\\r\\n\\r\\n\\x0cAnhang A\\r\\n\\r\\nErgebnisse der Umfrage\\r\\n\\r\\nAnhang\\r\\nA. Ergebnisse der Umfrage\\r\\n\\r\\nAbbildung 28: Bewertung der Oberfla\\xcc\\x88che\\r\\n\\r\\nI\\r\\n\\r\\n\\x0cAnhang A\\r\\n\\r\\nErgebnisse der Umfrage\\r\\n\\r\\nAbbildung 29: Fortsetzung der Bewertung zur Oberfla\\xcc\\x88che\\r\\n\\r\\nII\\r\\n\\r\\n\\x0cAnhang A\\r\\n\\r\\nErgebnisse der Umfrage\\r\\n\\r\\nAbbildung 30: Bewertung der Funktionalita\\xcc\\x88t\\r\\n\\r\\nIII\\r\\n\\r\\n\\x0cAnhang A\\r\\n\\r\\nErgebnisse der Umfrage\\r\\n\\r\\nAbbildung 31: Fortsetzung der Bewertung zur Funktionalita\\xcc\\x88t\\r\\n\\r\\nAbbildung 32: Allgemeine Fragen zur natu\\xcc\\x88rlichen Sprachverarbeitung\\r\\n\\r\\nIV\\r\\n\\r\\n\\x0cAnhang A\\r\\n\\r\\nErgebnisse der Umfrage\\r\\n\\r\\nAbbildung 33: Fortsetzung der natu\\xcc\\x88rlichen Sprachverarbeitung\\r\\n\\r\\nV\\r\\n\\r\\n\\x0cAnhang A\\r\\n\\r\\nErgebnisse der Umfrage\\r\\n\\r\\nAbbildung 34: Fortsetzung der natu\\xcc\\x88rlichen Sprachverarbeitung\\r\\n\\r\\nVI\\r\\n\\r\\n\\x0cAnhang B\\r\\n\\r\\nErgebnisse der Umfrage\\r\\n\\r\\nAbbildung 35: Feedback der Probanden\\r\\n\\r\\nVII\\r\\n\\r\\n\\x0cAnhang B\\r\\n\\r\\nMetriken der Pipeline\\r\\n\\r\\nB. Metriken der Pipeline\\r\\n\\r\\nAbbildung 36: Confusion Matrik mit dem Attribut \\xe2\\x80\\x9dPreis\\xe2\\x80\\x9dvon dem Schritt regula\\xcc\\x88re Ausdru\\xcc\\x88cke\\r\\n\\r\\nAbbildung 37: Confusion Matrik mit dem Attribut \\xe2\\x80\\x9dKamera\\xe2\\x80\\x9dvon dem Schritt regula\\xcc\\x88re\\r\\nAusdru\\xcc\\x88cke\\r\\n\\r\\nVIII\\r\\n\\r\\n\\x0cAnhang B\\r\\n\\r\\nMetriken der Pipeline\\r\\n\\r\\nAbbildung 38: Confusion Matrik mit dem Attribut \\xe2\\x80\\x9dHersteller\\xe2\\x80\\x9dvon dem Schritt Fuzzy\\r\\nMatching\\r\\n\\r\\nAbbildung 39: Confusion Matrik mit dem Attribut \\xe2\\x80\\x9dFarbe\\xe2\\x80\\x9dvon dem Schritt Fuzzy Matching\\r\\n\\r\\nIX\\r\\n\\r\\n\\x0c'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:\n",
      "\n",
      "Nico Wellermann\n",
      "\n",
      "Thema:\n",
      "\n",
      "Natürlichsprachliche Kommunikation in virtuellen\n",
      "Marktplätzen\n",
      "\n",
      "Arbeitsplatz:\n",
      "\n",
      "CAS Software AG, Karlsruhe\n",
      "\n",
      "Referent:\n",
      "\n",
      "Prof. Dr. Wölfel\n",
      "\n",
      "Korreferent:\n",
      "\n",
      "Prof. Dr. Körner\n",
      "\n",
      "Abgabetermin:\n",
      "\n",
      "09.02.2020\n",
      "\n",
      "Karlsruhe, 09.11.2019\n",
      "Der Vorsitzende des Prüfungsausschusses\n",
      "\n",
      "Prof. Dr. Heiko Körner\n",
      "\n",
      "Fakultät für Informatik und Wirtschaftsinformatik\n",
      "\n",
      "Bachelor-Thesis\n",
      "\n",
      "\f",
      "Erklärung\n",
      "Hiermit versichere ich, dass ich meine Abschlussarbeit selbständig verfasst und keine\n",
      "anderen als die angegebenen Quellen und Hilfsmittel benutzt habe.\n",
      "\n",
      "Datum:\n",
      "\n",
      ".......................................................\n",
      "(Unterschrift)\n",
      "\n",
      "\f",
      "ZUSAMMENFASSUNG\n",
      "\n",
      "I. Zusammenfassung\n",
      "Virtuelle Marktplätze werden von Jahr zu Jahr bedeutsamer. Auf elektronischen Marktplätzen beispielsweise finden viele Käufer–Verkäufer Situationen statt. Anwender erstellen\n",
      "ein digitales Angebot, das von potenziellen Käufern gefunden werden möchte. Für eine intuitive Bedienung soll die Verwendung der natürlichen Eingabe untersucht werden. Diese\n",
      "Arbeit befasst sich mit dem Erfassen und Strukturieren von Informationen, die in Textform vorliegen. Aus diesen Texten sollen die wesentlichen Informationen extrahiert werden\n",
      "und mit Hilfe der strukturierten Daten soll es dann möglich sein, passende Angebote für\n",
      "eine gegebene Anfrage zu finden. Dafür wird ein Prototyp in Form einer Webanwendung\n",
      "entwickelt, welcher die verschiedenen Aufgaben eines virtuellen Marktplatzes erfüllt. Zum\n",
      "Erkennen der Attribute aus der Texteingabe wurden mehrere Algorithmen verwendet,\n",
      "die zusammen eine Pipeline bilden. Um die Performance der Pipeline messen zu können,\n",
      "wurden verschiedene Metriken aufgestellt.\n",
      "Durch das Erstellen einer Pipeline können die Stärken der einzelnen Algorithmen kombiniert werden und somit das Ergebnis optimiert. Die verwendeten Algorithmen zum\n",
      "Erkennen des Hauptattribut “Produkt” erreichten eine Genauigkeit von 87,46 % auf den\n",
      "vorhandenen Datensatz. Beschreibbare Attribute wurden durch regelbasierte Ansätze aus\n",
      "dem Text extrahiert, was ein zielführendes Ergebnis erzielte. Die gemessenen Ergebnisse übertrafen deutlich die vorherigen Erwartungen und Anwender hatten das Gefühl als\n",
      "würde das System sie verstehen. Dieses Verfahren ermöglicht eine neue Art, um Verhandlungen in virtuellen Marktplätzen zu führen.\n",
      "\n",
      "I\n",
      "\n",
      "\f",
      "ZUSAMMENFASSUNG\n",
      "\n",
      "II. Abstract\n",
      "Since few years, virtual marketplaces are catching more and more attention. Daily, hundreds of thousands buyer and seller situations all over the world take place on so called\n",
      "electronic marketplaces. Users create digital offers that are found by potential buyers. Unfortunately, one online search creates numerous possible offers leading to a time-consuming\n",
      "comparison between many different offers. Therefore, an intuitive workflow using natural\n",
      "input is needed to facilitate each query. Main goal of the thesis was to collect and structure\n",
      "the query input, sort the collected information to present one perfect-fit offer. For this\n",
      "purpose, a prototype in form of a web application was developed fulfilling various tasks\n",
      "of a virtual marketplace. Several algorithms like ELMo and Targer were used to recognize\n",
      "attributes from the text input, forming a pipeline.\n",
      "By creating a pipeline, the strength of each individual algorithm was combined to optimize\n",
      "the overall result. In order to measure the performance of the pipeline, different metrics\n",
      "were set up. Algorithms used to recognize the main attribute “product” achieved an\n",
      "accuracy of 87.46 % on the existing data set. Describable attributes were extracted from\n",
      "the text using a rule-based system, which achieved a target-oriented result. The measured\n",
      "results significantly exceeded previous expectations as users have the feeling of being\n",
      "understood by the system. This technique enables a new way of negotiating in virtual\n",
      "marketplaces.\n",
      "\n",
      "II\n",
      "\n",
      "\f",
      "INHALTSVERZEICHNIS\n",
      "\n",
      "II Inhaltsverzeichnis\n",
      "I\n",
      "\n",
      "Zusammenfassung\n",
      "\n",
      "I\n",
      "\n",
      "II Abstract\n",
      "\n",
      "II\n",
      "\n",
      "II Inhaltsverzeichnis\n",
      "\n",
      "III\n",
      "\n",
      "IV Abkürzungsverzeichnis\n",
      "\n",
      "V\n",
      "\n",
      "1 Einleitung\n",
      "1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "1.2 Ziel der Arbeit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "1.3 Gliederung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "\n",
      "2 Grundlagen\n",
      "2.1 Bag–of–words . . . . . . . . .\n",
      "2.2 Word Embeddings . . . . . .\n",
      "2.2.1 Word2Vec . . . . . . .\n",
      "2.2.2 GloVe . . . . . . . . .\n",
      "2.2.3 ELMo . . . . . . . . .\n",
      "2.3 Convolutional Neural Network\n",
      "2.4 Recurrent Neural Network . .\n",
      "2.5 Unterschiede RNN und CNN .\n",
      "2.6 Long Short–Term Memory . .\n",
      "2.7 Conditional Random Fields .\n",
      "2.8 Fuzzy–Suche . . . . . . . . . .\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "10\n",
      "11\n",
      "11\n",
      "13\n",
      "14\n",
      "\n",
      "3 Konzeption\n",
      "3.1 Annahmen . . . . . . . . . . . . . . . . .\n",
      "3.2 Anforderungen . . . . . . . . . . . . . .\n",
      "3.3 Komponenten . . . . . . . . . . . . . . .\n",
      "3.3.1 Benutzerschnittstelle . . . . . . .\n",
      "3.3.2 Hybrid named-entity recognition\n",
      "3.3.3 Tagging . . . . . . . . . . . . . .\n",
      "3.3.4 Persistierung . . . . . . . . . . .\n",
      "3.3.5 Auswertung . . . . . . . . . . . .\n",
      "3.4 Prozesse . . . . . . . . . . . . . . . . . .\n",
      "3.5 Bewertungskriterien . . . . . . . . . . . .\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "16\n",
      "16\n",
      "17\n",
      "20\n",
      "20\n",
      "21\n",
      "23\n",
      "24\n",
      "25\n",
      "25\n",
      "26\n",
      "\n",
      "4 Umsetzung\n",
      "4.1 Vorgehen . . . . . . . . . . . . . .\n",
      "4.2 Datenakquise . . . . . . . . . . .\n",
      "4.3 Hybrid named-entity recognition .\n",
      "4.3.1 SpaCy . . . . . . . . . . .\n",
      "4.3.2 Reguläre Ausdrücke . . . .\n",
      "4.3.3 Metadaten Analyse . . . .\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "28\n",
      "28\n",
      "29\n",
      "30\n",
      "30\n",
      "31\n",
      "33\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "III\n",
      "\n",
      "\f",
      "INHALTSVERZEICHNIS\n",
      "\n",
      "4.4\n",
      "4.5\n",
      "\n",
      "4.3.4 Targer . . . . . . . . . . . .\n",
      "4.3.5 ELMo . . . . . . . . . . . .\n",
      "4.3.6 Fuzzy Matching . . . . . . .\n",
      "4.3.7 Zusammenspiel der Pipeline\n",
      "Verwendeten Technologien . . . . .\n",
      "Entwicklung des Prototyps . . . . .\n",
      "4.5.1 Eingabemethode Inserat . .\n",
      "4.5.2 Berechnung der Metriken . .\n",
      "4.5.3 Chatbot . . . . . . . . . . .\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "35\n",
      "39\n",
      "41\n",
      "44\n",
      "45\n",
      "46\n",
      "46\n",
      "46\n",
      "48\n",
      "\n",
      "5 Evaluation\n",
      "51\n",
      "5.1 Evaluationsmethodik . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n",
      "5.2 Auswertung der Algorithmen . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n",
      "5.3 Auswertung der Oberfläche . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n",
      "6 Fazit\n",
      "\n",
      "58\n",
      "\n",
      "7 Ausblick\n",
      "\n",
      "58\n",
      "\n",
      "8 Quellenverzeichnis\n",
      "\n",
      "60\n",
      "\n",
      "Anhang\n",
      "\n",
      "I\n",
      "\n",
      "A Ergebnisse der Umfrage\n",
      "\n",
      "I\n",
      "\n",
      "B Metriken der Pipeline\n",
      "\n",
      "VIII\n",
      "\n",
      "IV\n",
      "\n",
      "\f",
      "INHALTSVERZEICHNIS\n",
      "\n",
      "IV. Abkürzungsverzeichnis\n",
      "biLSTM\n",
      "biRNN\n",
      "BoW\n",
      "CNN\n",
      "CRF\n",
      "ELMo\n",
      "GB\n",
      "GloVe\n",
      "LSTM\n",
      "ML\n",
      "MP\n",
      "NER\n",
      "NET\n",
      "NLP\n",
      "POS\n",
      "REST\n",
      "RNN\n",
      "SE\n",
      "Tanh\n",
      "UI\n",
      "UX\n",
      "\n",
      "bidirectional Long Short–Term Memory\n",
      "bidirectional Recurrent Neural Network\n",
      "Bag–of–words\n",
      "Convolutional Neural Network\n",
      "Conditional Random Field\n",
      "Embeddings from Language Models\n",
      "Gigabyte\n",
      "Global Vectors\n",
      "Long Short–Term Memory\n",
      "Machine Learning\n",
      "Megapixel\n",
      "Named Entity Recognition\n",
      "Named Entity Tagging\n",
      "Natural Language Processing\n",
      "Part of Speech\n",
      "Representational State Transfer\n",
      "Recurrent Neural Network\n",
      "Software Engineering\n",
      "Tangens hyperbolicus\n",
      "User Interface\n",
      "User Experience\n",
      "\n",
      "V\n",
      "\n",
      "\f",
      "Kapitel 1\n",
      "\n",
      "Einleitung\n",
      "\n",
      "1. Einleitung\n",
      "1950 erfand der britische Mathematiker Alan Turing den nach ihm benannten “TuringTest”. Dieser Test sollte feststellen ob Menschen und Maschinen über die gleiche Art von\n",
      "Intelligenz verfügen. Hierbei versucht der Mensch durch Konversation zu entscheiden, ob\n",
      "es sich bei seinem Gegenüber um eine Maschine oder eine Person handelt. Jedoch besteht\n",
      "dieser Test nur als theoretischer Versuch, der erst mit dem Durchbruch der künstlichen\n",
      "Intelligenz zu praktischen Versuchen führte.\n",
      "Bereits 1980 widerlegte der amerikanische Philosoph John Searle die Theorie des “TuringTests”. Mit dem Gedankenexperiment durch das sogenannte “chinesische Zimmer” zeigte\n",
      "er auf, dass Computer, nur weil diese immer die korrekte Antwort geben, keine Experten\n",
      "auf dem Gebiet sein müssen. Das Experiment sieht folgendermaßen aus: In einem geschlossenen Raum sitzt eine Person, die weder Chinesisch spricht noch versteht. Diese hat\n",
      "die Aufgabe, auf chinesisch gestellte Fragen anhand einer in seiner Muttersprache verfassten Anleitung auf chinesisch zu beantworten. Personen außerhalb des Zimmers denken,\n",
      "dass der Mensch in dem Zimmer in der Lage ist chinesisch zu sprechen, obwohl dieser nur\n",
      "einfache Regeln befolgt.\n",
      "Übertragen auf Computer zeigt das Gedankenexperiment, dass die Computer nur weil\n",
      "sie richtige Ergebnisse produzieren, noch lange nicht in der Lage sind die Fragen bzw.\n",
      "die Situationen zu verstehen. Dennoch wird daran geforscht (Arel, Rose und Karnowski\n",
      "2010), (Devlin u. a. 2018), dass Computer mithilfe von verschiedensten Algorithmen eine\n",
      "Art Bewusstsein über Situationen erlernen und sogar verstehen — also eine künstliche\n",
      "Intelligenz entwickeln.\n",
      "Die natürliche Sprachverarbeitung ist dabei auch ein Baustein, an dem stetig geforscht\n",
      "wird. Dabei wird unter anderem versucht, dem Computer die menschliche Sprache zu\n",
      "vermitteln. Bei virtuellen Marktplätzen hat sich seit der Einführung viel verändert. So\n",
      "wird z.B. das Kundenverhalten mithilfe neuronaler Netze analysiert, um gezielt Vorschläge\n",
      "zu platzieren. Die eigentliche Produktsuche hat sich hingegen kaum verändert. In dieser\n",
      "Arbeit wird ein alternatives Verfahren untersucht, das mithilfe der natürlichen Sprachverarbeitung die herkömmliche Produktsuche ersetzen soll.\n",
      "\n",
      "1.1. Motivation\n",
      "In der heutigen Zeit ist es schwieriger Angebot und Nachfrage im E–Commerce zusammenzubringen. Die existierenden Systeme bieten nicht genug Freiheiten, um die Anfrage genau\n",
      "zu spezifizieren. Daher wird nicht nur das gesuchte Produkt, sondern auch viele andere\n",
      "\n",
      "1\n",
      "\n",
      "\f",
      "Kapitel 1\n",
      "\n",
      "Einleitung\n",
      "\n",
      "Ergebnisse gefunden. Mit verschiedenen Eingabefeldern kann die Auswahl genauer spezifiziert werden, was aber in den meisten Fällen zu generisch oder schlicht zu umständlich\n",
      "ist und deshalb nicht verwendet wird. Für Anwender ist es viel natürlicher etwas direkt\n",
      "zu beschreiben, als es in starre, vorgefertigte Formulare einzutragen. Diese Art der Eingabemethode setzt allerdings voraus, dass die Maschine den Nutzer versteht und dessen\n",
      "unstrukturierte Eingabe in eine für den Computer verständliche Struktur überführt. Mit\n",
      "diesem Vorgehen können sowohl Angebote als auch Nachfragen ohne mehrere Formularfelder auskommen, da nicht mehr für jedes Attribut ein eigenes Feld benötigt wird. Ein\n",
      "weiterer Vorteil dieses Vorgehens ist, dass eine eins zu eins Umsetzung zu Sprachassistenten möglich ist. Dazu wird die Sprache von einem bereits existierenden Assistenten (z.B.\n",
      "Amazon Alexa oder Google Assistant) erkannt und als Textform an das System übergeben.\n",
      "Durch den Einsatz von solchen Technologien ergeben sich Mehrwerte für Unternehmen, da\n",
      "Kunden bessere Vorschläge gemacht werden können und diese somit häufiger zum Kaufen\n",
      "angeregt werden. Auch kann durch die optimale Voraussetzung eines Sprachassistenten\n",
      "eine bequeme Alternative geboten werden, wodurch die Plattform häufiger verwendet\n",
      "und das Unternehmen attraktiver wird. Der Einsatz von virtuellen Marktplätzen erfordert ein System, welches die Anwender sowie ihre Bedürfnisse versteht und somit von\n",
      "Nutzern verwendet wird. Zudem werden weitere Informationen der Waren benötigt, damit die Eingabe auf diese Attribute geprüft werden kann. Um diese Herausforderungen\n",
      "anzugehen, könnten Technologien wie Natural Language Processing (NLP) oder Machine\n",
      "Learning (ML) verwendet werden.\n",
      "\n",
      "1.2. Ziel der Arbeit\n",
      "Ziel dieser Arbeit ist es, ein Konzept und Prototyp für einen virtuellen Marktplatz mit\n",
      "natürlicher Sprachverarbeitung zu entwickeln anhand dessen die Bedienbarkeit und Performance untersucht wird. Im Vordergrund steht dabei das Erkennen bzw. Klassifizieren der\n",
      "Attribute aus einer Eingabesequenz. Jede Produktkategorie verfügt über eigene Attribute,\n",
      "die von einem solchen System erkannt werden müssen. Zu Beginn werden diese reduziert\n",
      "und auf die Produktkategorie der Smartphones mit den Attributen: Produkt, Hersteller,\n",
      "Preis, Farbe, Kamera und Speicher beschränkt. Zudem wurde als Beispiel ein virtueller\n",
      "Marktplatz in Form eines Chatrooms betrachtet, was bedeutet, dass keine grammatikalisch, korrekte Schreibweise den Anfragen vorausgesetzt wird. Die Anwendung sollte in der\n",
      "Lage sein, sowohl Abkürzungen als auch Emojis handhaben zu können, was eine größere\n",
      "Herausforderung an die Algorithmen stellt. Für ein besseres Verständnis kann folgendes\n",
      "Beispiel betrachtet werden: “Hiiii, lz woche ist mein handy kaputt gegangen :( ich suche\n",
      "deshalb jetzt ein iphone x gerne auch gebraucht aber nicht teurer als 500 e”. In diesem\n",
      "\n",
      "2\n",
      "\n",
      "\f",
      "Kapitel 1\n",
      "\n",
      "Einleitung\n",
      "\n",
      "Szenario sollte das System “iphone x” als Produkt und “500 e” als Preis erkennen. Anwendern soll das Gefühl vermittelt werden, als würde das System sie verstehen. Dieses\n",
      "soll zudem mit einer geringen Menge von Daten erreicht werden.\n",
      "Beschrieben wird dieses Verhalten durch die Forschungsfrage (FF1 ): “Wie kann aus\n",
      "natürlicher unstrukturierter menschlicher Eingabe eine strukturierte Ausgabe erzeugt werden, die von einem Computer weiterverarbeitet werden kann?”. Begleitend dazu werden\n",
      "die folgenden Nebenfragen (NF1 ) beachtet: “Wie kann ein akzeptables Ergebnis mit einer\n",
      "sehr geringen Menge von Daten erzielt werden?” und (NF2 ) “Wie können die wichtigsten Schlüsselwörter aus einem Text ausgewertet werden?”. Um dies zu erreichen werden\n",
      "verschiedene Methoden und Tools untersucht.\n",
      "\n",
      "1.3. Gliederung\n",
      "In Kapitel 2 werden die verwendeten Techniken und Modelle zum Erreichen des Ziels dieser\n",
      "Arbeit vorgestellt. Kapitel 3 beginnt mit einer ausführlichen Betrachtung der Annahmen,\n",
      "gefolgt von den Abschnitten: Anforderungen, Komponenten, Prozesse und Bewertungskriterien. Im Anschluss wird in Kapitel 4 eine Pipeline konzipiert, die verschiedenen Algorithmen auf das Problem anwendet. Parallel zur Entwicklung der Pipeline wurde ein\n",
      "Prototyp erstellt, der mehrere Aufgaben erfüllt: einfacheres Sammeln von Daten, visuell\n",
      "unterstützte Bedienung der Pipeline, sowie das Aufstellen von Metriken bezüglich der\n",
      "Pipeline. Die Implementierung des Prototyps wird im Abschnitt 4.5 beschrieben. Eine\n",
      "ausführliche Betrachtung bezüglich der Performance des Prototyps sowie Auswertung der\n",
      "Oberfläche wird in Kapitel 5 erläutert. Zum Abschluss wird in Kapitel 6 das Ergebnis\n",
      "zusammengefasst und weitere zukünftige mögliche Erweiterungen werden in Kapitel 7\n",
      "vorgestellt.\n",
      "\n",
      "3\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "2. Grundlagen\n",
      "In diesem Kapitel werden die verwendeten Technologien und theoretischen Grundlagen\n",
      "vorgestellt, welche bei der Bearbeitung dieser Arbeit verwendet wurden. Zu Beginn werden\n",
      "Word Embeddings erläutert, welche ein wesentlicher Bestandteil dieser Arbeit darstellen.\n",
      "Im Anschluss werden die relevanten Eigenschaften der Modelle aus dem Bereich Machine\n",
      "Learning (ML) vorgestellt.\n",
      "\n",
      "2.1. Bag–of–words\n",
      "Sätze bzw. Wörter können nicht direkt von einem Computer verstanden werden. Dieser\n",
      "benötigt eine andere Repräsentation, um den Inhalt des Satzes zu verstehen. Wenn zum\n",
      "Beispiel die beiden Sätze: “Das Wetter heute ist schön” und “Das Wetter heute ist toll”\n",
      "betrachtet werden, ergibt sich ein Vokabular mit den Worten: [Das, Wetter, heute, ist,\n",
      "schön, toll]. Das Vokabular muss alle Wörter umfassen, die vom System erkannt werden\n",
      "sollen. Mit der “Bag–of–words” Codierung können die beiden Sätze für den Computer\n",
      "verständlich gemacht werden (Deepu, Raj und Rajaraajeswari 2016). Dazu wird ein leerer\n",
      "Vektor der Dimension entsprechend der Länge des Vokabulars erstellt und mit 0 gefüllt,\n",
      "jede Position entspricht somit einem Wort. Im Anschluss wird für jedes Wort der Eingabe\n",
      "geprüft, an welcher Position es sich befindet und diese Stelle im Vektor inkrementiert. Für\n",
      "die beiden Beispielsätze würde die “Bag–of–words” Codierung so aussehen: [1, 1, 1, 1, 1,\n",
      "0] und [1, 1, 1, 1, 0, 1]. Der Nachteil dieser Repräsentation ist, dass die Reihenfolge der\n",
      "Wörter verloren geht und somit keine Beziehungen mehr erkannt werden können. Auch\n",
      "können ähnliche Bedeutungen bei verschiedenen Wörtern nicht abgebildet werden, was\n",
      "bedeutet die Worte wie: “schön” und “toll” genauso verschieden sind wie “Wetter” und\n",
      "“heute”.\n",
      "\n",
      "2.2. Word Embeddings\n",
      "Word Embeddings bestehen aus vielen Wortvektoren (Schütze und Pedersen 1995) die\n",
      "Wörter für den Computer verständlich darstellen. Mit Wortvektoren wird versucht die\n",
      "Beziehungen der Wörter zueinander beizubehalten und das Wort durch einen Vektor zu\n",
      "repräsentieren. Dabei liegen Wörter mit ähnlicher Bedeutung im Vektorraum nah zusammen, wohingegen Wörter mit unterschiedlicher Bedeutung weit auseinander liegen.\n",
      "Die Dimension des Vektors spiegelt die Genauigkeit des Word Embeddings wieder. Eine\n",
      "größere Dimension beschreibt jedes Wort genauer, benötigt aber auch mehr Speicherplatz\n",
      "sowie mehr Zeit zum Erstellen der Vektoren. Zum Erstellen der Wortvektoren können\n",
      "\n",
      "4\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "verschiedene Verfahren verwendet werden (Perone, Silveira und Paula 2018). Die Verfahren Word2Vec und Global Vectors (GloVe) erzeugen pro Wort einen kontextbasierten\n",
      "Wortvektor. Die Embeddings from Language Models (ELMo) Repräsentation kann für\n",
      "ein Wort mehrere Wortvektoren erstellen um verschiedene Kontexte abzubilden.\n",
      "\n",
      "2.2.1. Word2Vec\n",
      "Word2vec (Tomas Mikolov u. a. 2013) ist ein Verfahren, das Algorithmen verwendet die\n",
      "basierend auf dem Kontext einer Eingabe einen numerischen Vektor erzeugen. Im Gegensatz zu Bag–of–words (BoW) erhalten damit verschiedene Wörter in demselben Kontext\n",
      "einen ähnlichen Vektor. Dazu werden vier Schritte benötigt (Goldberg und Levy 2014).\n",
      "Als Erstes werden die Daten für eine unüberwachte Vorhersage vorbereitet, also Eingabe\n",
      "und Ziel der Vorhersage als Tupel. Betrachtet wird dieser Satz: “Als es an der Tür klingelte, rannte der Hund los.”, die ersten Tupel wären [als, es], [es, als] und [es, an]. Es wird\n",
      "über jedes Wort der Eingabe iteriert, dass aktuelle Wort ist dabei immer der erste Wert\n",
      "in dem Tupel. Die Fenstergröße gibt an, wie viele Wörter vor und nach dem aktuellen\n",
      "Wort beachtet werden sollen (hier Fenstergröße = 1). Die betrachteten Wörter durch die\n",
      "Fenstergröße bilden den zweiten Wert des Tupel. Ein größeres Fenster bringt bessere Performance zulasten der Berechnungszeit. Im Anschluss wird eine Matrix erstellt, die für\n",
      "jedes Wort der gesamten Trainingsdaten einen zufällig erstellten Wortvektor bereitstellt.\n",
      "Dann folgt die Optimierung durch das neuronale Netzwerk. Dazu werden die Tupel einzeln verarbeitet und für die Eingabe wird der Wortvektor aus der Matrix verwendet. Das\n",
      "Netz berechnet basierend auf der Eingabe eine Vorhersage des nächsten Wortes, welches\n",
      "mit dem tatsächlichen nächsten Wort verglichen wird. Basierend auf dem Ergebnis wird\n",
      "sowohl das Netz als auch der Wortvektor optimiert. Nach dem Training wird die Matrix\n",
      "gespeichert und kann als Word Embedding verwendet werden.\n",
      "\n",
      "2.2.2. GloVe\n",
      "Ein Nachteil der Word2Vec Repräsentation ist, dass diese nur die umliegenden lokalen\n",
      "Wörter betrachtet, um daraus die Wortvektoren zu erstellen. Für den Satz “Der\n",
      "Hund spielt auf der Couch.” ist nicht eindeutig ob “der” in besonderer Beziehung zu\n",
      "“Hund” und “Couch” steht oder ob es sich bei “der” um ein Stoppwort handelt. Global\n",
      "Vectors (GloVe) betrachtet beide Repräsentationen, die globale sowie lokale Sicht. Wie\n",
      "von (Pennington, Socher und Manning 2014) wird das Vokabular der Trainingsdaten in\n",
      "einer co–occurrence Matrix abgebildet. Eine beispielhafte co–occurrence Matrix kann der\n",
      "Abbildung 1 entnommen werden. Durch ein stochastisches Verfahren lässt sich berechnen\n",
      "wie relevant ein Wort zu einem gegebenen anderen Wort ist. Dabei gilt, dass ein hoher\n",
      "\n",
      "5\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "Wert (>1) eine hohe Relevanz und ein niedriger Wert (<1) irrelevantes Verhalten\n",
      "repräsentiert.\n",
      "\n",
      "Abbildung 1: Die co–occurrence Matrix für den Satz ”Heute gibt es Kuchen da es regnet”mit einer Fenstergröße von 1\n",
      "\n",
      "2.2.3. ELMo\n",
      "Neuronale Netze benötigen eine spezielle Darstellung von Wörtern. Bei Word Embeddings\n",
      "wird die Semantik von Wörtern in Form von Vektoren dargestellt. Ein bei diesem Ansatz\n",
      "nicht beachtetes Problem ist die Tatsache, dass ein Wort in unterschiedlichen Kontexten\n",
      "verschiedene Bedeutungen haben kann. “Für meine Familie suche ich ein neues Schloss\n",
      "zum Wohnen” und “Für meine Tür suche ich ein neues Schloss”, in beiden Sätzen wird\n",
      "das Wort “Schloss” verwendet, aber die Bedeutung ist offensichtlich eine andere. Einfache\n",
      "Wortvektoren wie die vorgestellten GloVe und Word2Vec sind nicht in der Lage den\n",
      "Unterschied dieser Wörter zu erkennen, sie hätten dieselbe Bedeutung.\n",
      "Um dieses Verhalten besser abbilden zu können, werden contextualized word–embeddings\n",
      "(Peters, Neumann, Iyyer u. a. 2018) verwendet. Anders als bei einfachen Word Embeddings, wird eine ganze Sequenz anstelle eines einzelnen Wortes eingegeben. Dadurch ist\n",
      "das Modell in der Lage, den Kontext der einzelnen Wörter zu ermitteln und kann so genauere Wortvektoren zurückgeben. Wie bereits bei den Word Embeddings werden diese\n",
      "Modelle nur in Ausnahmefällen selbst trainiert. Die benötigte Datenmenge, sowie die Zeit\n",
      "um diese Vektoren zu berechnen ist sehr groß (Peters, Neumann, Zettlemoyer u. a. 2018).\n",
      "Deshalb wird auf vortrainierte Modelle zurückgegriffen, welche dann auf den eigenen Anwendungsfall optimiert werden.\n",
      "Zum Erstellen der Embeddings from Language Models (ELMo) wird ein Modell verwendet, dessen Aufgabe darin besteht, das nächste Wort einer Sequenz vorherzusagen. Diese\n",
      "Aufgabe kann unüberwacht ausgeführt werden und vereinfacht somit das Trainieren. Das\n",
      "\n",
      "6\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "Modell setzt dabei auf bidirectional Long Short–Term Memory (biLSTM) um ein Gefühl\n",
      "der vorherigen sowie nachfolgenden Wörter zu erhalten. Zum Erstellen der endgültigen\n",
      "Wortvektoren werden die Ergebnisse der einzelnen biLSTM Zellen verwendet. Im ersten\n",
      "Schritt werden die Ergebnisse aus der Vorhersagerichtung sowie der Rückrichtung verkettet. Im Anschluss werden die Vektoren mit einer Gewichtung des Modells multipliziert\n",
      "und zum Schluss summiert. Das Ergebnis ist ein kontextsensitives Word Embedding jedes\n",
      "Wortes eines Satzes.\n",
      "\n",
      "Abbildung 2: Beispielhafte Visualisierung der Wortvektoren für das Wort Schloss\n",
      "Abbildung 2 zeigt eine stark vereinfachte Visualisierung des Word Embedding. Der Wortvektor für das Wort “Schloss” ist, basierend auf den Kontext, verschieden. Wortvektoren\n",
      "können beliebig viele Dimensionen haben, weshalb dieses eine vereinfachte Darstellung\n",
      "ist.\n",
      "\n",
      "2.3. Convolutional Neural Network\n",
      "Um eine genauere Vorhersage über die Bedeutung der Worte treffen zu können, ist die Betrachtung des Kontextes hilfreich. Es gibt verschiedene modellbasierte Ansätze, um diesen\n",
      "Kontext zu erfassen. Für die Convolutional Neural Network (CNN) liegt der Schwerpunkt\n",
      "in der Bildverarbeitung (Krizhevsky, Sutskever und Hinton 2012). Die Pixelwerte eines\n",
      "Bildes werden verwendet, um daraus Vorhersagen zu treffen, was auf dem Bild zu erkennen ist. Um dieses Ziel zu erreichen werden einfache, Hardware unterstützte Verfahren\n",
      "verwendet, die im Folgenden vorgestellt werden. Generell bestehen CNN aus den drei\n",
      "folgenden, miteinander verknüpften Ebenen (Kalchbrenner, Grefenstette und Blunsom\n",
      "2014):\n",
      "Eine Faltungsebene, bei der die Eingabematrix mit Hilfe eines Filterkerns auf eine kleinere Matrix reduziert wird, z.B. 5 x 5 als Eingabematrix, 3 x 3 als Filterkern bei einer\n",
      "Schrittweite von 1 erzeugt eine 3 x 3 Matrix. Dazu wird der Filterkern über die Eingabematrix um die Schrittweite verschoben. Bei jedem Schritt werden die übereinander\n",
      "liegende Werte der Filter- und Eingabematrix multipliziert und anschließend alle Werte\n",
      "\n",
      "7\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "addiert, um den neuen Wert der Ergebnismatrix zu erhalten.\n",
      "Durch Reduzieren der Matrix und Beibehalten der wesentlichen Informationen verringert\n",
      "die Pooling–Schicht die Anzahl der Parameter für die folgenden Ebenen. Dies wird durch\n",
      "Unterteilung der Eingabematrix erreicht. Die Werte der einzelnen Abschnitte werden auf\n",
      "verschiedene Arten verarbeitet, wie z.B. Durchschnitts–Pooling oder Max–Pooling. Bei\n",
      "dem Durchschnitts–Pooling wird der Durchschnitt der Werte eines Abschnitts gebildet\n",
      "und als neuer Wert in die Ergebnismatrix eingetragen. Bei Max–Pooling wird der maximale Wert eines Abschnittes übernommen.\n",
      "Die vollständig verbundene Schicht bildet die vorletzte Ebene eines CNN und ist eine\n",
      "normale neuronale Netzstruktur. Die Matrix der vorherigen Schicht wird ausgerollt und\n",
      "an die Eingabe–Neuronen übergeben. Diese sind jeweils mit den Neuronen der nächsten\n",
      "Schicht vollständig verknüpft, bis eine Verbindung zu den Ausgabe–Neuronen besteht.\n",
      "Zuletzt wird die Aktivierungsfunktion z.B. Softmax aufgerufen. Softmax–Aktivierung\n",
      "sorgt dafür, dass alle Werte der Ausgabe–Neuronen sich zu 1 addieren und so die Wahrscheinlichkeit der jeweiligen Ausgabe repräsentieren.\n",
      "\n",
      "8\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "Abbildung 3: Visualisierung eines CNN–Modells zur Satz Klassifizierung (Zhang und Wallace 2015)\n",
      "Abbildung 3 zeigt, wie Convolutional Neural Networks in der Sprachverarbeitung verwendet werden können. Die Eingabe muss dafür in Form einer Matrix vorhanden sein.\n",
      "Texte müssen zum Erfüllen dieses Kriteriums zunächst vorverarbeitet werden. Wie im\n",
      "Abschnitt 2.2 beschrieben, können Wörter auch als Vektoren repräsentiert werden. Für\n",
      "jedes Wort der Eingabe wird der zugehörige Vektor verwendet. Die resultierende Matrix\n",
      "hat die Größe n x m, wobei n der Länge des Satzes und m der Dimension des Wortvektors entspricht. Der Filterkern, der in der Faltungsebene angewendet wird, umfasst alle\n",
      "Dimensionen der Wortvektoren in x–Richtung. Die y–Richtung umfasst typischerweise 2\n",
      "– 5 Wörter. Die nachfolgenden Schichten funktionieren wie für Pixel bereits beschrieben.\n",
      "Im letzten Schritt wird die Eingabe in Wahrscheinlichkeitswerten den möglichen Klassen\n",
      "zugewiesen.\n",
      "\n",
      "9\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "2.4. Recurrent Neural Network\n",
      "In vielen Fällen der Sprachverarbeitung ist der Kontext der Eingabe essenziell für das\n",
      "Erzielen des gewünschten Ergebnisses. Um diesen Kontext in einem neuronalen Netz darstellen zu können, muss eine gewisse Abhängigkeit bei den Eingabe–Neuronen gegeben\n",
      "sein. Bei anderen neuronalen Netzen agieren die Neuronen unabhängig voneinander. In\n",
      "der aktuellen Verarbeitung wird der vorherigen Eingabe sowie deren Ergebnis keine Bedeutung zuteil. Recurrent Neural Networks (RNNs) nach (Tomáš Mikolov u. a. 2010)\n",
      "beziehen diese Informationen der vorherigen Schritte in die folgenden Verarbeitungen mit\n",
      "ein um ein kontextsensitives Ergebnis zu erzielen. Um die vorherige Sequenz von Wörtern\n",
      "mit einzubeziehen ist die grundlegende Architektur von RNN eine Schleife.\n",
      "\n",
      "Abbildung 4: Ausgerollte Darstellung eines RNN–Modells (Olah 2015)\n",
      "Wie in der Abbildung 4 zu erkennen ist, wird zunächst das erste Wort der Sequenz als\n",
      "Eingabe an das RNN übergeben. Das Netz berechnet basierend auf der Eingabe ein Ergebnis, welches zusätzlich mit dem nächsten Wort der Sequenz erneut an das Modell gegeben\n",
      "wird. Dieser Prozess wiederholt sich bis das letzte Wort der Sequenz verarbeitet wurde\n",
      "und ein endgültiges Ergebnis entsteht. Durch dieses Verfahren ist das Ergebnis abhängig\n",
      "von dem vorherigen Ergebnis, welches wiederum selbst abhängig von seinem vorherigen\n",
      "Ergebnis ist. Dadurch wird die gesamte Sequenz beachtet. Diese Art der Struktur lässt\n",
      "sich auch als Weiterleitung mit Speicherfunktion betrachten.\n",
      "Zum Anwenden von RNN–Modellen werden die Wörter der Eingabesequenz in Vektoren\n",
      "umgewandelt. Dafür können verschiedene Repräsentationen verwendet werden, welche bereits im Abschnitt Word Embeddings vorgestellt wurden. Die Sequenz von Vektoren wird\n",
      "nacheinander von dem RNN verarbeitet. Dazu wird der Vektor der Eingabe mit dem vorherigen Ergebnis verbunden und der entstehende Vektor wird in die Aktivierungsfunktion\n",
      "Tangens hyperbolicus (Tanh) gereicht. Die Funktion Tanh sorgt dafür, dass die Werte\n",
      "in dem Vektor zwischen -1 und +1 bleiben, da ohne diese Funktion einzelne Werte eine\n",
      "zu starke Gewichtung bekommen und die übrigen Werte keine Auswirkung haben. Das\n",
      "\n",
      "10\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "Ergebnis der Tanh Funktion ist die Ausgabe für den Schritt, der in der nächsten Iteration\n",
      "wieder als Eingabe verwendet wird.\n",
      "Ein Nachteil dieses Modells ist das Trainieren, da jede Eingabe von demselben Modell verarbeitet wird. So haben längere Sequenzen, bei denen das Ergebnis über den hinteren Teil\n",
      "der Eingabe entschieden wird, mehr Einfluss auf die Bewertung der einzelnen Neuronen\n",
      "als Wörter zu Beginn der Sequenz. Dadurch entsteht ein Ungleichgewicht und Sequenzen\n",
      "mit stark variierender Länge werden von dem Modell nur schwer bis gar nicht erlernt.\n",
      "Dieses Problem ist unter dem Namen vanishing gradient problem bekannt. Der Gradient,\n",
      "der für das Lernen verantwortlich ist, wird durch backpropagation so weit verkleinert, bis\n",
      "dieser keine Auswirkung mehr auf die Gewichtung der Neuronen nimmt. Durch diesen\n",
      "Effekt ist das Modell nicht in der Lage Neues zu erlernen.\n",
      "\n",
      "2.5. Unterschiede RNN und CNN\n",
      "Auf den ersten Blick wirken RNNs und CNNs identisch, da beide den Kontext der Eingabe betrachten. Der wesentliche Unterschied ist, dass RNNs nur aus einer Schicht bestehen\n",
      "und das Ergebnis der vorherigen Berechnung als Eingabe für das nächste Wort betrachten.\n",
      "RNNs werden meistens für die Bearbeitung von Sequenzen verwendet. Bei CNNs wird die\n",
      "Eingabe durch mehrere Schichten verarbeitet und es werden direkt mehrere Wörter in\n",
      "einem Durchlauf betrachtet. Durch dieses Vorgehen wird der lokale, umliegende Kontext\n",
      "berücksichtigt und nicht die gesamte Eingabe. Der Hauptanwendungsbereich dieses Modells liegt in der Bildverarbeitung. In der Arbeit von (Bai, Kolter und Koltun 2018) wurde\n",
      "gezeigt, dass RNNs durch CNNs ersetzt werden können und diese bei Sequenzmodellierung deutlich bessere Ergebnisse erzielen als die betrachteten RNN–Modelle.\n",
      "\n",
      "2.6. Long Short–Term Memory\n",
      "RNN–Modelle haben Schwierigkeiten, die Informationen der längeren Sequenzen von\n",
      "früheren Schritten bis hin zu den späteren zu propagieren. Um das Problem zu lösen\n",
      "werden Long Short–Term Memory (LSTM)–Modelle (Cummins, Gers und Schmidhuber\n",
      "1999) eingesetzt, welche eine Ergänzung zu RNN darstellen (Sherstinsky 2018). Diese\n",
      "Modelle verwenden eine Art Schalter, mit dem reguliert werden kann, ob und welche\n",
      "Informationen gespeichert werden sollen. Mit diesem Vorgehen können wesentliche Informationen der Sequenz gezielt gespeichert werden. Das Modell bezieht nicht mehr die\n",
      "volle Sequenz zur Verarbeitung ein, wodurch das Auftreten des vanishing gradient problem\n",
      "reduziert wird.\n",
      "\n",
      "11\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "Die Architektur des Modells basiert auf der Verwendung von drei Gates. Diese entscheiden was mit der aktuellen Eingabe geschehen soll. Zusätzlich bietet die Architektur einen\n",
      "Zustand, der als Gedächtnis verwendet wird. Wie bereits RNN–Modelle verwenden auch\n",
      "LSTM–Modelle zusätzlich das vorherige Ergebnis um die Ausgabe zu erzeugen. Als Eingabe wird auch eine Vektor Repräsentation der Wörter verwendet, wie sie im Abschnitt\n",
      "Word Embeddings erläutert wurde. Alle Gates erhalten die Wortvektoren und das Ergebnis aus der vorherigen Berechnung als Eingabe.\n",
      "Für jedes Wort einer Sequenz wird das LSTM–Modell aufgerufen und ab dem ersten\n",
      "Wort wird der Zustand und das vorherige Ergebnis in die nächste Berechnung übergeben.\n",
      "Das Forget Gate entscheidet, welche Informationen der vorherigen Schritte behalten\n",
      "werden. Das Input Gate bestimmt, welche Informationen aktuell relevant sind und im\n",
      "Gedächtniszustand gespeichert werden sollen. Das Output Gate berechnet das Ergebnis,\n",
      "welches für das nächste Wort wiederverwendet wird.\n",
      "\n",
      "Abbildung 5: Verkettung und Aufbau der einzelnen LSTM Elemente (Olah 2015)\n",
      "Das Forget Gate entscheidet welche Informationen beibehalten oder verworfen werden.\n",
      "Dazu wird eine Sigmoidfunktion auf den Eingabevektor angewendet, um die Werte des\n",
      "Vektors zwischen 0 und 1 abzubilden. Dabei bedeutet eine 1, dass die Informationen\n",
      "beibehalten und die 0 das diese verworfen werden.\n",
      "Bei dem Input Gate wird der Eingabevektor von zwei Aktivierungsfunktionen verarbeitet. Die Sigmoidfunktion entscheidet, welche Informationen wichtig (1) oder unwichtig (0)\n",
      "sind. Die Tanh Funktion reguliert die Werte, damit sich diese zwischen -1 und 1 befinden\n",
      "und sich besser für die spätere Verarbeitung eignen. Im Anschluss werden die Ergebnisvektoren beider Funktionen multipliziert, um einen Vektor zu erhalten.\n",
      "Um den neuen Gedächtniszustand zu berechnen, wird der vorherige Zustand mit dem\n",
      "\n",
      "12\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "Ergebnis des Forget Gates multipliziert. Der daraus resultierende Vektor wird mit dem\n",
      "Ergebnis des Input Gates addiert, daraus ergibt sich ein neuer Zustand. Als letztes wird\n",
      "das Output Gate verwendet. Eine Sigmoidfunktion wird auf den Eingabevektor angewendet, der aktuelle Zustand wird an eine Tanh Funktion gereicht. Die Ergebnisse beider\n",
      "Funktionen werden multipliziert und wird als vorheriges Ergebnis in dem folgenden Schritt\n",
      "wieder verwendet. Das Output Gate berechnet also die Vektoren, die für den nächsten\n",
      "Schritt benötigt werden. Für ein besseres Verständnis der Elemente kann Abbildung 5\n",
      "betrachtet werden.\n",
      "Eine Erweiterung sind Bidirektionalen Netze (Schuster und Paliwal 1997), welche auch die\n",
      "vorherigen Wörter für die Verarbeitung betrachten. Sowohl LSTM als auch RNN Netze\n",
      "können um die bidirektionale Komponente erweitert werden, um ein besseres Ergebnis\n",
      "zu erzielen. Dazu wird die Anzahl der verwendeten Zellen dupliziert und in umgekehrter Reihenfolge miteinander verbunden. Dadurch wird die Sequenz in beide Richtungen\n",
      "verarbeitet und Beziehungen — sowohl vor als auch nach dem Wort — werden beachtet.\n",
      "\n",
      "2.7. Conditional Random Fields\n",
      "Conditional Random Field (CRF) sind diskriminierend und modellieren die bedingte\n",
      "Wahrscheinlichkeitsverteilung (Lafferty, McCallum und Pereira 2001). Eingesetzt werden\n",
      "diese Modelle unter anderem in der Bild- und Textverarbeitung. In der grundlegenden\n",
      "Funktionsweise beschreibt das Modell die Abhängigkeiten sowie Unabhängigkeiten zwischen zufälligen Variablen. Diese Variablen bilden einen Graphen, aus dem sich die Wahrscheinlichkeiten berechnen lassen mit der die jeweilige Variable zutrifft. Bei CRF wird die\n",
      "bedingte Wahrscheinlichkeitsverteilung betrachtet, dazu wird die Wahrscheinlichkeit der\n",
      "Klasse Y — unter der Annahme, dass die Eingabe X gilt — gesucht (Abbildung 6). Für\n",
      "ein besseres Verständnis wird im folgendem ein Beispiel aus dem Bereich der natürlichen\n",
      "Sprachverarbeitung betrachtet.\n",
      "\n",
      "13\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "Abbildung 6: Beispielhafte Darstellung eines CRF\n",
      "Die Eingabedaten der CRFs sind sequentiell und der frühere Kontext wird berücksichtigt\n",
      "um eine Vorhersage treffen zu können. Um dieses Verhalten modellieren zu können, werden\n",
      "Feature–Funktionen mit vier Eingabewerten verwendet. Diese sind:\n",
      "• die Wortvektoren für jedes Wort der Eingabe\n",
      "• die Position des Wortes, für die der Bezeichner bestimmt werden soll\n",
      "• die korrekte Bezeichnung des vorherigen Wortes\n",
      "• die korrekte Bezeichnung des gesuchten Wortes\n",
      "Im Anschluss wird eine Merkmalsfunktion definiert, die das gewünschte Verhalten abbildet. Zum Trainieren werden die Gewichtungen zufällig bestimmt und mit dem Gradientenabstiegsverfahren optimiert bis die Parameterwerte konvergieren. Dieses Verfahren\n",
      "ist der logistischen Regression ähnlich, da beide die bedingte Wahrscheinlichkeitsverteilung verwenden. Der Unterschied besteht darin, dass durch die Erweiterung von Feature–\n",
      "Funktionen eine sequenzielle Eingabe möglich ist.\n",
      "\n",
      "2.8. Fuzzy–Suche\n",
      "Die zweiwertige Logik ermöglicht das Modellieren von Verhalten und umfasst die Wahrheitswerte “wahr” und “falsch”. Fuzzylogik erweitert die Menge der Wahrheitswerte (z.B.\n",
      "“ein bisschen”, “wenig” und “sehr”) um eine unscharfe Beschreibung zu ermöglichen\n",
      "(Zadeh 1965). Abgebildet auf reelle Zahlen bedeutet das die Werte in dem Intervall [0,1].\n",
      "Fuzzy (Unschärfe) ist eine Form der Ungenauigkeit bei der Abbildung eines Sachverhalts.\n",
      "\n",
      "14\n",
      "\n",
      "\f",
      "Kapitel 2\n",
      "\n",
      "Grundlagen\n",
      "\n",
      "Als Beispiel wird ein Zimmer betrachtet welches zwei Zustände haben kann: warm und\n",
      "kalt. Die zweiwertige Logik legt einen Grenzwert fest, ab wann der Übergang zwischen\n",
      "kalt zu warm ist z.B. 20 Grad Celsius. Bei Fuzzylogik wird eine weiche Grenze zwischen\n",
      "den Zuständen definiert und Werte wie 18,9 Grad Celsius werden beschrieben durch z.B.\n",
      "ein bisschen warm oder weniger kalt.\n",
      "Bei der unscharfen Suche auf Zeichenketten wird nicht auf die exakte Zeichenfolge, sondern\n",
      "ähnliche Zeichenketten geprüft. Die Levenshtein–Distanz ist ein Verfahren zur Messung\n",
      "der Differenz zwischen zwei Sequenzen (Levenshtein 1966). Die gesamte Distanz setzt\n",
      "sich dabei aus der benötigten Anzahl von Einfüge-, Lösch- und Ersetzung-Operationen\n",
      "zusammen, die benötigt werden, um ein Wort in das andere zu ändern. Betrachtet man\n",
      "die Wörter “Tier” und “Tor” kann der Buchstabe “i” durch ein “o” ersetzt werden und\n",
      "das “e” muss gelöscht werden. Somit beträgt die Levenshtein–Distanz 2. Die Distanz\n",
      "repräsentiert wie hoch eine Übereinstimmung dieser Wörter ist. Eine geringe Levenshtein–\n",
      "Distanz bedeutet dabei hohe Übereinstimmung.\n",
      "\n",
      "15\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "3. Konzeption\n",
      "Ziel dieser Arbeit ist es, aus natürlicher unstrukturierter menschlicher Eingabe eine strukturierte Ausgabe zu erzeugen, die von einem Computer weiterverarbeitet werden kann.\n",
      "Hier könnte es sich beispielsweise um Empfehlungen von Produkten auf eine Suchanfrage handeln. Dabei ist es wichtig, dass die natürliche Eingabe des Menschen korrekt\n",
      "verstanden und ausgewertet wird.\n",
      "\n",
      "3.1. Annahmen\n",
      "Im folgendem werden verschiedene Annahmen vorgestellt, die im Rahmen dieser Arbeit\n",
      "getroffen wurden.\n",
      "1. Annahme: Festlegen der Sprache\n",
      "Sprachmodelle die mit mehreren Sprachen interagieren sollen sind wesentlich komplexer. Die Charakteristiken einer Sprache variieren sehr stark, weshalb ein Modell,\n",
      "welches auf die englische Sprache trainiert wurde, nicht direkt mit deutscher Eingabe bedient werden kann. Um dieser Problematik nicht zu begegnen wird nur die\n",
      "deutsche Sprache unterstützt. Für eine Lösung muss das Modell selbst in der Lage\n",
      "sein, auf die verschiedenen Sprachen zu reagieren oder es wird ein Modell verwendet, welches die eingegebene Sprache ermittelt und abhängig davon das passende\n",
      "Sprachmodell bereitstellt.\n",
      "2. Annahme: Eingrenzung der Domäne\n",
      "Über virtuelle Marktplätze werden sämtliche Produkte gehandelt, die verschiedensten Attribute besitzen. Im Rahmen dieser Arbeit wird die Domäne beschränkt, mit\n",
      "der Möglichkeit diese nach Belieben zu erweitern. Technologische Artikel sind beliebte Produkte welche häufig über online Marktplätzen gehandelt werden, weshalb\n",
      "die Domäne zu Beginn auf diese Produkte begrenzt wird. Um diese noch weiter\n",
      "einzuschränken wurde sich an der Produktgruppe der Smartphones orientiert. Basierend auf dieser Gruppe wurden 6 Attribute — die häufig verwendet werden —\n",
      "gewählt, um Smartphones zu beschreiben. Diese sind in der Regel: Produkt, Hersteller, Preis, Farbe, Speicher und Kamera. Das in dieser Arbeit beschriebene Verfahren\n",
      "kann verwendet werden, um weitere Attribute bzw. Produktgruppen zu ergänzen.\n",
      "3. Annahme: Attribute sind zusammenstehend\n",
      "Ein bekanntes Problem bei Sprachmodellen ist, dass diese Schwierigkeiten haben\n",
      "Attribute zu bestimmen, bei Wörtern die nicht zusammenstehen. Aus diesem Grund\n",
      "wird angenommen, dass mehrere Wörter, die zu einem Attribut gehören, zusammen\n",
      "\n",
      "16\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "stehen und nicht von anderen Wörtern unterbrochen werden. Ein Gegenbeispiel\n",
      "dafür ist: “Ich suche ein iPhone, am besten das 10.”, da hier das gesuchte Produkt\n",
      "“iPhone 10” nicht zusammenhängt. Wird diese Annahme nicht getroffen, könnte die\n",
      "Eingabe durch eine Vorverarbeitung umstrukturiert werden, sodass die Attribute\n",
      "wieder zusammenstehen.\n",
      "4. Annahme: Eingaben sind nur Handelsanfragen\n",
      "Eingaben zwischen normaler Konversation und Handelsanfragen zu unterscheiden\n",
      "ist ein zusätzliches Problem, welches nicht im Fokus dieser Arbeit steht. Es wird\n",
      "angenommen, dass jede Eingabe mindestens das Attribut “Produkt” enthält und\n",
      "somit eine Handelsanfrage darstellt — dadurch kann sich auf das Klassifizieren der\n",
      "Attribute fokussiert werden. Alternativ müsste ein zusätzliches Modell eingesetzt\n",
      "werden, welches auf die Differenzierung zwischen normaler Konversation und Handelsanfragen trainiert ist.\n",
      "\n",
      "3.2. Anforderungen\n",
      "Virtuelle Marktplätze werden von Jahr zu Jahr bedeutsamer. Auf elektronischen Marktplätzen finden viele Käufer–Verkäufer Situationen statt. Anwender erstellen ein digitales\n",
      "Angebot, das von potenziellen Käufern gefunden werden möchte. Dieser Ablauf beschreibt\n",
      "grob einen Anwendungsfall, welcher durch die natürliche Sprachverarbeitung unterstützt\n",
      "werden soll. Die genauen Abläufe könnten wie folgt aussehen.\n",
      "1. Szenario: Angebotssuche\n",
      "Ein Anwender kann eine Anfrage in Form einer Texteingabe an das System stellen.\n",
      "Die Eingabe wird von einer Komponente verarbeitet, in der die wesentlichen Informationen extrahiert werden. Das Ergebnis der Verarbeitung wird mit der Eingabe\n",
      "in einer Datenbank abgespeichert, damit zukünftige Handelsanfragen diese Anfrage\n",
      "finden können. Ebenfalls wird das Ergebnis an eine andere Komponente übergeben,\n",
      "welche basierend auf den extrahierten Informationen ein passendes Gegenangebot\n",
      "zurückgibt. Dieses wird im Anschluss dem Anwender mit den erkannten Attributen\n",
      "aus seiner Eingabe präsentiert.\n",
      "2. Szenario: Gruppensuche\n",
      "In einem spezielleren Szenario sucht ein Anwender nach Produkten von einem bestimmten Hersteller, ohne das gesuchte Produkt genau zu spezifizieren. Die Attribute aus der Eingabe werden wie in dem vorherigen Szenario von einer Komponente\n",
      "bestimmt. Die zweite Komponente, welche das passende Gegenangebot ermittelt\n",
      "reagiert auf die Suche nach einer Menge von Produkten. Basierend auf die übrigen\n",
      "\n",
      "17\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "Attribute der Eingabe wird dem Anwender ein passendes Gegenangebot angezeigt.\n",
      "Diese Szenarien verdeutlichen den Ablauf einer Suche über einen virtuellen Marktplatz.\n",
      "3. Szenario: Inserat Erstellung\n",
      "In dem letzten Szenario erstellt ein Anwender ein Inserat. Die Eingabe wird verarbeitet und das eigene Ergebnis dem Anwender präsentiert. Dieser entscheidet dann,\n",
      "ob die erkannten Attribute korrekt sind. Ist dies nicht der Fall, so soll dem Anwender die Möglichkeit geboten werden die Attribute in seiner Eingabe manuell zu\n",
      "bestimmen. Im Anschluss werden die Attribute sowie die Eingabe in einer Datenbank gespeichert. Der Nutzer erhält kein Gegenangebot.\n",
      "Anwender sollen mit dem System interagieren können. Deshalb wird die direkte Eingabe\n",
      "der Nutzer verwendet, was als natürliche Eingabe bezeichnet wird. Als Beispiel dafür wird\n",
      "eine virtuelle Verhandlung über einen Chat betrachtet in dem Produkte gehandelt werden.\n",
      "Jeder Mensch verfügt über eine eigene Art wie er sich in einem Chatroom ausdrückt,\n",
      "weshalb keine korrekte Rechtschreibung angenommen wird. Auch muss das System in der\n",
      "Lage sein mit Abkürzungen sowie Emojis umzugehen. Aus den genannten Anforderungen\n",
      "wird deutlich, welche Funktionen der Prototyp bereitstellen muss. Für die ersten beiden\n",
      "Anwendungsfälle wird eine Oberfläche erwartet, in der ein Anwender Eingaben tätigen\n",
      "kann und die Möglichkeit hat eine Antwort zu erhalten. Chatsysteme werden häufig bei\n",
      "Consumer–to–Consumer Transaktionen in virtuellen Marktplätzen eingesetzt, weshalb\n",
      "der Aufbau dem eines Chatrooms ähnlich sein soll. Der Anwender kann seine Anfrage dann\n",
      "in Form einer Nachricht in diesem Chat an das System senden. Wie es in einen Chatroom\n",
      "üblich ist, wird dem Anwender seine eigene Nachricht angezeigt und nach der Verarbeitung\n",
      "auch die Antwort des Systems. Die Verarbeitung darf nicht zu lange dauern, da sonst das\n",
      "Interesse der Anwender verloren geht. In der Oberfläche soll es dem Benutzer möglich sein,\n",
      "mehrere Anfragen nacheinander an das System zu senden mit der Möglichkeit weiterhin\n",
      "die vorherigen Ergebnisse angezeigt zu bekommen. Die Nachrichten des Anwenders und\n",
      "Systems sollten farblich differenzierbar und links bzw. rechtsbündig ausgerichtet sein.\n",
      "Anwender sind an diesen Aufbau von anderen Nachrichtensystem vertraut, wodurch der\n",
      "Einstieg in die Bedienung erleichtert wird.\n",
      "Für das letzte Szenario wird eine andere, simplere Oberfläche verwendet. Es wird keine\n",
      "Antwort von dem System erwartet, weshalb nur die Eingabe des Anwenders im Vordergrund steht. Durch eine Texteingabe wird die Anfrage des Anwenders entgegengenommen\n",
      "und ausgewertet. Der Prototyp stellt im Anschluss die Eingabe mit den gefundenen Attributen sowie der Möglichkeit das Ergebnis zu bestätigen oder abzulehnen dem Anwender\n",
      "dar. Der Anwendungsfall bietet dem Anwender die Möglichkeit die eigene Anfrage manuell\n",
      "\n",
      "18\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "mit Attributen zu versehen. Um diese Funktionalität anzubieten wird für jedes Attribut\n",
      "eine Schaltfläche verwendet, mit der die ausgewählte Sequenz dem jeweiligen Attribut\n",
      "zugewiesen werden kann. Formalisiert lassen sich aus den Beschreibungen der Szenarien\n",
      "sowie dem Ziel der Arbeit die folgenden Anforderungen erfassen. Die Anforderungen werden mit den Buchstaben FA und NA für funktionale bzw. nicht funktionale Anforderungen\n",
      "gekennzeichnet.\n",
      "FA1: Das System muss Eingaben in Form von Handelsanfragen von Anwendern\n",
      "ermöglichen.\n",
      "FA2: Das System muss basierend auf die Handelsanfragen passend antworten.\n",
      "FA3: Das System muss den Anwendern die Möglichkeit bieten, die Eingabe manuell mit\n",
      "Attributen zu versehen.\n",
      "FA4: Das System muss Gruppensuchen ermöglichen und mit einem passenden Angebot\n",
      "reagieren.\n",
      "FA5: Das System muss alle Anfragen persistieren.\n",
      "FA6: Das System muss mit bestimmte Anwenderfehler wie z.B. Rechtschreibfehler umgehen können.\n",
      "NA1: Aufrufe der Anwender müssen schnell (<3 s) verarbeitet und beantwortet werden.\n",
      "NA2: Anwendern wird das Gefühl vermittelt, von dem System verstanden zu werden.\n",
      "NA3: Die Antworten des Systems sind begründet und können von den Anwendern nachvollzogen werden.\n",
      "\n",
      "19\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "3.3. Komponenten\n",
      "\n",
      "Abbildung 7: Aufbau der Anwendung mit den Komponenten\n",
      "Um die vorgestellten Szenarien aus Abschnitt 3.2 zu erfüllen werden fünf Komponenten\n",
      "benötigt, um einen Prototyp zu erstellen wie in Abbildung 7 dargestellt. In den folgenden\n",
      "Abschnitten werden die Komponenten genauer vorgestellt.\n",
      "\n",
      "3.3.1. Benutzerschnittstelle\n",
      "Der Prototyp kann mit verschiedenen Oberflächen realisiert werden z.B. Webanwendung, Desktop–Anwendung, Android–App oder Kommandozeile. Was verwendet wird\n",
      "ist abhängig von dem Ziel, dass der Prototyp verfolgt. Ein Kriterium ist die einfache\n",
      "Zugänglichkeit, sodass viele Anwender den Prototypen problemlos benutzen können. Am\n",
      "einfachsten zugänglich ist eine Webanwendung, da diese im Webbrowser aufgerufen werden kann. Die anderen Möglichkeiten benötigen eine Installation oder zumindest eine\n",
      "ausführbare Projektdatei auf dem Endgerät.\n",
      "Die wesentliche Aufgabe des Prototyps ist es, Text entgegenzunehmen und zu verarbeiten (FA1 ). Aus diesem Grund ist ein weiteres Kriterium die Unterstützung der einfachen\n",
      "Texteingabe von der Oberfläche. In Smartphone Apps wird Text meist nur über die Bildschirmtastatur eingegeben was umständlicher ist als z.B. an einen Computer. In einer\n",
      "Kommandozeilen–Anwendung ist der Umgang mit langen Texteingaben ebenfalls nicht\n",
      "optimal da per Mausklick nicht an die gewünschte Stelle gesprungen wird.\n",
      "Das nächste Kriterium ist eine leicht verständliche Oberfläche, die intuitiv bedient werden\n",
      "kann. Die Oberfläche der Kommandozeile ist nicht benutzerfreundlich, weshalb viele Anwender davor zurückschrecken würden eine solche Anwendung zu benutzen. Bei Desktop–\n",
      "Anwendungen neigen Entwickler dazu ein komplett eigenes und kein einheitliches Design\n",
      "zu verwenden. Die Folge davon ist, dass Anwender sich erst an die Bedienung gewöhnen\n",
      "\n",
      "20\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "müssen. Bei Webanwendungen und Smartphone Apps wird mehr Wert auf ein einheitliches Design gelegt und sich an bereits existierende Anwendungen orientiert.\n",
      "Zum Erstellen dieser Arbeit wird eine Webanwendung erstellt. Webanwendungen bieten\n",
      "den Anwendern eine vertraute Oberfläche, die einfach zu bedienen ist. Webseiten können\n",
      "von den meisten Endgeräten aus aufgerufen werden, was die Verwendung von Smartphones miteinschließt. Das häufige Eingeben von Text wird durch die Verwendung einer\n",
      "Computertastatur erleichtert. Anwender müssen keinen Client updaten, um die neueste\n",
      "Version des Prototyps verwenden zu können. Es wird ein Server benötigt, auf dem die\n",
      "Webanwendung ausgeführt wird damit diese verfügbar ist.\n",
      "\n",
      "3.3.2. Hybrid named-entity recognition\n",
      "Die natürliche Eingabe des Anwenders wird an eine Komponente übergeben, welche die\n",
      "Attribute bestimmt um später eine passende Antwort generieren zu können. Bei der erhaltenen Eingabe kann von keiner korrekten Rechtschreibung ausgegangen werden (FA6 ).\n",
      "Die Attribute zeichnen sich durch besondere Charaktereigenschaften aus. So besteht der\n",
      "Preis meist aus einem beschreibenden Wort z.B. “mindestens” oder “maximal” gefolgt\n",
      "von einer Zahl (z.B. 300) mit einer abschließenden Einheit (z.B. “e”, “euro”). Der strukturelle Aufbau der Attribute SSpeicheründ ”Kameraı̈st identisch, nur die Einheit ist eine\n",
      "Andere (“Gigabyte (GB)” bzw. “Megapixel (MP)”).\n",
      "Attribute wie Hersteller und Farbe bestehen in den allermeisten Fällen nur aus einzelnen Wörtern oder einer kleinen Wortkette z.B. “Apple” und “helles grau”. Das Produkt\n",
      "hingegen besteht nicht nur aus Wörtern oder Wortketten, sondern es beinhaltet häufig\n",
      "genaue Artikelbezeichnungen, die in Form von Buchstaben konkateniert mit Zahlen dargestellt werden (z.B. “Galaxy S10”). Auch können Produkte den Namen des Herstellers\n",
      "beinhalten, was das Differenzieren beider Attribute erschwert. Abbildung 8 zeigt eine beispielhafte Eingabe in der die Attribute farblich hervorgehoben wurden: Hersteller (grau),\n",
      "Produkt (blau), Farbe (schwarz), Kamera (türkis), Speicher (gelb) und Preis (rot).\n",
      "\n",
      "Abbildung 8: Visuelle Unterstützung einer beispielhaften Eingabe\n",
      "Aufgrund der unterschiedlichen Eigenschaften der Attribute, wird eine Menge von Algorithmen verwendet, die gemeinsam eine Pipeline bilden. Diese erzeugt aus einer unstruktu-\n",
      "\n",
      "21\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "rierten Eingabe eine mit korrekten Bezeichnungen versehene Ausgabe. Die Pipeline setzt\n",
      "sich dabei aus unterschiedlichen Algorithmen zusammen, die nacheinander angewendet\n",
      "werden, um so ein optimales Ergebnis zu erzielen. Der Fokus dieser Arbeit beschränkt\n",
      "sich auf das Erkennen des Attributes “Produkt”, da dieses bei allen Handelsanfragen\n",
      "enthalten sein muss. Die übrigen Attribute (Hersteller, Preis, Farbe, Speicher und Kamera) sollen zeigen, dass eine Erweiterung auf mehrere Attribute möglich ist. Die einzelnen\n",
      "Schritte der Pipeline sind aufsteigend gewichtet. Das bedeutet, dass die späteren Schritte\n",
      "Teilergebnisse der vorherigen überschreiben, weshalb die Stärken verschiedener Algorithmen kombiniert werden können. Der Aufbau der Pipeline ermöglicht ein einfaches Hinzufügen, Verschieben oder Entfernen von Algorithmen, welches Anpassungen an spezielle\n",
      "Anforderungen ermöglicht.\n",
      "\n",
      "Abbildung 9: Aufbau der Pipeline\n",
      "Abbildung 9 zeigt den konzeptionellen Aufbau der Pipeline. Wie zu erkennen besteht die\n",
      "Pipeline aus mehreren Bauteilen, die sich auf verschiedene charakteristische Eigenschaften\n",
      "der Attribute fokussieren. Mit diesem Aufbau werden die Stärken der einzelnen Schritte\n",
      "kombiniert, wodurch die Erkennung optimiert werden kann.\n",
      "Den ersten Schritt bildet ein neuronales Netz, dessen Hauptaufgabe das Erkennen des\n",
      "Attributes “Produkt” ist. Es gibt sehr viele verschiedene Produktbezeichnungen mit variierender Länge und Anzahl der Wörter, sodass neuronale Netze für diese Aufgabe benötigt\n",
      "werden. Die Netze sind durch Trainieren in der Lage, bestimmte Muster in den verschiedenen Eingaben zu erkennen, die zuvor von Menschen nicht erkannt wurden. Durch die\n",
      "Vielzahl von möglichen Produkten und dem Ziel alle möglichen Produkte zu erkennen wurde ein einfaches Vergleichsverfahren an dieser Stelle ausgeschlossen. Das System würde\n",
      "nur die zuvor definierten Produkte erkennen und neue Produkte müssten dauerhaft manuell hinzugefügt werden was nicht zielführend ist. Das neuronale Netz muss in der Lage\n",
      "sein, Wörter bzw. ganze Sätze als Eingabe entgegenzunehmen und eine Wortsequenz —\n",
      "die dem passenden Attribut zugewiesen wird — als Ausgabe zu erzeugen.\n",
      "Der nächste Schritt dient zum Erkennen von Attributen, die durch einen regelbasierten\n",
      "Ansatz erkannt werden können. Einige Attribute wie Preis, Speicher und Kamera folgen\n",
      "\n",
      "22\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "immer einem ähnlichen Muster, das durch reguläre Ausdrücke beschrieben werden kann.\n",
      "Die Werte dieser Attribute sind deutlich weniger variabel als die der übrigen Attribute.\n",
      "Zudem ist es unwahrscheinlich, dass in naher Zukunft neue Werte zu den Attributen hinzugefügt werden und diese somit sehr starr sind. Ein alternatives Vorgehen zur Erkennung\n",
      "dieser Attribute ist mit neuronalen Netzen. Das Trainieren eines neuronalen Netzes zum\n",
      "Erkennen dieser Attribute ist wesentlich aufwändiger und fehleranfälliger. Aus diesem\n",
      "Grund wurde sich gegen dieses Vorgehen und für die regulären Ausdrücke entschieden.\n",
      "In dem letzten Schritt wird ein einfacher Vergleich der Eingabe mit zuvor definierten Attribut Ausprägungen vorgenommen. Dieser Schritt wird für Attribute verwendet, welche\n",
      "nicht durch reguläre Ausdrücke beschrieben werden können. Die Eingabe wird mit zuvor\n",
      "definierten Werten, wie z.B. “iPhone” abgeglichen, um sicher zu stellen das zumindest\n",
      "diese Werte korrekt klassifiziert werden. Anders als der erste Schritt, in dem sämtliche\n",
      "Produkte identifiziert werden sollen, ist das Ziel des letzten Schrittes nur wenige, bestimmte Attribute zu erkennen. Aufgrund des anderen Zieles wird das folgende Verfahren\n",
      "in Betracht gezogen. Die gegebene Eingabe wird Wort für Wort mit den zuvor definierten\n",
      "Ausprägungen abgeglichen und bei einer Übereinstimmung ist das Attribut in der Eingabe enthalten. Der Nachteil dieses Ansatzes ist, dass die definierten Werte eine exakte\n",
      "Übereinstimmung in der Eingabe voraussetzen, da diese sonst nicht gefunden werden.\n",
      "Einen besseren Ansatz verfolgt die Fuzzylogik (Zadeh 1965). Die Wörter benötigen keine\n",
      "exakte Übereinstimmung da auch ungenaue Ergebnisse zugelassen werden. Der Nachteil\n",
      "der exakten Übereinstimmung ist dadurch nicht mehr gegeben, weshalb für den letzten\n",
      "Schritt die Fuzzylogik betrachtet wird (Mansouri, Affendey und Mamat 2008).\n",
      "\n",
      "3.3.3. Tagging\n",
      "Falsche Ergebnisse sind bei der Verwendung von neuronalen Netzen nicht auszuschließen, weshalb diese berücksichtigt werden müssen. Um zu verhindern, das falschen Daten\n",
      "persistiert werden wird eine Komponente benötigt, mit der das Ergebnis der Pipeline\n",
      "manuell nachgebessert werden kann (FA3 ). Die Komponente unterteilt sich dabei in zwei\n",
      "Unterfunktionen, zum einen das manuelle Setzen von Attributen und zum anderen das\n",
      "Bestimmen der Rolle (Käufer oder Verkäufer) aus einer Anfrage. Durch das richtige Setzen\n",
      "von Attributen können diese Anfragen korrekt in der Auswertungs–Komponente verwendet werden. Aus falsch persistiert Daten können unpassende Ergebnisse entstehen die dem\n",
      "Anwender auf seine Anfrage als Antwort vorgeschlagen werden. Selbiges gilt für falsch zugewiesene Rollen, auf eine Kaufanfrage könnte mit einer weiteren Kaufanfrage von dem\n",
      "System geantwortet werden.\n",
      "\n",
      "23\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "Eine solche Komponente, in der Anwender die Daten selbst annotieren können, kann\n",
      "verwendet werden, um Daten zu sammeln. Es kann auf keine Datengrundlage aufgebaut\n",
      "werden, die die Anforderungen erfüllen, weshalb dieses Vorgehen geeignet ist. Die gesammelten Daten können verwendet werden, um das benötigte neuronale Netz zu trainieren\n",
      "und so die Performance zu verbessern. Durch die manuelle Annotation der Daten können\n",
      "diese, ohne zusätzliche Bearbeitungsschritte verwendet werden, um den Ablauf zu vereinfachen. Mit dieser Struktur kann ein iterativer Ansatz zum Verbessern der Modelle erstellt\n",
      "werden. Es werden Daten gesammelt, die durch den Anwender korrekt annotiert sind. Ab\n",
      "einer gewissen Menge von neuen Daten wird der gesamte Datenbestand verwendet, um\n",
      "ein neues Modell zu trainieren welches das vorherige ersetzt. Anhand der Daten aus den\n",
      "späteren Iterationen lassen sich die Modelle evaluieren und können so verglichen werden.\n",
      "Zudem kann die Skalierung der Modelle mit mehr Daten gemessen werden, indem diese\n",
      "erneut trainiert und auf eine Verbesserung der Genauigkeit geprüft werden. Durch eine\n",
      "Automatisierung der Iteration wäre das System in der Lage sich kontinuierlich selbst zu\n",
      "verbessern und so immer mehr Eingaben korrekt zu erkennen.\n",
      "\n",
      "3.3.4. Persistierung\n",
      "Der Handel zwischen Kunden ist ein wesentlicher Bestandteil eines virtuellen Marktplatzes. Um diesen zu ermöglichen, muss das System in der Lage sein, die Angebote und\n",
      "ggf. Nachfragen zu persistieren, damit diese von Kunden gefunden werden können (FA5 ).\n",
      "Zudem ist ein virtueller Marktplatz erst dann für Kunden attraktiv, wenn dieser über\n",
      "eine Vielzahl von Produkten im Sortiment verfügt. Zum Verwalten von großen Mengen\n",
      "an Daten wird meist auf Datenbanken zurückgegriffen. In der Datenbank werden die Benutzereingaben sowie die erkannten Attribute gespeichert. Wurde das Ergebnis der Verarbeitung von dem Anwender manuell verbessert wird das ebenfalls persistiert, um einen\n",
      "korrekt klassifizierten Datensatz zu erhalten. Für diese Arbeit wurde zwischen Graphdatenbanken und relationale Datenbank nach (Vicknair u. a. 2010) entschieden. Aus den\n",
      "vorgestellten Anwendungsfällen in Abschnitt 3.2 ist ersichtlich, dass die Daten keine Indizierung benötigen und überwiegend nur aus Text bestehen. Bezogen auf die Performance,\n",
      "sind Relationale Datenbanken den Graphdatenbanken in diesem Szenario unterlegen. Der\n",
      "zweite Anwendungsfall bezieht sich auf eine Gruppensuche, die viele Beziehungen der\n",
      "einzelnen Daten voraussetzt (z.B. Knowledge Graph). Vordefinierte Produkte können Beziehungen zu Herstellern haben und es können Obergruppen für bestimmte Kategorien\n",
      "angelegt werden. Die Komponente welche passende Gegenangebote ermittelt kann auf\n",
      "diese Daten zurückgreifen, um so bessere Ergebnisse zu erzielen. Dieses ist ein weiterer\n",
      "Vorteil der Graphdatenbanken nach (Vicknair u. a. 2010) weshalb diese im Rahmen dieser\n",
      "\n",
      "24\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "Arbeit verwendet werden.\n",
      "\n",
      "3.3.5. Auswertung\n",
      "Die letzte Komponente erstellt die Antwort zu einer gegebenen Eingabe. Damit vorherigen\n",
      "Anfragen ausgewertet werden können, benötigt die Komponente Zugriff auf die Datenbank. Dabei muss die Rolle des Benutzers (Käufer oder Verkäufer) beachtet werden damit\n",
      "nur Anfragen der anderen Rolle ausgewertet werden. In dem speziellen Szenario aus Abschnitt 3.2 muss die Komponente erkennen, dass eine Gruppensuche erwartet wird (FA4 ).\n",
      "Aus den gefundenen Mengen der Ergebnisse muss anhand einer Strategie ein optimales\n",
      "Gegenangebot gefunden werden, welches zurückgegeben wird (FA2 ). Eine geeignete Strategie sucht das Angebot mit den meisten übereinstimmenden Attributen aus der Anfrage.\n",
      "Das Attribut “Produkt” muss mindestens übereinstimmen da es sich sonst um verschiedene Produkte handelt. Anhand der Rolle kann eine Regel für den Preis erstellt werden,\n",
      "als Verkäufer wird der höchste Preis bevorzugt, als Käufer der niedrigste. Mit dieser Strategie kann ein Matchmaking erstellt werden welches immer das passende Gegenangebot\n",
      "für eine Anfrage findet. Wenn kein Angebot gefunden werden konnte, sollte dieses ebenfalls wiedergegeben werden. Die erkannten Attribute aus der Eingabe sind auch in der\n",
      "zurückgegeben Antwort enthalten, um diese dem Anwender zu zeigen (NA3 ).\n",
      "\n",
      "3.4. Prozesse\n",
      "Aus den in Abschnitt 3.2 vorgestellten Anwendungsfällen sind die im Abschnitt 3.3\n",
      "erläuterten Komponente entstanden, welche alle Anforderungen (FA1 - FA6 ) erfüllen.\n",
      "Die Anwendungsfälle beschreiben bereits einen groben Ablauf in welcher Reihenfolge die\n",
      "Komponente aufgerufen werden. Im folgendem wird anhand der Szenarien deutlich, wie\n",
      "die Kommunikation zwischen den Komponenten dargestellt wird und welche Funktionen\n",
      "diese bereitstellen müssen.\n",
      "1. / 2. Szenario:\n",
      "Die Szenarien 1. und 2. unterscheiden sich nur in der Art der Suche. In dem einen Szenario wird ein explizites Produkt gesucht und in dem anderen wird nach einem Produkt\n",
      "aus einer Produktgruppe gesucht. Der Ablauf der Szenarien wird durch diesen Unterschied nicht beeinflusst, weshalb beide Anwendungsfälle gemeinsam betrachtet werden.\n",
      "Eingeleitet wird die Suche durch das Eingeben einer Anfrage durch den Anwender. Diese\n",
      "wird an die Hybrid Named Entity Recognition (NER)–Komponente übergeben, welche\n",
      "eine Funktion bereitstellen muss, die eine Anfrage entgegennimmt. Die Eingabe sowie das\n",
      "Ergebnis der Verarbeitung wird an die Datenverwaltung zum Persistieren übergeben. Die\n",
      "\n",
      "25\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "Daten aus diesen Szenarien müssen mit einem zusätzlichen Vermerk gespeichert werden,\n",
      "da das Ergebnis nicht manuell verifiziert wurde und möglicherweise fehlerhaft sein kann.\n",
      "Im Anschluss wird das Ergebnis an die Auswertungs–Komponente übergeben. Dort wird\n",
      "bestimmt ob es sich um eine Gruppen- oder Produktsuche handelt und eine passende\n",
      "Anfrage an die Datenbank gestellt. Die Datenverwaltung benötigt zwei Funktionen. Die\n",
      "erste Funktion nimmt das gesuchte Produkt und die Rolle der Anfrage entgegen und\n",
      "gibt die gefundenen Anfragen mit enthaltenen Attributen zurück. Der zweiten Funktion\n",
      "wird eine Produktgruppe anstelle eines bestimmten Produktes mit der Rolle übergeben,\n",
      "die Rückgabe bleibt identisch. Die Ergebnisse der Datenbankanfrage werden ausgewertet\n",
      "und ein mögliches Gegenangebot mit den erkannten Attributen der eigenen Eingabe an\n",
      "die Oberfläche zurück übergeben. Die Oberfläche wird um die Antwort erweitert und die\n",
      "Suchanfrage ist beendet.\n",
      "3. Szenario:\n",
      "Die Erstellung eines Inserats wird durch eine Benutzereingabe eingeleitet. Die Hybrid\n",
      "NER–Komponente muss eine Schnittstelle bereitstellen, die diese Eingabe entgegennimmt. Das Ergebnis wird zurück an die Oberfläche übergeben, um es dem Anwender\n",
      "zu präsentieren. Basierend auf der Rückmeldung wird die Eingabe sofort gespeichert oder\n",
      "einer manuellen Bearbeitung unterzogen. Der Tagging–Komponente wird die Eingabe\n",
      "übergeben und bietet dem Anwender in einer Oberfläche die Möglichkeit die Attribute der Eingabe manuell zu bestimmen. Die Datenverwaltung benötigt eine Funktion, an\n",
      "die die Eingabe, sowie das erkannte bzw. manuell bestimmte Ergebnis übergeben werden kann. Das Inserat wurde erstellt und der Ablauf ist abgeschlossen. Die Auswertungs–\n",
      "Komponente wird in diesem Szenario nicht benötigt, da der Anwender nach dem Erstellen\n",
      "eines Inserats keine Antwort des Systems erhält.\n",
      "\n",
      "3.5. Bewertungskriterien\n",
      "Es werden verschiedene Algorithmen verwendet, um alle Attribute aus einer Eingabe zu\n",
      "erkennen. Damit die Algorithmen verglichen werden können, werden einheitliche Metriken\n",
      "verwendet. Die meisten neuronalen Netze werden anhand der Werte: Accuracy, Precision, Recall und F1–Score bemessen (Faruqui und Padó 2010). Diese Werte werden aus\n",
      "den Feldern einer Confusion Matrix berechnet. Damit die berechneten Ergebnisse aus\n",
      "der Evaluation auch mit anderen Arbeiten vergleichbar sind, werden dieselben Metriken\n",
      "aufgestellt. Für eine ausführliche Evaluation wird eine zusätzliche Bewertung nach (Jiang, Banchs und Li 2016) durchgeführt. Die Attribute können dabei in folgende Klassen\n",
      "eingeordnet werden:\n",
      "\n",
      "26\n",
      "\n",
      "\f",
      "Kapitel 3\n",
      "\n",
      "Konzeption\n",
      "\n",
      "• Erkannt, richtige Klasse\n",
      "• Erkannt, falsche Klasse\n",
      "• Zu viel/wenig erkannt, richtige Klasse\n",
      "• Zu viel/wenig erkannt, falsche Klasse\n",
      "• Falsch erkanntes Wort\n",
      "• Attribut nicht erkannt\n",
      "Durch eine genauere Aufteilung können so die Algorithmen gezielter untersucht werden, um eine mögliche spätere Nachverarbeitung zu vereinfachen. In dem Bereich der\n",
      "natürlichen Sprachverarbeitung gibt es viele Modelle die Named Entity Tagging (NET)\n",
      "unterstützen. Aus diesem Grund soll der Prototyp die Metriken automatisch generieren.\n",
      "Dadurch wären die Modelle einheitlich gestaltet und sind somit besser nachvollziehbar.\n",
      "So kann die Performance der Pipeline jederzeit nachvollzogen werden. Zeitmessungen\n",
      "wurden auf einem Laptop (i7-4710MQ mit 2,50 GHz und 16 GB RAM) mit den vorhandenen Testdaten ausgeführt. Dabei wurden externe Einflussfaktoren so weit wie möglich\n",
      "ausgeschlossen (keine weiteren laufenden Programme, keine Internetverbindung) und die\n",
      "Testdurchläufe wurden zehnmal wiederholt, um ein möglichst genaues Ergebnis zu erzielen.\n",
      "\n",
      "27\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "4. Umsetzung\n",
      "Der folgende Abschnitt beschreibt das Sammeln der Daten, die in dieser Arbeit verwendet\n",
      "wurden. Im Anschluss wird die Implementierung der einzelnen Komponenten, die zusammen eine Pipeline bilden, vorgestellt. Abschließend wird auf die Oberfläche des Prototyps\n",
      "eingegangen.\n",
      "\n",
      "4.1. Vorgehen\n",
      "Die Umsetzung erfolgt in zwei Iterationsschritten, die auf Abbildung 10 dargestellt werden. In der ersten Iteration wird eine gewisse Menge von Daten akquiriert, auf die die\n",
      "verschiedenen Modelle trainiert und evaluiert werden, um diese vergleichen zu können.\n",
      "Anhand dieser Ergebnisse werden die Modelle gewichtet und zusammen kombiniert, um\n",
      "die Pipeline zu erstellen. Im Anschluss wird die erste Version des Prototyps realisiert, der\n",
      "das Erstellen von Inserats unterstützt.\n",
      "\n",
      "Abbildung 10: Ablaufdiagramm der Umsetzung dieser Arbeit\n",
      "In der zweiten Iteration werden mehr Daten mithilfe des Prototyps gesammelt. Die bereits trainierten Modelle werden anhand dieser Daten evaluiert, um die Genauigkeit der\n",
      "Modelle besser zu bestimmen. Die verwendeten Modelle werden mit dem gesamten Datensatz erneut trainiert und die vorherigen Ergebnisse mit den neuen verglichen. Die neuen\n",
      "Modelle werden mit den vorhandenen in der Pipeline ausgetauscht, um das Ergebnis des\n",
      "Prototyps zu verbessern.\n",
      "\n",
      "28\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "4.2. Datenakquise\n",
      "Ein wichtiger Bestandteil, um mit maschinellen Lernen Probleme lösen zu können sind\n",
      "relevante Daten. Mit einer großen Menge von Daten können die verwendeten Modelle\n",
      "bessere Ergebnisse erzielen, da Abweichungen weniger Gewichtung haben. Zudem sind\n",
      "die Daten vielfältiger und können somit mehrere verschiedene Situationen abdecken.\n",
      "Zu Beginn der Arbeit waren keine Daten vorhanden weshalb die Datenakquise ein wesentlicher Bestandteil darstellt. Die ersten Daten wurden in einer Umfrage erhoben. Die\n",
      "Arbeit beschränkt sich auf das Erkennen des Attributes “Produkt” weshalb die Teilnehmer\n",
      "Sätze bilden sollten, in denen nach einem Produkt gesucht wird. Das enthaltene Produkt\n",
      "sollte zudem in einem zusätzlichen Feld eingetragen werden, um so die spätere Vorverarbeitung der Daten zu vereinfachen. In der ersten Iteration wurden so 70 Datensätze\n",
      "erhoben, die in dem nächsten Schritt vorverarbeitet wurden. Die Algorithmen sollen nur\n",
      "Produkte erkennen, welche in dem gegebenen Satz enthalten sind. So wurden Sätze wie:\n",
      "“Am Wochenende lade ich wieder zu einer Grillparty ein, ich suche noch jemand der\n",
      "Fleisch mitbringen kann” mit dem angegebenen Produkt “Grillfleisch” geändert, sodass\n",
      "das gesuchte Wort exakt in dem Satz enthalten ist, in diesem Fall: “Fleisch”. Basierend\n",
      "auf diesen Daten wurden die Algorithmen in der ersten Iteration trainiert.\n",
      "In dem zweiten Iterationsschritt konnte auf einen lauffähigen Prototyp aufgebaut werden,\n",
      "um so das Sammeln der Daten zu unterstützen. Die Probanden wurden gebeten, sich auf\n",
      "die Produktgruppe der Smartphones zu fokussieren damit die vorgegebenen möglichen\n",
      "Attribute in der Eingabe enthalten sein können. In einer Eingabemaske wird das Angebot bzw. die Nachfrage eingegeben und auf der nächsten Seite wird das Ergebnis des\n",
      "Algorithmus dargestellt. Dabei wurde sich auf 6 mögliche Attribute beschränkt: Produkt,\n",
      "Hersteller, Preis, Farbe, Speicher und Kamera. Die Probanden sollten entscheiden, ob ihre\n",
      "Eingabe richtig erkannt wurde, oder ob Attribute falsch gesetzt wurden bzw. komplett fehlen. Im letzten Fall sollten die Anwender selbst die Attribute markieren, um die Daten für\n",
      "eine spätere Verarbeitung vorzubereiten. Der Vorteil in dieser Methode liegt darin, dass\n",
      "deutlich mehr Datensätze direkt verwendet werden können und keine Vorverarbeitung der\n",
      "Daten wie in der ersten Iteration nötig ist. Die Oberfläche erlaubt nur das Markieren von\n",
      "zusammenstehenden Wörtern, die tatsächlich in dem Satz enthalten sind und so das Attribut bilden. Beides sind Annahmen die im Rahmen dieser Arbeit getroffen wurden und\n",
      "im Abschnitt 3.1 genauer beschrieben werden. Dieses Vorgehen ermöglicht das Sammeln\n",
      "eines dynamisch wachsenden Datensatzes, welcher zum Evaluieren und Optimieren der\n",
      "Algorithmen verwendet wird.\n",
      "\n",
      "29\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "4.3. Hybrid named-entity recognition\n",
      "Zum Erkennen der Attribute werden verschiedene, bereits existierende Verfahren kombiniert, um gemeinsam eine Pipeline zu bilden. Die Algorithmen können vorherige Teilergebnisse überschreiben, um das endgültige Resultat zu verbessern. Die Verfahren werden\n",
      "passend zu der Reihenfolge in der Pipeline in den folgenden Abschnitten vorgestellt. Abbildung 11 zeigt einen Überblick, welche Algorithmen verwendet werden.\n",
      "\n",
      "Abbildung 11: Reihenfolge der verwendeten Algorithmen\n",
      "\n",
      "4.3.1. SpaCy\n",
      "Zu Beginn der Arbeit wurde das vorhandene und bereits trainierte deutsche Modell von SpaCy evaluiert. Das Modell unterstützt das Setzen von Part of Speech\n",
      "(POS), Abhängigkeiten und NER welches für diesen Teil verwendet wurde. Das Modell verwendet eine eigene Word Embedding Strategie mit Unterwortmerkmalen und\n",
      "“Bloom”–Einbettungen sowie ein tiefes CNN um die Ergebnisse zu berechnen (SpaCy–\n",
      "Dokumentation 2019). Trainiert wurde das Modell auf einem Korpus von mehreren tausend, deutschen Wikipedia Artikeln mit 4 ausschlaggebenden Attributen: Lokation, Organisation, Personen und sonstigen. Getestet wurde auf Erkennen der Organisation, welches — in dem gegebenen Anwendungsfall — gleichbedeutend mit dem Hersteller des\n",
      "Produktes ist. Das Ergebnis eines Testszenarios zeigte, dass die Satzstruktur zwischen\n",
      "dem Anwendungsfall und dem Wikipediakorpus zu unterschiedlich ist, sodass das Attribut nicht erkannt wurde. Basierend auf dem Testszenario–Datensatz, der 14 verschiedene\n",
      "Eingaben enthält, wurde ein neues Modell trainiert. Abbildung 12 zeigt die Ergebnisse\n",
      "beider Modelle mit derselben Eingabe.\n",
      "\n",
      "30\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Abbildung 12: Ergebnisse der verschiedenen SpaCy–Modelle\n",
      "Das neue Modell wurde auf das Erkennen aller sechs Attribute trainiert. Dieses sollte\n",
      "zeigen, ob das Framework mit einer sehr geringen Menge an Daten lernen kann. Wie der\n",
      "Abbildung 12 zu entnehmen ist hat sich das Ergebnis gegenüber dem vortrainierten Modell deutlich verbessert. Das bedeutet, dass SpaCy, selbst mit einer geringen Menge an\n",
      "Daten, in der Lage ist entsprechende Ergebnisse zu erzeugen.\n",
      "Mit den Trainingsdaten aus dem ersten Iterationsschritt zeigte sich, dass sich das Modell stark verbesserte. Basierend auf der Annahme, dass mehr Trainingsdaten zu einem\n",
      "deutlich besseren und weiterhin performanten Modell führen, bildet der Named Enitity\n",
      "Tagger aus dem SpaCy Framework den ersten Schritt in der Pipeline. SpaCy bietet zudem\n",
      "eine Tokenizing Funktion welche die Eingabe in einzelne Token (z.B. Wörter, Satzzeichen\n",
      "usw.) unterteilt die in den nachfolgenden Schritten verwendet werden. Ein wesentlicher\n",
      "Nachteil der SpaCy NER Funktion ist, dass es die Eingaben von Bezeichnungen an der\n",
      "falschen Stelle erkennt. So werden Wörter als Produkt klassifiziert die keine sind. Aus\n",
      "diesem Grund wurde in der Pipeline eine Gewichtung eingebaut, die den folgenden Algorithmen das Recht gibt, vorherige Teilergebnisse zu überschreiben nicht jedoch zu löschen.\n",
      "Dieses ist von Vorteil da sich einzelne Schritte nur auf das Finden einiger Attribute fokussieren können, welche zum Ende der Pipeline ausgeführt werden, die zum Ausbessern\n",
      "vorheriger Fehler geeignet sind.\n",
      "\n",
      "4.3.2. Reguläre Ausdrücke\n",
      "Um eine der Schwächen des SpaCy–Modells auszugleichen, wurde ein regelbasierter Ansatz verwendet. Das sprachliche Modell ist für das Erkennen und richtige Unterscheiden\n",
      "von Zahlenwerten weniger geeignet. So wurden die Attribute Preis, Speicher und Kamera\n",
      "von der SpaCy Komponente häufig falsch klassifiziert. Der einzige wesentliche Unterschied\n",
      "ist die Einheit nach dem Zahlenwert wie z.B. 300 e, 256 GB und 13 MP. Zum Erkennen\n",
      "\n",
      "31\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "solcher Attribute werden reguläre Ausdrücke verwendet. Die Eingabe wird nach einem\n",
      "Zahlenwert durchsucht und anhand der folgenden Einheit klassifiziert. Um das Erstellen\n",
      "der regulären Ausdrücke zu vereinfachen, wird ein Ausdruck dreigeteilt. Das Präfix steht\n",
      "vor dem gesuchten Wert und beschreibt diesen z.B. “max”, “höchstens” oder “mid”. Nach\n",
      "dem Präfix kommt der Stamm, dieser beschreibt den Aufbau des gesuchten Zahlenwertes,\n",
      "in Python könnte es für europäische Preise wie folgt aussehen:\n",
      "1\n",
      "\n",
      "r e T a g g e r = ReTagging ( )\n",
      "\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "\n",
      "p r e f i x = [ ’ max ’ , ’ maximal ’ , ’ b i s zu ’ , ’ ab ’ , ’ mid ’ ,\n",
      "stam = [ ’ ( \\ d+\\ ,\\d { 1 , 2 } ) ’ , ’ ( \\ d+) ’ ]\n",
      "s u f f i x = [ ’ e ’ , ’ euro ’ ]\n",
      "\n",
      "’ ’]\n",
      "\n",
      "6\n",
      "7\n",
      "\n",
      "r e T a g g e r . add ( ’MONEY’ , p r e f i x , s u f f i x , stam )\n",
      "\n",
      "Listing 1: Regel zum Erstellen des regulären Ausdruck zum Erkennen des Preises\n",
      "Zum Schluss folgt das Suffix, es beschreibt die Einheit, die dieses Attribut haben könnte.\n",
      "Diese drei Mengen werden mit dem Attributbezeichner (z.B “MONEY”) der Methode\n",
      "übergeben, die alle Kombinationen aus den Mengen bildet, um daraus den regulären\n",
      "Ausdruck zu erzeugen.\n",
      "Die Tatsache das es ein regelbasierter Ansatz ist, erübrigt das genaue Evaluieren. Dieses\n",
      "Verfahren bietet sich für Attribute an, die hauptsächlich aus Zahlen bestehen und diese\n",
      "Anhand von Regeln erkannt werden können. Es ist von Vorteil, da keine Modelle trainiert werden müssen und direkt eingesetzt werden können. Dadurch wird ein schnelles\n",
      "Reagieren auf Ausdrücke, die neu hinzugefügt werden müssen, ermöglicht. Selbiges zeigt\n",
      "die Unflexibilität von regulären Ausdrücken, da diese nur Werte erkennen, die zuvor mit\n",
      "Regeln beschrieben wurden und zudem manuell gepflegt werden müssen. Zum Klassifizieren von Produkten sind reguläre Ausdrücke nicht geeignet, da weder ein Stamm noch ein\n",
      "Suffix genau definiert werden kann. Das Präfix allein ist nicht ausreichend (z.B. “suche []”,\n",
      "“verkaufe []”). Reguläre Ausdrücke sind schlicht zu unflexibel. Der regelbasierte Ansatz\n",
      "bildet den zweiten Schritt der Pipeline, damit dieser mögliche Fehler bei Attributen mit\n",
      "Zahlenwerten der SpaCy Komponente korrigieren kann.\n",
      "In der ersten Iterationsstufe wurden einige Regeln zum passenden Erkennen der Testdaten\n",
      "erstellt. Diese wurden geringfügig in der späteren Iterationen der Pipeline modifiziert.\n",
      "\n",
      "32\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "4.3.3. Metadaten Analyse\n",
      "Wörter haben neben ihrer Bedeutung noch Wortklassen, die basierend der grammatikalischen Eigenschaften des Wortes gesetzt werden. Abbildung 13 zeigt die erkannten Wortklassen (z.B.Verben, Nomen, numerisch oder Satzzeichen) sowie die Beziehungen zwischen\n",
      "den einzelnen Wörter. Das trainierte Modell von SpaCy ist in der Lage die Wortklassen\n",
      "den Wörtern zuzuordnen. Auch werden weitere Metadaten von SpaCy erkannt und den\n",
      "einzelnen Wörtern der Eingabe zugeordnet. Diese sind unter anderem, ob das Token nur\n",
      "aus Buchstaben besteht und ob es sich hierbei um ein Stoppwort handelt. Stoppwörter\n",
      "sind Wörter, die keinen Mehrwert für die Aussage beinhalten, weshalb diese in der Regel\n",
      "in der Datenauswertung ignoriert werden. Auch sind es Wörter, die überdurchschnittlich\n",
      "häufig in einer Sprache vorkommen und häufig als Füllwörter eingesetzt werden. Diese\n",
      "Wörter sind unter anderem: “also”, “bei” oder “hat” und sind bei SpaCy in dem Modell\n",
      "hinterlegt. Weitere Metadaten, die erfasst werden, sind die Position des Wortes in dem\n",
      "Text, die Länge des Wortes und ob der erste Buchstabe des Wortes großgeschrieben ist.\n",
      "\n",
      "Abbildung 13: Beispiel für erkannte Wortklassen des SpaCy Frameworks\n",
      "Basierend auf diese Informationen wurde ein einfaches, neuronales Netz trainiert, dass\n",
      "die Metadaten des einzelnen Wortes als Eingabe verwendet. Das Modell besteht aus drei\n",
      "voll vernetzten Schichten, von der eine Schicht ein versteckter Layer ist. Der letzte Layer\n",
      "des Netzes verwendet die “Binärer Schritt” Aktivierungsfunktion welche das Ergebnis auf\n",
      "die Werte 0 (kein Produkt) und 1 (Produkt) beschränkt. Trainiert wurde das Modell auf\n",
      "demselben Datensatz wie auch schon zuvor das SpaCy–Modell. Der Datensatz besteht\n",
      "aus ausschließlich grammatikalisch, korrekten Anfragen mit einer Maximallänge von 12\n",
      "Wörtern. Die folgenden Abbildungen 14 und 15 zeigen die Performance des Modells nach\n",
      "der ersten Iteration der Datenakquise.\n",
      "\n",
      "33\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Abbildung 14: Auswertung der Metadaten Analyse auf 70 Datensätzen\n",
      "\n",
      "Abbildung 15: Confusion Matrix der Metadaten Analyse auf 70 Datensätzen\n",
      "Kürzere Anfragen sind die Stärke des Netzes, da es bei diesen über eine höhere Genauigkeit\n",
      "verfügt. Wie der Metrik zu entnehmen ist, erkennt das Modell etwas mehr als ein Drittel\n",
      "der Produkte korrekt. Unter optimalen Bedingungen ist die Erkennung des Produktes\n",
      "\n",
      "34\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "sehr hoch und die Laufzeit des Algorithmus mit im Durchschnitt 25 ms sehr kurz.\n",
      "Einer genaueren Evaluation der Daten (Abbildung 14) zeigte, dass das Modell keine Produkte erkennt, die aus mehreren Wörtern bestehen. So wird zum Beispiel “iPhone 8” nicht\n",
      "erkannt, sondern nur der erste Teil des Wortes: “iPhone”. Dieses ist auf die Auswertung,\n",
      "in der die Tokens einzeln bewertet werden, zurückzuführen. Auch setzt das Modell eine\n",
      "korrekte Rechtschreibung der Eingabe voraus, da sonst den Wörtern falsche Metadaten\n",
      "zugeordnet werden, die das Ergebnis verfälschen.\n",
      "In der zweiten Iteration der Datenakquise wurde das Modell erneut auf die dann vorhandenen Daten trainiert. Der Datensatz erhöhte die maximale Länge der Eingabe und\n",
      "beinhaltete grammatikalisch, inkorrekte Eingaben. Das Ergebnis verschlechterte sich im\n",
      "Vergleich zum vorherigen erheblich, was auf die grammatikalisch, inkorrekte Eingabe\n",
      "zurückzuführen ist. Nach einer Vorverarbeitung, in der fehlerhafte Daten entfernt wurden,\n",
      "wurde das Modell erneut trainiert. Dieses erbrachte keine Verbesserung des ursprünglichen\n",
      "Modells, weshalb das erste Modell in dem Prototyp verwendet wurde.\n",
      "Werden nur die Metadaten betrachtet, gehen viele Informationen der Eingabe verloren,\n",
      "die bei einer Auswertung nicht beachtet werden. Auch werden Produkte, die aus mehreren Wörtern bestehen nie erkannt, da sich die Metadaten zu stark zu den einfachen\n",
      "Produkten unterscheiden. Aus diesen Gründen ist die Genauigkeit der Vorgehensweise\n",
      "limitiert. Durch die gute Performance bei optimaler Eingabe wird dieses Verfahren an\n",
      "dritter Stelle der Pipeline verwendet. Fehler der vorherigen Schritte werden korrigiert,\n",
      "wobei die Klassifizierung der Metadaten kaum bis gar keine Wörter falsch zuordnet.\n",
      "\n",
      "4.3.4. Targer\n",
      "Das Attribut Produkt wurde in den vorherigen Schritten nur unter bestimmten\n",
      "Umständen richtig klassifiziert, da unter anderem der Aufbau der Eingabe nicht beachtet\n",
      "wurde. In dem Abschnitt 2.2 wurden Word Embeddings vorgestellt, welche Wörter in\n",
      "Form eines Vektors beschreiben. Diese Repräsentation beinhaltet Informationen, anhand\n",
      "das folgende Modell in der Lage ist, Wörter mit Attributen zu versehen.\n",
      "\n",
      "35\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Abbildung 16: Aufbau und Funktionsweise des Targer–Modells nach (Chernodub 2018)\n",
      "Das Targer–Modell (Chernodub u. a. 2019) besteht aus der Kombination der Architekturen bidirectional Recurrent Neural Network (biRNN), CNN und CRF. Als RNN wird ein\n",
      "biLSTM–Modell verwendet welche im Kapitel 2 genauer erläutert wurde. Eine beispielhafte visuelle Darstellung des Modells kann Abbildung 16 entnommen werden. Bei dem\n",
      "Trainieren des Modells werden die GloVe Word Embeddings verwendet, um mit diesen Informationen die Buchstaben–Features der Eingabe zu erstellen. Die Buchstaben–Features\n",
      "oder auch Char–level features werden nach dem Trainieren mit dem Modell gespeichert.\n",
      "Bei der Verwendung des Modells werden nur die Char–level features benötigt und nicht\n",
      "mehr die gesamten Wortvektoren. Für den Ablauf des Netzes wird zunächst die Eingabe in die Buchstaben–Features umgewandelt, welche dann an die erste Ebene — also\n",
      "biLSTM — übergeben werden. Dort werden die Vektoren wie bereits in dem Abschnitt\n",
      "2.6 erläutert verarbeitet. Die daraus resultierenden Ergebnisse werden im Anschluss von\n",
      "dem CNN Netz verarbeitet. In dem letzten Schritt werden die Werte von einem CRF\n",
      "verarbeitet.\n",
      "Für diese Arbeit wurden GloVe Wortvektoren mit 300–Dimension verwendet, um die\n",
      "höchstmögliche Genauigkeit zu erzielen. Aufgrund der langen Trainingsdauer, sowie der\n",
      "großen Menge an benötigten Trainingsdaten wurde ein bereits trainiertes Modell verwendet (Deepset o.D.). Das Vokabular des Modells umfasst 400000 Wörter und wurde auf\n",
      "deutsche Wikipedia Artikel trainiert.\n",
      "Dem trainierten Modell wird eine Liste mit den einzelnen Wörtern der Eingabe übergeben.\n",
      "Die Rückgabe ist eine Liste mit gesetzten Attributen in dem CoNLL Format (Tjong Kim\n",
      "Sang und De Meulder 2003). In diesem Format entspricht ein “O” das für dieses Token kein\n",
      "Attribut gefunden wurde. Für das Produkt “iPhone X” werden die Bezeichnungen “B–\n",
      "\n",
      "36\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "PRODUCT” und “I–PRODUCT” verwendet. Der erste Teil der Bezeichnung beschreibt,\n",
      "ob es sich um einen Anfang des gesuchten Wortes handelt (“B–”). Besteht das gefundene\n",
      "Attribut aus mehreren Wörtern, werden alle folgenden Wörter mit “I–” als Präfix markiert.Trainiert wurde das Modell nur auf das Erkennen des Attributes Produkt welches\n",
      "in den folgenden Metriken (Abbildung 17 und 18) evaluiert wurde.\n",
      "\n",
      "Abbildung 17: Auswertung des Targer–Modells auf 70 Datensätzen\n",
      "\n",
      "37\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Abbildung 18: Confusion Matrix des Targer–Modells auf 70 Datensätzen\n",
      "Wie auf der Abbildung 17 zu erkennen erreicht das Modell eine hohe Genauigkeit, bei\n",
      "dem Erkennen des Produktes. Dieses ist darauf zurückzuführen, dass der Aufbau bzw.\n",
      "die Bedeutung des Satzes betrachtet wird und nicht die einzelnen Wörter. Die benötigte\n",
      "Laufzeit, um die Eingabe mit den entsprechenden Attributen zu versehen, wird durch diesen Schritt geringfügig (im Durchschnitt 125 ms pro Anfrage) beeinflusst, welches bei der\n",
      "Verarbeitung von einzelnen Anfragen den Ablauf nicht merkbar verlängert. Die Berechnung der Metriken wird stärker beeinflusst, da der gesamte bisherige Datensatz von der\n",
      "Pipeline nacheinander verarbeitet wird. Die gute Performance ist auf die Verwendung der\n",
      "Char–level features zurückzuführen, da nicht mehr die gesamten Wortvektoren benötigt\n",
      "werden.\n",
      "Das Targer–Modell ist nicht kontextsensitiv weshalb es Schwierigkeiten hat, Sätze mit\n",
      "mehreren Produkten bzw. Beziehungen zwischen den Produkten korrekt zu klassifizieren.\n",
      "Als Beispiel dient die folgende Eingabe “Mein altes Smartphone ist leider kaputt gegangen\n",
      "weshalb ich dringend ein neues iPhone X benötige!” richtig zu erkennen. Es tendiert dazu,\n",
      "das Attribut ”Produkt”doppelt zu setzen, zum einen für das Wort “Smartphone” und\n",
      "“iPhone X”. Ein alternatives Verhalten ist, dass nur das erste Wort der beiden Elemente\n",
      "mit dem Attribut versehen wird, was in diesem Fall “Smartphone” wäre und somit falsch\n",
      "ist. Durch eine Regel, die besagt, dass immer das zuletzt gefundene Element für ein\n",
      "\n",
      "38\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Attribut wiedergegeben werden soll, konnte das erste Szenario teilweise gelöst werden,\n",
      "aber nicht alle Eingaben folgen dieser Regel.\n",
      "\n",
      "4.3.5. ELMo\n",
      "In dem Abschnitt 2.2.3 wurde das ELMo Word Embedding vorgestellt. Der Vorteil dieser\n",
      "Repräsentation liegt darin, dass die Vektoren der Wörter abhängig von dem Kontext\n",
      "sind und somit das Szenario expliziter beschreiben. Wie bereits erwähnt, ist das Targer–\n",
      "Modell nicht kontextsensitiv weshalb es Schwierigkeiten hat, bestimmte Eingaben korrekt\n",
      "mit Attributen zu versehen. In diesem Schritt wird das grundlegende Modell von Targer\n",
      "(also biLSTM, CNN, CRF) mit der ELMo Repräsentation als Eingabe verwendet, um so\n",
      "die Vorteile beider Methoden zu kombinieren.\n",
      "In dem vorherigen Kapitel wurde bereits beschrieben, wie das Modell aufgebaut ist und\n",
      "auch wie die einzelnen Schichten zusammenarbeiten. Der wesentliche Unterschied zwischen diesen beiden Ansätzen ist, dass keine Char–level features mehr verwendet werden.\n",
      "Dies bedeutet, dass für die Verwendung des Modells immer die GloVe Word Embeddings\n",
      "geladen sein müssen. Zusätzlich dazu werden die bereits trainierten Gewichtungen, sowie\n",
      "die dazugehörigen Einstellungen, zum Verwenden des Modells benötigt. Die Gewichtungen wurden trainiert, um den jeweiligen Kontext einer Eingabe zu bestimmen und so die\n",
      "dazugehörigen Wortvektoren zu ermitteln, die in dem Modell verwendet werden. Diese\n",
      "Vorgehensweise wurde in Abschnitt 2.2.3 genauer erläutert.\n",
      "Für selbst trainierte ELMo Word Embeddings wird eine große Menge von Daten und\n",
      "Zeit benötigt. Das in dieser Arbeit verwendete Modell (May 2019), (Reimers und Gurevych 2019) wurde auf einen deutschen Wikipedia Korpus trainiert. Zusätzlich wurden die\n",
      "Kommentare der verwendeten Artikel genutzt, um Umgangssprache in den Datensatz mit\n",
      "einzubeziehen. Außerdem werden die zum Modell gehörenden Gewichtungen und Optionen verwendet.\n",
      "Da das Modell immer die gesamten Word Embeddings benötigt um verwendet werden zu\n",
      "können, muss die 4 GB große ELMo Datei dauerhaft im RAM verfügbar sein. Aus diesem Grund wurde das Modell in eine separate Anwendung ausgelagert. Dieses bietet eine\n",
      "Representational State Transfer (REST) Schnittstelle, an die eine Eingabe übergeben\n",
      "wird. Diese wird von dem Modell verarbeitet und ein Dictionary mit dem Attributbezeichner als Schlüssel und dem gefundenen Ergebnis als Wert zurückgesendet. Der Pipeline selbst wurde ein Schritt hinzugefügt, welche diese Schnittstelle verwendet, um die\n",
      "entsprechenden Ergebnisse zu erhalten. Durch diese Designentscheidung war es möglich,\n",
      "die benötigten Ressourcen der hauptsächlichen Anwendung gering zu halten und weitere\n",
      "\n",
      "39\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Algorithmen können mittels der REST Schnittstelle hinzugefügt werden.\n",
      "\n",
      "Abbildung 19: Auswertung des ELMo–Modells auf 70 Datensätzen\n",
      "\n",
      "Abbildung 20: Confusion Matrix des ELMo–Modells auf 70 Datensätzen\n",
      "\n",
      "40\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Das Modell weist die höchste Genauigkeit aller verwendeten Algorithmen auf, wie den\n",
      "Abbildungen 19 und 20 zu entnehmen ist. Dadurch wird deutlich, dass die Betrachtung\n",
      "des Kontextes für den Anwendungsfall zielführend ist. Als Beispiel dient folgende Eingabe\n",
      "“hallo, wir möchten am kommenden wochenende mit den nachbarn grillen und ich wollte\n",
      "dafür einen salat machen weshalb ich auf der suche nach einer salatschüssel bin da mir\n",
      "aufgefallen ist, dass ich keine habe” in der das gesuchte Produkt “salatschüssel” korrekt\n",
      "erkannt wird. Ein anderes Produkt an derselben Stelle wird ebenfalls mit hoher Wahrscheinlichkeit vom Algorithmus korrekt erkannt. Dieses zeigt, dass der Algorithmus nicht\n",
      "die charakteristischen Eigenschaften eines jeden Produktes lernt, sondern die Position, an\n",
      "der ein Produkt stehen würde. Durch dieses Verhalten ist das Modell in der Lage, mit\n",
      "wenigen Trainingsdaten ein überaus gutes Ergebnis zu erzielen.\n",
      "\n",
      "4.3.6. Fuzzy Matching\n",
      "Der letzte Schritt der Pipeline stellt sicher, dass bestimmte Attribute erkannt werden. So\n",
      "können bestimmte Werte, auf die die Pipeline bisher nicht trainiert wurde, den passenden Attributen zugewiesen werden. Dadurch ist ein schnelles Hinzufügen einzelner Werte\n",
      "möglich, bevor die verwendeten Modelle trainiert werden.\n",
      "Um verschiedene Schreibweisen des Wortes abzudecken, wird ein Fuzzy Matching (Seatgeek 2015) verwendet. Für jedes zuvor definierte Wort wird geprüft mit welcher Wahrscheinlichkeit dieses sich in dem Satz befindet. Dafür wird die Levenshtein Entfernung zwischen\n",
      "einem definierten Wort und einem Wort aus dem Satz gebildet. Da Fuzzy Matching (oder\n",
      "auch Approximation Matching) die Eigenschaft besitzt immer Ergebnisse zu liefern, wird\n",
      "ein zuvor definierter Grenzwert angelegt, wie hoch die Übereinstimmung mindestens sein\n",
      "muss, bevor die Wörter als identisch gelten. Bei Produkten wird ein Grenzwert von 95\n",
      "% Übereinstimmung angelegt, damit die Unterschiede zwischen den einzelnen Versionsnummern noch erkannt werden, wie z.B. bei Smartphones (iPhone 8 und iPhone X). Der\n",
      "Nachteil bei diesem hohen Grenzwert ist, dass die verschiedenen Schreibweisen für ein\n",
      "Produkt einzeln angegeben werden müssen (z.B. “iphone 8” und “iPhone 8”), da diese\n",
      "sonst unter Umständen nicht mehr erkannt werden. Bei anderen Attributen zeigte sich,\n",
      "dass eine Übereinstimmung von 80 % ausreicht, um ein genaues Ergebnis zu erzielen, da\n",
      "sich Attribute wie “Hersteller” üblicherweise nicht nur in einem einzelnen Buchstaben\n",
      "unterscheiden.\n",
      "Ein weiteres Problem bei Fuzzy Matching ist, dass nicht nur auf die höchste\n",
      "Übereinstimmung geachtet werden darf, sondern auch auf die Länge der Wörter. Befinden sich beispielsweise die Wörter “iPhone” und “iPhone X” in dem Fuzzy Matcher\n",
      "\n",
      "41\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "und als Eingabe erfolgt der Satz: “Hey ich bin auf der suche nach einem iPhone X” werden\n",
      "die hinterlegten Werte der Reihe nach mit der Eingabe auf teilweiser Übereinstimmung\n",
      "geprüft. Beide Werte erreichen eine Genauigkeit von 100 % und das zurückgegebene Ergebnis hängt von der Reihenfolge der Prüfung ab. Um immer den spezifischen Ausdruck\n",
      "zu identifizieren werden stets längere Werte den kürzeren gegenüber bevorzugt, solange\n",
      "diese sich noch über dem definierten Grenzwert befinden. Dadurch wird sichergestellt,\n",
      "dass in dem Beispielszenario der Wert “iPhone X” erkannt wird.\n",
      "\n",
      "42\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Abbildung 21: Vergleich der Genauigkeit nur des ELMo–Modells (oben) und mit anschließendem Fuzzy Matching (unten)\n",
      "\n",
      "43\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Die Abbildung 21 zeigt zwei Messungen, die korrekt erkannten Produkte ohne Fuzzy\n",
      "Matching (oben) und mit Fuzzy Matching als letzten Schritt (unten). Wie der Abbildung\n",
      "zu entnehmen ist, hat das Fuzzy Matching in diesem Fall das Ergebnis verschlechtert. Dem\n",
      "Fuzzy Matcher wurden Produkte hinzugefügt, welche bereits von der vorherigen Pipeline\n",
      "erkannt worden sind, aber der Fuzzy Matcher nicht alle Schreibweisen kennt. Das Produkt\n",
      "wird in einer leicht anderen Schreibweise gefunden und durch die Gewichtung der Pipeline\n",
      "wird das vorherige Ergebnis überschrieben. Dadurch ist das Produkt, welches am Ende\n",
      "von der Pipeline erkannt wurde, nicht korrekt in der Eingabe vorhanden und es wird nicht\n",
      "als korrekt klassifiziert gezählt.\n",
      "Die Laufzeit des Fuzzy Matching unter der Verwendung der Levenshtein Entfernung ist\n",
      "abhängig der Anzahl der Werte, auf die die Eingabe geprüft werden soll. So wird der Prototyp mit acht Werten betrieben, die mit 3 ms pro Eingabe die Laufzeit nicht wesentlich\n",
      "beeinflussen. Weitere Tests zeigten, dass die Laufzeit ab 250 Werten bereits durchschnittlich 254 ms beträgt. Dieses zeigt wie bereits in Abbildung 21 dargestellt, dass Fuzzy\n",
      "Matching nur für wenige Szenarien verwendet werden sollte, um so das Ergebnis bis zum\n",
      "Trainieren der neuen Modelle zu verbessern.\n",
      "\n",
      "4.3.7. Zusammenspiel der Pipeline\n",
      "In den vorherigen Abschnitten wurden die Funktionalitäten sowie die einzelnen Vorteile\n",
      "und Nachteile jeder Komponente vorgestellt. Es wurden verschiedene Algorithmen angewendet, um das Ergebnis möglichst genau abbilden zu können. Alle Algorithmen zeigten\n",
      "Schwierigkeiten mit dem Erkennen von Produktversionen wie sie häufig bei Smartphones\n",
      "zu finden sind (z.B. Galaxy S10). Um diese Szenarien abfangen zu können, wird nach\n",
      "der Ausführung der Pipeline eine Nachverarbeitung der Ergebnisse vorgenommen. Dazu\n",
      "wird jedes Token nach dem gefundenen Produkt analysiert. Es wird geprüft, ob dieses\n",
      "Token eine Kombination aus Buchstaben und Zahlen ist oder ob es ausschließlich aus\n",
      "Großbuchstaben besteht. In beiden Fällen wird das Token zu dem Produkt hinzugefügt\n",
      "und es wird erneut das folgende Token betrachtet. Trifft keiner der beiden Fälle zu, so\n",
      "wird der Prozess beendet und die Nachverarbeitung ist abgeschlossen. Dieses Vorgehen\n",
      "verbessert die Genauigkeit der Pipeline was im Abschnitt Evaluation zusammen mit den\n",
      "ELMo Algorithmus genauer betrachtet wird. Abbildung 22 zeigt den gesamten Aufbau der\n",
      "Pipeline mit allen Algorithmen die verwendet werden. Die Laufzeit der gesamten Pipeline\n",
      "beträgt 837 ms und liegt somit unter den geforderten drei Sekunden aus NF1.\n",
      "\n",
      "44\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Abbildung 22: Pipeline mit allen Algorithmen und den ausgelegten Attributen\n",
      "\n",
      "4.4. Verwendeten Technologien\n",
      "Die Oberfläche ist als Webanwendung verfügbar und wurde mit der Programmiersprache\n",
      "Python und dem Webframework Flask realisiert. Flask ist ein leichtgewichtiges Framework\n",
      "welches nur die Template–Engine Jinja2 als Abhängigkeit besitzt. Die einzelnen Seiten\n",
      "wurden in HTML erstellt und mit Jinja2 dynamisch gestaltet, um eine hohe Flexibilität\n",
      "der Seiten zu erhalten. Jede Funktionalität ist durch einen Flask Endpoint zugänglich\n",
      "und wird durch die Webseite aufgerufen.\n",
      "Das Aussehen der Weboberfläche wurde mit dem CSS–Framework Bootstrap gestaltet.\n",
      "Bootstrap ist ein weit verbreitet Framework und wird von vielen verschiedenen Webseiten\n",
      "eingebunden. Durch die Verwendung von Bootstrap wird ein einheitliches Aussehen mit\n",
      "anderen Webseiten hergestellt. Dieses hat zufolge, dass durch den Wiedererkennungswert\n",
      "der Bedienelemente die Nutzung für Anwender erleichtert wird.\n",
      "Für die Persistierung der Daten wird eine Neo4J Datenbank verwendet. Neo4J ist eine\n",
      "Graphdatenbank und wurde von (Vicknair u. a. 2010) den relationalen Datenbanken gegenübergestellt und bewertet. Die verschiedenen Datenbankzugriffe wurden in Methoden\n",
      "gekapselt, um diese separiert von der Anwendung zu verwalten.\n",
      "Die Pipeline wird als eigene Komponente eingebunden und stellt zwei Methoden zur\n",
      "Verfügung, über die der Webserver die Funktionalität aufrufen kann. Die resolve Methode\n",
      "erhält als Übergabeparameter eine Anfrage, die ausgewertet wird. Zurückgegeben wird ein\n",
      "Dictionary bei dem der Schlüssel dem Attributbezeichner und der Wert der gefundenen\n",
      "Sequenz entspricht. Die zweite Methode wird zum Berechnen der Metriken verwendet und\n",
      "erhält eine Liste mit allen Datensätzen sowie den zugeordneten Attributen. Zurückgegeben\n",
      "wird ein Container, der die Ergebnisse für jeden Algorithmus sowie der gesamten Pipeline\n",
      "enthält.\n",
      "\n",
      "45\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "4.5. Entwicklung des Prototyps\n",
      "In den vorherigen Kapiteln wurde beschrieben wie die Pipeline funktioniert, die zum Erkennen der einzelnen Attribute eingesetzt wird. Simultan zur Entwicklung der Pipeline\n",
      "entstand ein Prototyp, der zur Verbesserung der Pipeline entstand. Später wurden weitere Funktionen ergänzt, die sowohl eine Verwendung der Pipeline zeigen als auch das\n",
      "Hinzufügen und Bearbeiten des Datenbestandes vereinfachen. Der Prototyp beschränkt\n",
      "sich auf das Erkennen und Taggen von 6 Attributen (Produkt, Hersteller, Preis, Farbe,\n",
      "Speicher, Kamera) welche alle in der Smartphone–Domäne vertreten sind. Auch stellt der\n",
      "Prototyp keine nutzerorientierte Anwendung dar, sondern lediglich eine funktionsorientierte Oberfläche zum Bedienen der Pipeline.\n",
      "\n",
      "4.5.1. Eingabemethode Inserat\n",
      "Auf der Startseite wird dem Nutzer die Möglichkeit geboten eine Eingabe zu tätigen. Beim\n",
      "Bestätigen der Eingabe wird die eingegebene Anfrage von der Pipeline verarbeitet und die\n",
      "gefundenen Ergebnisse werden — damit diese für den Benutzer besser nachvollziehbar sind\n",
      "— farblich hervorgehoben. Der Anwender entscheidet, ob alle gesuchten Attribute durch\n",
      "die Pipeline korrekt klassifiziert werden. Ist die Klassifizierung falsch wird der Anwender\n",
      "aufgefordert, die eigene Anfrage selbst mit den passenden Tags zu versehen. Das Zuweisen\n",
      "der Attribute geschieht in der Oberfläche des Taggers. Erst wird eine Wortsequenz aus\n",
      "der Eingabesequenz hervorgehoben und im Anschluss die passende Schaltfläche betätigt,\n",
      "um der Wortkette das Attribut zuzuweisen. Der Tagger kann auf beliebige Attribute\n",
      "erweitert werden. Dazu reicht es aus, eine neue Schaltfläche hinzuzufügen und diese mit\n",
      "einem nicht verwendeten Bezeichner zu versehen. Dem Attribut wird eine neue Farbe\n",
      "zugeteilt. Das neue Attribut kann verwendet werden, um zukünftige Daten zu annotieren.\n",
      "Damit das Attribut automatisch erkannt wird, muss die Pipeline erneut trainiert werden.\n",
      "Wie bereits in der Datenakquise vorgestellt, wurde dieser Teil des Prototyps verwendet,\n",
      "um die Datenbasis zu erweitern.\n",
      "\n",
      "4.5.2. Berechnung der Metriken\n",
      "Die in dem Kapitel 4 gezeigten Diagramme werden durch den Prototypen, basierend auf\n",
      "den zugrundeliegenden Daten, automatisiert erstellt. Zum Erstellen der Diagramme werden die Daten aus der Datenbank verwendet, die zuvor von Anwendern in die Oberfläche\n",
      "des Prototyps eingegeben wurden. Die Sätze werden erneut an die Pipeline übergeben,\n",
      "sodass die Algorithmen das Ergebnis berechnen. Dieses wird mit den korrekten Attributen\n",
      "aus der Datenbank verglichen und die unterschiedlichen Diagramme werden berechnet. Al-\n",
      "\n",
      "46\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "le Diagramme betrachten dabei die gesamte Eingabe, bewerten also nicht einzelne Wörter.\n",
      "Die erstellten Diagramme sind: Confusion Matrix, Piechart und Barchart.\n",
      "Abbildung 23 zeigt die Confusion Matrix für das Attribut “Produkt” mit dem verwendeten Algorithmus ELMo. Die vertikale Achse gibt an, ob sich das Attribut in der Eingabe\n",
      "befindet oder nicht. Auf der horizontalen Achse wird das Ergebnis des Algorithmus angegeben. Bei einem guten Ergebnis des Algorithmus sind die Felder mit übereinstimmenden\n",
      "Achsen–Bezeichner höher als die übrigen Felder. Erst bei einer exakten Übereinstimmung,\n",
      "Algorithmus–Ergebnis und Eingabe–Ergebnis, wird der Wert des übereinstimmenden Feldes des Attributes erhöht. Durch eine Fehlermeldung verhindert die Oberfläche Eingaben\n",
      "die nicht mindestens das Attribut “Produkt” enthalten, weshalb wie auf der Abbildung\n",
      "23 zu erkennen, alle Eingaben dieses Attribut besitzen. Aus dem Ergebnis der Confusion\n",
      "Matrix werden die Werte Accuracy, Precision, Recall und somit auch der F1–Score berechnet. Der Prototyp bietet die Möglichkeit, die Confusion Matrix für jedes Attribut mit\n",
      "jedem Algorithmus darzustellen.\n",
      "\n",
      "Abbildung 23: Confusion Matrix für den ELMo Algorithmus und dem Attribut Produkt\n",
      "Die Confusion Matrix beinhaltet nicht alle Information, die benötigt werden, um die\n",
      "Performance der Pipeline messen zu können. Die Balkendiagramme zeigen wie oft die\n",
      "\n",
      "47\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "einzelnen Attribute vorkommen und erkannt werden. Dabei zeigt der blaue Balken an,\n",
      "wie oft das einzelne Attribut in dem Datenbestand vorkommt. Der rote Balken zeigt, wie\n",
      "oft das einzelne Attribut komplett korrekt erkannt wird (Angaben in Prozent). Aus dieser\n",
      "Metrik lässt sich sehr einfach die effektive Performance der Algorithmen beurteilen, da\n",
      "die korrekte Klassifizierung der Attribute der Häufigkeit gegenübergestellt wird. Dieses\n",
      "Diagramm zeigt im Wesentlichen die Genauigkeit des Algorithmus für jedes Attribut, weshalb das Balkendiagramm für jeden Algorithmus sowie der gesamten Pipeline dargestellt\n",
      "werden kann.\n",
      "In den Kuchendiagrammen wird die Unterteilung der Klassifizierung weiter aufgesplittet.\n",
      "Die Attribute werden anhand von 6 Teilgruppen bewertet, um ein besseres Verständnis\n",
      "der Klassifizierung des Algorithmus zu erhalten. Die Attribute aus den getesteten Anfragen können dabei einer dieser Gruppen zugeordnet werden: Erkannt, richtige Klasse,\n",
      "Erkannt, falsche Klasse; Zu viel/wenig erkannt, richtige Klasse; Zu viel/wenig erkannt,\n",
      "falsche Klasse; Falsch erkanntes Wort und Attribut nicht erkannt. Durch die Aufteilung\n",
      "wird deutlich, dass, auch wenn der Algorithmus das Attribut nicht komplett korrekt klassifizieren konnte, dennoch akzeptable Teile der Lösung erkannt werden. So wurde häufig die\n",
      "Produktbezeichnung wie ı̈Phoneërkannt, nicht aber der Zusatz ”Xöder SSE”, was durch\n",
      "dieses Diagramm deutlich wurde. Wie die Confusion Matrix kann das Kuchendiagramm\n",
      "für alle Attribute und Komponenten der Pipeline erstellt werden.\n",
      "\n",
      "4.5.3. Chatbot\n",
      "Als beispielhafte Anwendung bietet der Prototyp eine Chatbot Funktion. Hier können\n",
      "Anwender Anfragen oder Angebote stellen, auf die das System nach einem passenden\n",
      "Gegenstück sucht. Als Beispiel könnte die Eingabe “Hey, letzte Woche ist mein Handy\n",
      "kaputt gegangen, weshalb ich jetzt auf der Suche nach einem neuen Apple iPhone X in\n",
      "Weiß für unter 800 e bin” dienen. Nach dem Absenden wird die Eingabe der Pipeline\n",
      "übergeben und die wesentlichen Attribute werden extrahiert. Basierend auf dieser Eingabe wird eine Anfrage an die Datenbank gestellt, welche passende Gegenangebote und die\n",
      "dazugehörigen Ergebnisse liefert. In einem einfachen Matchmaking wird geprüft, welches\n",
      "dieser Angebote am ehesten zur gegebenen Anfrage passen würde. Dabei wird versucht,\n",
      "möglichst viele übereinstimmende Attribute zu finden. Beim Preis wird die Rolle beachtet: stellt der Anwender eine Anfrage so wird ein geringerer Preis bevorzugt. Handelt es\n",
      "sich hingegen um ein Angebot, wird die Kaufanfrage mit dem höchst genannten Preis bevorzugt. Auf die beispielhafte Eingabe könnte folgende Ausgabe erfolgen “Hey ich biete\n",
      "hier mein neues Apple iPhone X in weiß für 800 e”. Die Antwort enthält 3 Attribute von\n",
      "Interesse auf die das Matchmaking prüfen kann, die alle auf die Suchanfrage zutreffen.\n",
      "\n",
      "48\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Abbildung 24 zeigt die Oberfläche mit dem Beispiel als Eingabe.\n",
      "\n",
      "Abbildung 24: Beispielverlauf einer Anfrage über den Chatbot (gelesen von unten nach\n",
      "oben)\n",
      "Die Gruppensuche (Abschnitt 3.2) wird durch zuvor definierte Relationen in dem Knowledge Graph ermöglicht. Eine mögliche Eingabe könnte dann wie folgt aussehen: “Hallo,\n",
      "für meinen Sohn bin ich auf der Suche nach einem Apple Smartphone”. Diese Eingabe enthält weniger konkrete Informationen als das vorherige Beispiel. Die Pipeline hat\n",
      "zwei Attribute gefunden: Hersteller Apple und Produkt Smartphone. Mit dem vorherigen Ansatz würde kein Produkt gefunden werden da die Firma Apple kein Produkt mit\n",
      "dem Namen Smartphone herstellt, sondern nur Geräte, die der Kategorie Smartphone\n",
      "angehören. Um diese Fälle zu identifizieren wird geprüft, ob das gesuchte Produkt in\n",
      "der Wissensdatenbank vorhanden ist. Trifft dieses zu, wird über Relationen geprüft auf\n",
      "welche anderen Produkte der Eintrag verweist. Basierend auf dem Beispiel könnte das\n",
      "Ergebnis diese Werte enthalten: “iPhone 5”, “iPhone 6”, “iPhone 7”, “iPhone 8” oder\n",
      "“iPhone X”. Im Anschluss wird der bereits oben beschriebene Vorgang wiederholt, nur\n",
      "dass anstelle eines Produktes in der Datenbank auf jedes dieser Attribute verglichen wird.\n",
      "\n",
      "49\n",
      "\n",
      "\f",
      "Kapitel 4\n",
      "\n",
      "Umsetzung\n",
      "\n",
      "Zum Schluss folgt ein Matchmaking, um den besten Treffer zu finden, welcher dann dem\n",
      "Anwender angezeigt wird wie es bereits vorgestellt wurde.\n",
      "Für diese Art der Produktfindung wird das genutzte Wissen vorausgesetzt. Es wurde im\n",
      "Vorfeld definiert, dass es die Kategorie Smartphone gibt und auch welche Produkte zu\n",
      "dieser Kategorie gehören. Das System lässt sich beliebig auf weitere Kategorien erweitern.\n",
      "So könnte die Kategorie Tablet hinzugefügt werden, in dem der Bezeichner der Kategorie\n",
      "(hier Tablet) der Wissensdatenbank angehangen wird. Im Anschluss müssen die möglichen\n",
      "Ausprägungen der Kategorie (z.B. ‘iPad’, ‘iPad Air’, ‘iPad Pro’) hinterlegt werden. Dann\n",
      "würde die Eingabe: “Für meinen Neffen suche ich ein neues Tablet, gerne gebraucht aber\n",
      "unter 300 e” sämtliche der Kategorie Tablet enthaltenen Produkte finden.\n",
      "\n",
      "50\n",
      "\n",
      "\f",
      "Kapitel 5\n",
      "\n",
      "Evaluation\n",
      "\n",
      "5. Evaluation\n",
      "Dieses Kapitel unterteilt sich in die Evaluation zweier Aspekte. In dem ersten Abschnitt\n",
      "werden die verwendete Evaluationsmethodiken vorgestellt. In dem nächsten Abschnitt\n",
      "wird die Performance der verwendeten Algorithmen sowie der gesamten Pipeline untersucht. Es werden die im Abschnitt 3.5 vorgestellten Bewertungskriterien verwendet, um\n",
      "einen genauen Einblick der Ergebnisse zu erhalten. Der dritte Abschnitt befasst sich mit\n",
      "der Evaluation der Oberfläche des Prototyps. Die im Abschnitt 3.2 aufgestellten Anwendungsfälle wurden mit einen Fragebogen an zehn Probanden gestellt. Die Ergebnisse\n",
      "werden im Abschnitt 5.3 analysiert.\n",
      "\n",
      "5.1. Evaluationsmethodik\n",
      "Das Ziel dieser Arbeit ist es, ein System zu erstellen, welches mit einer geringen Menge von\n",
      "Trainingsdaten dem Anwender das Gefühl vermittelt verstanden zu werden. Um dieses\n",
      "beurteilen zu können wurde eine Nutzerevaluation und mehrere Messungen durchgeführt.\n",
      "Für die Messungen werden die Daten aus beiden Iterationen der Datenakquise verwendet,\n",
      "um diese Ergebnisse mit den Daten aus der ersten Iteration zu vergleichen. Der F1–\n",
      "Score beschreibt dabei die Genauigkeit der jeweiligen Algorithmen. Zusätzlich werden\n",
      "die Werte: Accuracy, Precision und Recall betrachtet, um die Forschungsfrage NF1 zu\n",
      "beantworten und damit die Ergebnisse mit anderen Arbeiten verglichen werden können.\n",
      "In dem Abschnitt 3.5 wurden noch sechs weitere Klassen vorgestellt, die ebenfalls für eine\n",
      "ausführlichere Evaluation betrachtet werden. Die NA2 ist durch Zahlenwerte schwer zu\n",
      "beantworten, weshalb eine Nutzerevaluation durchgeführt wurde.\n",
      "Um überprüfen zu können ob Anwender das Gefühl haben von dem System verstanden\n",
      "zu werden reicht es nicht aus, eine bestimmte Genauigkeit zu erreichen. Anhand mehrerer\n",
      "Anwendungsfälle sowie einen Fragebogen wird eine Nutzerevaluation durchgeführt, um\n",
      "die Oberfläche sowie das Verständnis auszuwerten.\n",
      "\n",
      "5.2. Auswertung der Algorithmen\n",
      "Das vorherige Kapitel befasste sich mit verschiedenen Algorithmen, die zusammen kombiniert wurden, um ein optimales Ergebnis zu erzielen. Die höchste Gewichtung wurde\n",
      "dem ELMo Algorithmus zugeteilt, da dieser in der ersten Evaluation die höchste Genauigkeit aufweisen konnte. In diesem Abschnitt wird dieser Algorithmus, sowie die gesamte\n",
      "Pipeline einer ausführlichen Evaluation unterzogen, um die Performance genauer zu charakterisieren.\n",
      "\n",
      "51\n",
      "\n",
      "\f",
      "Kapitel 5\n",
      "\n",
      "Evaluation\n",
      "\n",
      "Zu Beginn wurden alle Modelle, bis auf eines, in der Pipeline mit 70 Datensätzen verschiedener Länge und Form trainiert. Das übrige Modell wurde zunächst mit 16 Datensätzen\n",
      "und für eine Evaluation erneut mit 70 Datensätzen trainiert. Basierend auf diesen Ergebnissen wurden die Modelle bewertet, ob und wie diese sich in die Pipeline einbauen lassen.\n",
      "Der aktuelle Datensatz umfasst 193 Einträge, die im Laufe der Entwicklung gesammelt\n",
      "wurden.\n",
      "\n",
      "Abbildung 25: Performance der gesamten Pipeline\n",
      "Abbildung 25 zeigt die Performance der gesamten Pipeline mit den anfänglich trainierten\n",
      "Modellen. Bei dem Attribut “Produkt” wird eine Genauigkeit von 80,8 % erzielt, für die\n",
      "übrigen Attribute wurden keine Modelle trainiert. Die übrigen Werte werden nur durch\n",
      "Ansätze wie Reguläre Ausdrücke bzw. Fuzzy Matching ermöglicht. Dieses Ergebnis zeigt\n",
      "das bereits mit einer geringen Menge an Daten, das Modell in der Lage ist in 4 von 5\n",
      "Fällen das Produkt korrekt zu klassifizieren. 79,8 % werden von dem ELMo Algorithmus\n",
      "erkannt, die Nachverarbeitung der gesamten Pipeline verbessert das Ergebnis auf 80,8\n",
      "%. Szenarien, die in dieser Statistik nicht berücksichtigt werden, sind unter anderem\n",
      "Attribute, die nur in Teilen erkannt wurden. “Galaxy S10” ist ein beispielhaftes Produkt,\n",
      "dass hätte erkannt werden sollen, von der Pipeline wurde “Galaxy” erkannt, was teilweise\n",
      "korrekt ist. Abbildung 26 zeigt eine genauere Analyse des ELMo Algorithmus. Es werden\n",
      "zusätzlich zu den Klassen “Erkannt, richtige Klasse” und “Attribut nicht erkannt” noch\n",
      "vier weitere Klassen erfasst: “Erkannt, falsche Klasse”, “Zu viel/wenig erkannt, richtige\n",
      "Klasse”, “Zu viel/wenig erkannt, falsche Klasse” und “Falsch erkanntes Wort”.\n",
      "\n",
      "52\n",
      "\n",
      "\f",
      "Kapitel 5\n",
      "\n",
      "Evaluation\n",
      "\n",
      "Abbildung 26: Piechart Analyse der ELMo Komponente\n",
      "Wie der Abbildung 26 zu entnehmen ist wurden 9,3 % (“Attribut nicht erkannt” und\n",
      "“Falsch erkanntes Wort”) der Anfragen unzureichend verarbeitet. In 10,9 % der Fälle\n",
      "wurde zu viel bzw. zu wenig des gesuchten Produktes erkannt, was — je nach Aufgabenstellung — bereits zielführend ist. Durch Optimierung der Nachverarbeitung wäre die\n",
      "Pipeline imstande gegenüber den bisher erzielten 1 %, die Eingabe um 10,9 % selbstständig\n",
      "zu verbessern. Alternativ könnte das Modell mit einem größeren Datensatz trainiert werden, um eine allgemeine Verbesserung der Ergebnisse zu erzielen.\n",
      "Durch die Datenakquise sowie den Testdaten sind insgesamt 260 Datensätze gesammelt\n",
      "worden, die zum Trainieren und Verifizieren verwendet wurden. Die Daten fokussierten\n",
      "sich hauptsächlich auf Produkte aus der Kategorie Smartphone, aber auch andere Produktkategorien waren vertreten. Die Länge der Sätze war variabel, die Rechtschreibung\n",
      "wird nicht beachtet. Die Daten wurden durch die Oberfläche des Prototyps gesammelt,\n",
      "weshalb keine Vorverarbeitung des Datensatzes notwendig war. Zum Trainieren des Modells wurden die Daten aufgeteilt. Auf 90 % der Datensätze — also 234 Einträge — wurde\n",
      "das Modell trainiert. Die restlichen 10 % wurden für die Verifizierung verwendet. Aufgrund\n",
      "der geringen Datenmenge war es möglich, dass bestimmte Formulierungen der Sätze nur\n",
      "zum Testen und nicht zum Trainieren verwendet wurden. Um diese Problematik zu umgehen wurde das Modell in zehn Durchgängen mit verschiedenen Daten zum Verifizieren\n",
      "trainiert. Für ein endgültiges Ergebnis wurde der Durchschnitt der Trainingsdurchläufe\n",
      "verwendet.\n",
      "\n",
      "53\n",
      "\n",
      "\f",
      "Kapitel 5\n",
      "\n",
      "Evaluation\n",
      "\n",
      "Durchlauf\n",
      "1.\n",
      "2.\n",
      "3.\n",
      "4.\n",
      "5.\n",
      "6.\n",
      "7.\n",
      "8.\n",
      "9.\n",
      "10.\n",
      "Avg.\n",
      "\n",
      "Precision\n",
      "0,857\n",
      "0,889\n",
      "0,905\n",
      "0,880\n",
      "0,815\n",
      "0,885\n",
      "0,889\n",
      "0,963\n",
      "0,793\n",
      "0,815\n",
      "0,869\n",
      "\n",
      "Recall\n",
      "0,923\n",
      "0,923\n",
      "0,942\n",
      "0,846\n",
      "0,846\n",
      "0,885\n",
      "0,923\n",
      "0,963\n",
      "0,767\n",
      "0,771\n",
      "0,879\n",
      "\n",
      "F1–Score\n",
      "0,8889\n",
      "0,9057\n",
      "0,9231\n",
      "0,8627\n",
      "0,8302\n",
      "0,8850\n",
      "0,9057\n",
      "0,9630\n",
      "0,7797\n",
      "0,7925\n",
      "0,8736\n",
      "\n",
      "Tabelle 1: Ergebnisse der 10 Trainingsdurchläufe\n",
      "Wie der Tabelle 1 zu entnehmen ist, wurde ein durchschnittlicher F1–Score von 87,36\n",
      "% erreicht. Dieser setzt sich aus den Werten Precision sowie dem Recall zusammen und\n",
      "vereint beide Werte in einem. Ein höherer F1–Score bedeutet im Allgemeinen, dass die\n",
      "Performance des Modells gestiegen ist. In gewissen Situationen kann es Ziel sein, eine\n",
      "hohe Precision auf Kosten des Recalls zu erreichen und umgekehrt, was bei dieser Aufgabenstellung nicht zutrifft. Berechnet wurden die Werte basierend auf jedem Wort der\n",
      "Verifikationsdaten. Bei den Metriken des Prototyps wird die gesamte Sequenz der Eingabe für die Bewertung beachtet, weshalb ein direkter Vergleich nicht möglich ist. Damit\n",
      "die Werte verglichen werden können, wurde das vorhandene ELMo–Modell der Pipeline\n",
      "nacheinander mit jedem einzelnen der zehn berechneten Modelle ausgetauscht und die\n",
      "gleiche Metrik wurde erstellt.\n",
      "Durch die neu trainierten Modelle verbesserte sich die Genauigkeit der Pipeline im Durchschnitt auf 87,46 %. Das vorherige ELMo–Modell wurde durch die Nachverarbeitung um\n",
      "1 % verbessert. Die durchschnittliche Genauigkeit der neu trainierten ELMo–Modelle\n",
      "erreichte 87,21 % was bedeutete, dass die Nachverarbeitung das Ergebnis um 0,25 %\n",
      "verbesserte. Durch die Tatsache, dass die gesamte Eingabe zum Berechnen der Metrik\n",
      "betrachtet wurde und jede Eingabesequenz mindestens das Attribut Produkt enthalten\n",
      "musste, war die Confusion Matrix einseitig. Die Werte Precision und Recall wurden aus\n",
      "den Werten der Confusion Matrix berechnet weshalb der daraus resultierende F1–Score\n",
      "von 93,1 % nicht mit dem vorherigen F1–Score verglichen werden konnte. Das vorherige\n",
      "ELMo–Modell erreichte ein F1–Score von 89 %, dieses entsprach einer Verbesserung von\n",
      "etwa 4 %. Die allgemeine Genauigkeit verbesserte sich um ungefähr 7 %. Daraus resultierte, dass der ELMo Algorithmus — mit fast der vierfachen Menge an Daten — nur\n",
      "marginal besser wurde.\n",
      "\n",
      "54\n",
      "\n",
      "\f",
      "Kapitel 5\n",
      "\n",
      "Evaluation\n",
      "\n",
      "5.3. Auswertung der Oberfläche\n",
      "Die vorgestellte Anwendung soll dem Nutzer die Bedienung bzw. den Umgang mit der\n",
      "Pipeline näherbringen. Dazu wird ein grundlegendes Verständnis der Anwendung durch\n",
      "die Benutzung der einfachen Eingabe vermittelt. Dieses beinhaltet das manuelle Setzen\n",
      "von Attributen. Diese Funktion ist ein wesentlicher Bestandteil der Arbeit, da zum Trainieren aller Modelle mit Bezeichner versehene Daten benötigt werden. Zusätzlich wird das\n",
      "manuelle Setzen der Attribute in jeder Realisierung einer solchen Anwendung benötigt, da\n",
      "das System nicht immer alle Attribute korrekt erfasst. Eine mögliche Anwendung für die\n",
      "Pipeline ist ein Chatbot welcher ebenfalls Teil des Prototyps ist. Dieser soll Anwendern\n",
      "zeigen, welche Vorteile ein virtueller Marktplatz gegenüber herkömmlichen Marktplätzen\n",
      "besitzt.\n",
      "All diese Funktionen wurden von mehreren Probanden getestet und bewertet. Die Probanden wurden aufgrund ihrer verschiedenen Fachkenntnisse ausgewählt, so wurden User\n",
      "Experience (UX), User Interface (UI)-Designer sowie Software Engineering (SE) befragt\n",
      "um ein umfassendes Feedback zu erhalten. Insgesamt haben an der Evaluation zehn Personen teilgenommen, wobei jeder dieselben Szenarien zu bewältigen hatte. Zu Beginn wurde das Umfeld des Tests vorgestellt: Der Proband befindet sich in der Facebook Gruppe\n",
      "“Flohmarkt Karlsruhe” und versucht in dieser Gruppe sein altes Smartphone zu verkaufen. In dem ersten Durchlauf wurde das Ergebnis der Pipeline nur angezeigt, damit die\n",
      "Testperson sieht, wie die Anfrage verarbeitet wird und welche Attribute von der Pipeline\n",
      "erkannt werden. In dem zweiten Durchlauf sollten die Probanden eine Anfrage erzeugen,\n",
      "die nicht erkannt wird. Im Anschluss wurde das manuelle Tagging getestet. In dem letzten Testszenario sollten die Probanden die Eingabe der ersten Anfrage in dem Chatbot\n",
      "wiederholen. Während der Tests wurden die Probanden beobachtet wie diese den Prototypen bedienen. Den Abschluss bildete ein Fragebogen (siehe Anhang). Die Ergebnisse\n",
      "der Evaluation werden im folgenden Absatz vorgestellt.\n",
      "Das Szenario, in dem die Probanden die einfache Eingabemaske zum Erstellen eines Inserats bedienen sollten, wurde von 9 Teilnehmern direkt verstanden und es wurde eine\n",
      "passende Anfrage an das System geschickt. Die Ansicht mit der farblichen Hervorhebung\n",
      "wurde von allen Probanden auf Anhieb verstanden. 30 % der Probanden waren unsicher\n",
      "bezüglich der erkannten Attribute. So wurde z.B. bei der Eingabe: “Hey ich verkaufe mein\n",
      "altes Handy. Es ist ein Huawei P30 preis verhandelbar” Huawei P30 als Produkt erkannt.\n",
      "Für den Probanden sollte Handy das Produkt sein, Huawei die Marke und P30 das Modell. In dem Abschnitt 3.1 wurde bereits erläutert, warum von der Pipeline Huawei P30\n",
      "korrekterweise als Produkt\n",
      "\n",
      "55\n",
      "\n",
      "\f",
      "Kapitel 5\n",
      "\n",
      "Evaluation\n",
      "\n",
      "Durch die erste Aufgabe haben die Probanden erkannt, welche Attribute von der Pipeline erkannt werden sollten, was die Bearbeitung der zweiten Aufgabe erleichterte. Die\n",
      "Anwender werden nach der Eingabe vom System gefragt, ob die erkannten Ergebnisse\n",
      "korrekt sind. Bei einer Verneinung wird die Anfrage an den Tagger weitergeleitet und der\n",
      "Anwender wird aufgefordert seine Eingabe manuell mit Attributen zu versehen. Wird das\n",
      "Ergebnis abgelehnt, war jedem Probanden bewusst, dass die Attribute manuell gesetzt\n",
      "werden sollen, ohne dass eine solche Anweisung von der Oberfläche angezeigt wird. Alle\n",
      "Probanden versuchten zunächst die farblichen Schaltflächen der Attribute auf die passenden Begriffe der Eingabe per Drag–and–Drop zu ziehen. Erst nach einigen Versuchen\n",
      "wurde die Bedienung des Taggers verstanden. Das vorherige erwähnte Problem der Unsicherheit — was genau mit welchem Attribut zu versehen ist — hatten hier 6 von 10\n",
      "Probanden.\n",
      "In dem letzten Szenario wurde der Chatbot evaluiert. Durch die vorherigen Aufgaben\n",
      "und die kleine Beschreibung des Chatbots war eine problemlose Bedienung möglich. Je\n",
      "nach Anfrage erhielten die Anwender eine Antwort, entweder dass ein passendes Angebot\n",
      "gefunden werden konnte oder die Rückmeldung, dass kein Angebot vorhanden ist. In\n",
      "beiden Fällen wurde deutlich welche Attribute in der Anfrage enthalten waren. Dadurch\n",
      "konnten die Probanden nachvollziehen, dass kein passendes Angebot für die jeweilige\n",
      "Eingabe gefunden werden konnte. Von allen Teilnehmern wurde die Zustandslosigkeit\n",
      "bzw. das nicht Fortführen der Verhandlung des Chatbots negativ wahrgenommen.\n",
      "Der Fragebogen teilt sich in vier Hauptkategorien auf: Oberfläche, Funktionalität,\n",
      "natürliche Sprachverarbeitung und Feedback. Die gesamten Antworten können dem Fragebogen aus dem Anhang entnommen werden. Im Folgenden werden einige der Antworten\n",
      "vorgestellt.\n",
      "Der Chatbot stellt eine reale Anwendung dar, der dem Nutzer die Vorteile der natürlichen\n",
      "Sprachverarbeitung zeigen soll. In dem Testdurchlauf wurde bereits deutlich, dass die\n",
      "Probanden davon ausgingen, dass der Chat fortgeführt werden würde. Diese Erkenntnis\n",
      "spiegelt sich deutlich in der Umfrage wieder, da die Stimmen bei “Zielführend” gleich\n",
      "zwischen -1 und +1 aufgeteilt sind. Zudem erwarteten einige Probanden, dass mehr als\n",
      "nur ein Resultat auf die gegebene Anfrage angezeigt werden würde. Auch wurde mehrfach\n",
      "versucht, die Suche durch weitere Anfragen zu spezifizieren, was aufgrund der Zustandslosigkeit nicht möglich war.\n",
      "Das Tagging spielt eine wesentliche Rolle bei allen NLP Anwendungen. Selbst gut funktionierende Anwendungen sollten Nutzern die Möglichkeit geben, die eigene Eingabe manuell mit Attributen zu versehen, falls diese nicht korrekt erkannt wurden. Ist dieses\n",
      "\n",
      "56\n",
      "\n",
      "\f",
      "Kapitel 5\n",
      "\n",
      "Evaluation\n",
      "\n",
      "nicht möglich, wird der Nutzer nicht verstanden und eine Benutzung der Anwendung ist\n",
      "unmöglich. In der Evaluation sollte der Tagger verwendet werden, ohne dass dieser erklärt\n",
      "wird. Wie der Abbildung 27 zu entnehmen ist war dieser Test teilweise erfolgreich: der\n",
      "Tagger ist sowohl zielführend als auch optisch ansprechend. Die Intuitivität hingegen wurde besser bewertet als in der Evaluation beobachtet werden konnte, da alle Probanden erst\n",
      "nach einigen Versuchen die Bedienung verstanden haben. Durch die vorherige Aufgabe\n",
      "wurde bereits ein gewisses Verständnis der farblichen Hervorhebung vermittelt, weshalb\n",
      "die Verständlichkeit des Taggers gut ist. Die meisten Teilnehmer hatten das Gefühl, dass\n",
      "die Anwendung die gegebene Anfrage verstehen würden. Diese Frage wurde überwiegend\n",
      "durch den ersten Eindruck beantwortet, da die meisten Probanden weniger als 6 Anfragen an das System stellten. Dies ist ein wesentliches Kriterium für eine reale Anwendung,\n",
      "da der erste Eindruck entscheidend dafür ist, ob das Programm weiterhin verwendet wird\n",
      "oder nicht. Somit hatten Anwender das Gefühl, von dem System verstanden zu werden was\n",
      "NA2 erfüllt. Ebenfalls relevant ist die Frage, ob diese Art der Produktsuche gegenüber der\n",
      "herkömmlichen Schlagwortsuche bevorzugt werden würde. 9 von 10 Probanden stimmten\n",
      "dem zu.\n",
      "\n",
      "Abbildung 27: Ergebnisse der Umfrage bezüglich der Tagging Funktion\n",
      "Zusammenfassend war die Evaluation erfolgreich, da alle Probanden mit dem Prototyp\n",
      "zufrieden waren. Was genau mit welchen Attributen versehen werden sollte sowie die\n",
      "Oberfläche des Taggers, benötigt eine kurze Erklärung, damit Nutzer genau wissen was die\n",
      "Anwendung erwartet. Ebenfalls sollte das Aussehen der meisten Funktionen überarbeitet\n",
      "werden, da diese bei der Evaluation überwiegend neutral bewertet wurden.\n",
      "\n",
      "57\n",
      "\n",
      "\f",
      "Kapitel 7\n",
      "\n",
      "Fazit\n",
      "\n",
      "6. Fazit\n",
      "Diese Arbeit befasst sich mit dem Umwandeln von unstrukturierter Eingabe in strukturierte Ausgabe, die von einem Computer weiterverarbeitet wird. Um dieses Ziel zu erreichen\n",
      "wurden verschiedene Methoden und Algorithmen angewendet und evaluiert. Im Rahmen\n",
      "dieser Arbeit wurde ein generisches Konzept entwickelt, durch das ein virtueller Marktplatz mit der natürlichen Sprachverarbeitung unterstützt werden kann. Die Konzeption\n",
      "wurde prototypisch umgesetzt, um zusätzlich zu den Anforderungen, das Sammeln von\n",
      "Daten und Bewerten der Performance zu unterstützen. Die Forschungsfragen FF1 und\n",
      "NF2 können mit der Pipeline beantwortet werden. Im Bereich des ML ist die vorhandene Menge der Daten ein wesentlicher Faktor um zielführende Modelle zu erstellen. Der\n",
      "mit dieser Arbeit verbundene Datensatz umfasste lediglich 260 Einträge. Das auf diesem\n",
      "Datensatz erzielte Ergebnis von 87,46 % Genauigkeit, welches im Abschnitt 5.2 hergeleitet wurde, zeigt dass auch mit einer kleinen Menge von Daten ein solides Ergebnis\n",
      "entstehen kann, was NF1 beantwortet. Dieses Ergebnis übertrifft die anfänglichen Erwartungen deutlich, da vermutet wurde das die ganzen Produkte zu verschieden sind, um\n",
      "diese so präzise zu bestimmen. Somit konnten alle anfänglich gestellten Forschungsfragen\n",
      "beantwortet werden.\n",
      "Mit der prototypischen Implementierung konnte das Verständnis der Anwender gegenüber\n",
      "einem solchen System untersucht werden. Die Evaluation zeigt sowohl eine hohe Akzeptanz als auch das Interesse der Nutzer gegenüber der neuen Art auf virtuellen Marktplätzen zu handeln. Diese Erkenntnisse erzeugen, zusätzlich zu den bereits erwähnten aus\n",
      "Abschnitt 1.1, weitere Mehrwerte die ein Unternehmen erhalten würde wie z.B. ein innovatives, akzeptiertes Verfahren der Anfragenverarbeitung. Die Oberfläche sowie Funktionsweise des Taggers wurde während der Verwendung des Prototyps positiv wahrgenommen,\n",
      "was zeigt, dass dieser als Vorlage für eine reale Anwendung verwendet werden kann.\n",
      "\n",
      "7. Ausblick\n",
      "Ein Tool das beliebige Attribute in einer Eingabesequenz klassifizieren kann, hat viele\n",
      "verschiedene Anwendungsbereiche. Der Prototyp umfasst bereits alle Funktionalitäten,\n",
      "die für eine neue Applikation benötigt werden. So werden beispielsweise Daten gesammelt\n",
      "und gegebenenfalls nachträglich überarbeitet. Auch wird dem Nutzer mit dem Chatbot\n",
      "eine Anwendung geboten, die die Vorteile eines solchen Systems darstellt. Das automatische Generieren der Metriken zeigt die Stärken des Systems und durch die verschiedenen\n",
      "Graphen wird das Finden von Schwächen erleichtert. Weitere Ideen für Funktionalitäten\n",
      "\n",
      "58\n",
      "\n",
      "\f",
      "Kapitel 7\n",
      "\n",
      "Ausblick\n",
      "\n",
      "wurden bereits während der Entwicklung des Prototyps deutlich, die Aufgrund des Umfangs dieser Arbeit nicht realisiert wurden. Ein Feature war das automatische Trainieren\n",
      "der Pipeline, sobald eine gewisse Menge von neuen Daten zur Verfügung stand. Dieses\n",
      "würde dafür sorgen, dass die Performance der Anwendung sich von selbst verbessert,\n",
      "ohne dass das Training manuell gestartet werden müsste. Auch könnte der Tagger in\n",
      "seiner Funktionalität erweitert werden. So besteht für den Anwender die Möglichkeit eigene Attribute hinzuzufügen, welche dann im Tagger verwendet werden können. Durch\n",
      "diese Änderung könnten bereits Daten für andere Kategorien gesammelt werden, welches ein späteres Erweitern der Pipeline erleichtert. Durch das Feedback der Evaluation\n",
      "wurde deutlich, dass eine andere Art der Bedienung des Taggers den Umgang verbessern könnte. Eine mögliche Realisierung wäre, dass Nutzer ein Attribut auswählen und\n",
      "im Anschluss die passenden Wörter anklicken wodurch diese farblich hervorgehoben werden. In dem 1.1. Kapitel wurde die Bedienung über Sprachinterfaces vorgestellt, welches\n",
      "ebenfalls eine interessante Erweiterung für den Prototypen darstellt. Die Matchmaking\n",
      "Funktion des Chatbots könnte überarbeitet werden, da diese bisher nur auf die genaue\n",
      "Übereinstimmung von Attributen achtet. Auch könnten dem Chatbot Zustände hinzugefügt werden, wodurch dem Anwender eine echte Konversation suggeriert wird.\n",
      "Zum Schluss dieser Arbeit ergeben sich neue Fragen, wie z.B.: “Wie gut skaliert die\n",
      "Pipeline?” bzw. “Wie viele Attribute können die einzelnen Modelle unterscheiden, ohne\n",
      "dass die Genauigkeit beeinflusst wird?”. Hierbei handelt es sich um wesentliche Aspekte,\n",
      "die für die Realisierung eines virtuellen Marktplatzes in dieser Form benötigt werden.\n",
      "Die Pipeline selbst könnte durch Ergänzen von mehreren Attributen aus verschiedenen\n",
      "Produktklassen erweitert werden. Dadurch wäre es mögliche, die Frage der Skalierbarkeit\n",
      "zu beantworten.\n",
      "\n",
      "59\n",
      "\n",
      "\f",
      "Kapitel 8\n",
      "\n",
      "Quellenverzeichnis\n",
      "\n",
      "8. Quellenverzeichnis\n",
      "Zadeh, Lotfi A (1965). Fuzzy sets“. In: Information and control 8.3, S. 338–353.\n",
      "”\n",
      "Levenshtein, Vladimir I (1966). Binary codes capable of correcting deletions, insertions,\n",
      "”\n",
      "and reversals“. In: Soviet physics doklady. Bd. 10. 8, S. 707–710.\n",
      "Schütze, Hinrich und Jan O Pedersen (1995). Information retrieval based on word senses“.\n",
      "”\n",
      "In: Citeseer.\n",
      "Schuster, Mike und Kuldip K Paliwal (1997). Bidirectional recurrent neural networks“.\n",
      "”\n",
      "In: IEEE transactions on Signal Processing 45.11, S. 2673–2681.\n",
      "Cummins, F., F.A. Gers und J. Schmidhuber (1999). Learning to forget: continual pre”\n",
      "diction with LSTM“. In: IET Conference Proceedings, 850–855(5).\n",
      "Lafferty, John D., Andrew McCallum und Fernando C. N. Pereira (2001). Conditional\n",
      "”\n",
      "Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data“. In:\n",
      "Proceedings of the Eighteenth International Conference on Machine Learning, S. 282–\n",
      "289.\n",
      "Tjong Kim Sang, Erik F. und Fien De Meulder (2003). Introduction to the CoNLL-2003\n",
      "”\n",
      "Shared Task: Language-Independent Named Entity Recognition“. In: Proceedings of the\n",
      "Seventh Conference on Natural Language Learning at HLT-NAACL 2003, S. 142–147.\n",
      "Mansouri, Alireza, Lilly Suriani Affendey und Ali Mamat (2008). Named entity recogni”\n",
      "tion approaches“. In: International Journal of Computer Science and Network Security\n",
      "8.2, S. 339–344.\n",
      "Arel, Itamar, Derek C Rose und Thomas P Karnowski (2010). Deep machine learning-a\n",
      "”\n",
      "new frontier in artificial intelligence research [research frontier]“. In: IEEE computational intelligence magazine 5.4, S. 13–18.\n",
      "Faruqui, Manaal und Sebastian Padó (2010). Training and Evaluating a German Named\n",
      "”\n",
      "Entity Recognizer with Semantic Generalization“. In: KONVENS, S. 129–133.\n",
      "Mikolov, Tomáš u. a. (2010). Recurrent neural network based language model“. In: Ele”\n",
      "venth annual conference of the international speech communication association.\n",
      "Vicknair, Chad u. a. (2010). A comparison of a graph database and a relational database:\n",
      "”\n",
      "a data provenance perspective“. In: Proceedings of the 48th annual Southeast regional\n",
      "conference, S. 1–6.\n",
      "Krizhevsky, Alex, Ilya Sutskever und Geoffrey E Hinton (2012). Imagenet classification\n",
      "”\n",
      "with deep convolutional neural networks“. In: Advances in neural information processing\n",
      "systems, S. 1097–1105.\n",
      "Mikolov, Tomas u. a. (2013). Distributed representations of words and phrases and their\n",
      "”\n",
      "compositionality“. In: Advances in neural information processing systems, S. 3111–3119.\n",
      "\n",
      "60\n",
      "\n",
      "\f",
      "Kapitel 8\n",
      "\n",
      "8. Quellenverzeichnis\n",
      "\n",
      "Goldberg, Yoav und Omer Levy (2014). word2vec Explained: deriving Mikolov et al.’s\n",
      "”\n",
      "negative-sampling word-embedding method“. In: arXiv preprint arXiv:1402.3722.\n",
      "Kalchbrenner, Nal, Edward Grefenstette und Philip Blunsom (2014). A convolutional\n",
      "”\n",
      "neural network for modelling sentences“. In: 52nd Annual Meeting of the Association\n",
      "for Computational Linguistics.\n",
      "Pennington, Jeffrey, Richard Socher und Christopher D Manning (2014). Glove: Global\n",
      "”\n",
      "vectors for word representation“. In: Proceedings of the 2014 conference on empirical\n",
      "methods in natural language processing (EMNLP), S. 1532–1543.\n",
      "Olah, Christopher (2015). Understanding LSTM Networks. http://colah.github.io/\n",
      "posts/2015-08-Understanding-LSTMs/. (besucht am 22.11.2019).\n",
      "Seatgeek (2015). Fuzzywuzzy. https://github.com/seatgeek/fuzzywuzzy. (besucht am\n",
      "16.10.2019).\n",
      "Zhang, Ye und Byron Wallace (2015). A sensitivity analysis of (and practitioners’ gui”\n",
      "de to) convolutional neural networks for sentence classification“. In: arXiv preprint\n",
      "arXiv:1510.03820.\n",
      "Deepu, S, Pethuru Raj und S Rajaraajeswari (2016). A Framework for Text Analytics\n",
      "”\n",
      "using the Bag of Words (BoW) Model for Prediction“. In: Proceedings of the 1st International Conference on Innovations in Computing & Networking, S. 12–13.\n",
      "Jiang, Ridong, Rafael E Banchs und Haizhou Li (2016). Evaluating and combining name\n",
      "”\n",
      "entity recognition systems“. In: Proceedings of the Sixth Named Entity Workshop, S. 21–\n",
      "27.\n",
      "Bai, Shaojie, J Zico Kolter und Vladlen Koltun (2018). An empirical evaluation of ge”\n",
      "neric convolutional and recurrent networks for sequence modeling“. In: arXiv preprint\n",
      "arXiv:1803.01271.\n",
      "Chernodub, Artem (2018). Targer. https://github.com/achernodub/targer. (besucht\n",
      "am 28.10.2019).\n",
      "Devlin, Jacob u. a. (2018). Bert: Pre-training of deep bidirectional transformers for lan”\n",
      "guage understanding“. In: arXiv preprint arXiv:1810.04805.\n",
      "Perone, Christian S, Roberto Silveira und Thomas S Paula (2018). Evaluation of sen”\n",
      "tence embeddings in downstream and linguistic probing tasks“. In: arXiv preprint arXiv:1806.06259.\n",
      "Peters, Matthew E, Mark Neumann, Mohit Iyyer u. a. (2018). Deep contextualized word\n",
      "”\n",
      "representations“. In: arXiv preprint arXiv:1802.05365.\n",
      "Peters, Matthew E, Mark Neumann, Luke Zettlemoyer u. a. (2018). Dissecting con”\n",
      "textual word embeddings: Architecture and representation“. In: arXiv preprint arXiv:1808.08949.\n",
      "\n",
      "61\n",
      "\n",
      "\f",
      "Kapitel 8\n",
      "\n",
      "8. Quellenverzeichnis\n",
      "\n",
      "Sherstinsky, Alex (2018). Fundamentals of Recurrent Neural Network (RNN) and Long\n",
      "”\n",
      "Short-Term Memory (LSTM) Network“. In: arXiv preprint arXiv:1808.03314.\n",
      "Chernodub, Artem u. a. (2019). Targer: Neural argument mining at your fingertips“. In:\n",
      "”\n",
      "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, S. 195–200.\n",
      "May, Philip (2019). German ELMo Model. https://github.com/t-systems-on-siteservices-gmbh/german-elmo-model. (besucht am 24.10.2019).\n",
      "Reimers, Nils und Iryna Gurevych (2019). Alternative Weighting Schemes for ELMo\n",
      "”\n",
      "Embeddings“. In: arXiv preprint arXiv:1904.02954.\n",
      "SpaCy–Dokumentation (2019). Library architecture. https : / / spacy . io. (besucht am\n",
      "14.10.2019).\n",
      "Deepset (o.D.). German Word Embeddings. https : / / deepset . ai / german - word embeddings. (besucht am 25.10.2019).\n",
      "\n",
      "62\n",
      "\n",
      "\f",
      "Anhang A\n",
      "\n",
      "Ergebnisse der Umfrage\n",
      "\n",
      "Anhang\n",
      "A. Ergebnisse der Umfrage\n",
      "\n",
      "Abbildung 28: Bewertung der Oberfläche\n",
      "\n",
      "I\n",
      "\n",
      "\f",
      "Anhang A\n",
      "\n",
      "Ergebnisse der Umfrage\n",
      "\n",
      "Abbildung 29: Fortsetzung der Bewertung zur Oberfläche\n",
      "\n",
      "II\n",
      "\n",
      "\f",
      "Anhang A\n",
      "\n",
      "Ergebnisse der Umfrage\n",
      "\n",
      "Abbildung 30: Bewertung der Funktionalität\n",
      "\n",
      "III\n",
      "\n",
      "\f",
      "Anhang A\n",
      "\n",
      "Ergebnisse der Umfrage\n",
      "\n",
      "Abbildung 31: Fortsetzung der Bewertung zur Funktionalität\n",
      "\n",
      "Abbildung 32: Allgemeine Fragen zur natürlichen Sprachverarbeitung\n",
      "\n",
      "IV\n",
      "\n",
      "\f",
      "Anhang A\n",
      "\n",
      "Ergebnisse der Umfrage\n",
      "\n",
      "Abbildung 33: Fortsetzung der natürlichen Sprachverarbeitung\n",
      "\n",
      "V\n",
      "\n",
      "\f",
      "Anhang A\n",
      "\n",
      "Ergebnisse der Umfrage\n",
      "\n",
      "Abbildung 34: Fortsetzung der natürlichen Sprachverarbeitung\n",
      "\n",
      "VI\n",
      "\n",
      "\f",
      "Anhang B\n",
      "\n",
      "Ergebnisse der Umfrage\n",
      "\n",
      "Abbildung 35: Feedback der Probanden\n",
      "\n",
      "VII\n",
      "\n",
      "\f",
      "Anhang B\n",
      "\n",
      "Metriken der Pipeline\n",
      "\n",
      "B. Metriken der Pipeline\n",
      "\n",
      "Abbildung 36: Confusion Matrik mit dem Attribut ”Preis”von dem Schritt reguläre Ausdrücke\n",
      "\n",
      "Abbildung 37: Confusion Matrik mit dem Attribut ”Kamera”von dem Schritt reguläre\n",
      "Ausdrücke\n",
      "\n",
      "VIII\n",
      "\n",
      "\f",
      "Anhang B\n",
      "\n",
      "Metriken der Pipeline\n",
      "\n",
      "Abbildung 38: Confusion Matrik mit dem Attribut ”Hersteller”von dem Schritt Fuzzy\n",
      "Matching\n",
      "\n",
      "Abbildung 39: Confusion Matrik mit dem Attribut ”Farbe”von dem Schritt Fuzzy Matching\n",
      "\n",
      "IX\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
